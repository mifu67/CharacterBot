{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1102\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "EXPERIENCE_PATH = './trainingdata/hansolo/young-han.json'\n",
    "EXPERIENCE_OLD_PATH = './trainingdata/hansolo/han.json'\n",
    "PROTECTED_PATH = './trainingdata/hansolo/han-protective.json'\n",
    "\n",
    "han_exps = ['./trainingdata/hansolo/young-han.json', './trainingdata/hansolo/han.json', './trainingdata/hansolo/old-han.json']\n",
    "han_protected = ['./trainingdata/hansolo/old-han-protective.json']\n",
    "\n",
    "new_data = []\n",
    "\n",
    "# loop thru the original jsons\n",
    "# for each object present, do the following:\n",
    "# 1. create an empty dict\n",
    "# 2. add the key \"text\"\n",
    "\n",
    "for path in (han_exps + han_protected):\n",
    "    with open(path, 'r') as f:\n",
    "        exp = json.load(f)\n",
    "        for obj in exp:\n",
    "            #print(obj)\n",
    "            temp = {'text': []}\n",
    "            temp['text'].append('<instruction>')\n",
    "            temp['text'].append(obj['instruction'])\n",
    "            temp['text'].append('<input>')\n",
    "            temp['text'].append(obj['input'])\n",
    "            temp['text'].append('<output>')\n",
    "            temp['text'].append(obj['output'])\n",
    "            temp['text'] = ' '.join(temp['text'])\n",
    "            new_data.append(temp)\n",
    "        f.close()\n",
    "\n",
    "print(len(new_data))\n",
    "# filthy\n",
    "# with open(EXPERIENCE_PATH, 'r') as f:\n",
    "#     exp = json.load(f)\n",
    "#     for obj in exp:\n",
    "#         #print(obj)\n",
    "#         temp = {'text': []}\n",
    "#         temp['text'].append('<instruction>')\n",
    "#         temp['text'].append(obj['instruction'])\n",
    "#         temp['text'].append('<input>')\n",
    "#         temp['text'].append(obj['input'])\n",
    "#         temp['text'].append('<output>')\n",
    "#         temp['text'].append(obj['output'])\n",
    "#         temp['text'] = ' '.join(temp['text'])\n",
    "#         new_data.append(temp)\n",
    "#     f.close()\n",
    "# print(len(new_data))\n",
    "\n",
    "# with open(EXPERIENCE_OLD_PATH, 'r') as f:\n",
    "#     exp = json.load(f)\n",
    "#     for obj in exp:\n",
    "#         #print(obj)\n",
    "#         temp = {'text': []}\n",
    "#         temp['text'].append('<instruction>')\n",
    "#         temp['text'].append(obj['instruction'])\n",
    "#         temp['text'].append('<input>')\n",
    "#         temp['text'].append(obj['input'])\n",
    "#         temp['text'].append('<output>')\n",
    "#         temp['text'].append(obj['output'])\n",
    "#         temp['text'] = ' '.join(temp['text'])\n",
    "#         new_data.append(temp)\n",
    "#     f.close()\n",
    "# print(len(new_data))\n",
    "# with open(PROTECTED_PATH, 'r') as f:\n",
    "#     exp = json.load(f)\n",
    "#     for obj in exp:\n",
    "#         #print(obj)\n",
    "#         temp = {'text': []}\n",
    "#         temp['text'].append('<instruction>')\n",
    "#         temp['text'].append(obj['instruction'])\n",
    "#         temp['text'].append('<input>')\n",
    "#         temp['text'].append(obj['input'])\n",
    "#         temp['text'].append('<output>')\n",
    "#         temp['text'].append(obj['output'])\n",
    "#         temp['text'] = ' '.join(temp['text'])\n",
    "#         new_data.append(temp)\n",
    "#     f.close()\n",
    "# print(len(new_data))\n",
    "with open('./trainingdata/hansolo/old-han-data.jsonl', 'w') as f:\n",
    "    for entry in new_data:\n",
    "        json.dump(entry, f)\n",
    "        f.write('\\n')\n",
    "    # json.dump(new_experience, f)\n",
    "    f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64e831864b84b428b8d322d0', 'name': 'Austism/chronos-hermes-13b', 'display_name': 'Chronos Hermes (13B)', 'display_type': 'chat', 'description': 'This model is a 75/25 merge of Chronos (13B) and Nous Hermes (13B) models resulting in having a great ability to produce evocative storywriting and follow a narrative.', 'license': 'other', 'creator_organization': 'Austism', 'hardware_label': '2x A100 80GB', 'num_parameters': 13000000000, 'show_in_playground': True, 'isFeaturedModel': True, 'context_length': 2048, 'config': {'stop': ['</s>'], 'prompt_format': '### Instruction:\\n{prompt}\\n### Response:\\n', 'chat_template': \"{% for message in messages %}{% if message['role'] == 'user' %}{{ '### Instruction:\\n' + message['content'] + '\\n' }}{% else %}{{ '### Response:\\n' + message['content'] + '\\n' }}{% endif %}{% endfor %}{{ '### Response:\\n' }}\"}, 'pricing': {'input': 75, 'output': 75, 'hourly': 0}, 'created_at': '2023-08-24T17:08:25.379Z', 'update_at': '2023-08-24T17:08:25.379Z', 'access': '', 'link': '', 'descriptionLink': '', 'depth': {'num_asks': 2, 'num_bids': 0, 'num_running': 0, 'asks': {'0xFA5C96b20a10cAC5d21E095e6F4f8c3CBC2f3527': 1, '0xa96806eD1168d759DC233DfB636522b72bBbE159': 1}, 'asks_updated': '2023-11-30T20:16:42.570673278Z', 'gpus': {'': 0}, 'qps': 0.04196506, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'throughput_in': 19.94224, 'throughput_out': 3.3861134}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '6532f0faf94bacfc629b4cf7', 'name': 'EleutherAI/llemma_7b', 'display_name': 'Llemma (7B)', 'display_type': 'language', 'description': 'Llemma 7B is a language model for mathematics. It was initialized with Code Llama 7B weights, and trained on the Proof-Pile-2 for 200B tokens.', 'license': 'LLaMA license Agreement (Meta)', 'link': 'https://huggingface.co/EleutherAI/llemma_7b', 'creator_organization': 'EleutherAI', 'hardware_label': 'A100 80GB', 'pricing_tier': 'Featured', 'access': 'open', 'num_parameters': 6738546688, 'show_in_playground': True, 'isFeaturedModel': True, 'context_length': 4096, 'config': {'chat_template_name': 'llama'}, 'pricing': {'input': 50, 'output': 50, 'hourly': 0}, 'created_at': '2023-10-20T21:28:26.403Z', 'update_at': '2023-10-24T17:42:38.630Z', 'descriptionLink': '', 'depth': {'num_asks': 1, 'num_bids': 0, 'num_running': 0, 'asks': {'0x1de9B2f4CFe3fc2905B5C38302E77dd823536c73': 1}, 'asks_updated': '2023-11-30T12:02:47.193210295Z', 'gpus': {'': 0}, 'qps': 0.02729248, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'throughput_in': 0.5046903, 'throughput_out': 1.7144008}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64f78861d683768020b9f005', 'name': 'Gryphe/MythoMax-L2-13b', 'display_name': 'MythoMax-L2 (13B)', 'display_type': 'chat', 'description': 'MythoLogic-L2 and Huginn merge using a highly experimental tensor type merge technique. The main difference with MythoMix is that I allowed more of Huginn to intermingle with the single tensors located at the front and end of a model', 'license': 'other', 'creator_organization': 'Gryphe', 'hardware_label': '1x A40 48GB', 'num_parameters': 13000000000, 'release_date': '2023-08-01T00:00:00.000Z', 'show_in_playground': True, 'isFeaturedModel': True, 'context_length': 4096, 'config': {'stop': ['</s>'], 'prompt_format': '### Instruction:\\n{prompt}\\n### Response:', 'chat_template': \"{% for message in messages %}{% if message['role'] == 'user' %}{{ '### Instruction:\\n' + message['content'] + '\\n' }}{% else %}{{ '### Response:\\n' + message['content'] + '\\n' }}{% endif %}{% endfor %}{{ '### Response:' }}\"}, 'pricing': {'input': 75, 'output': 75, 'hourly': 0}, 'created_at': '2023-09-05T19:58:25.683Z', 'update_at': '2023-09-05T19:58:25.683Z', 'instances': [{'avzone': 'us-east-1a', 'cluster': 'happypiglet'}, {'avzone': 'us-east-2a', 'cluster': 'jumpyjackal'}, {'avzone': 'us-central-1a', 'cluster': 'sassyseal'}], 'access': '', 'link': '', 'descriptionLink': '', 'depth': {'num_asks': 209, 'num_bids': 190, 'num_running': 190, 'asks': {'0x01637e64a1CFbE292e6EBe2E00f69185DF89d611': 4, '0x07b4653B4C867C9CfB4f2A3ceaC68F1F20671Da6': 1, '0x09D59bBE7Fb86f94F0BCDbD3De7Ff9f13938aB59': 6, '0x0E86A9D366259A7Ff146BfC6BE69e580B0BeBf3A': 1, '0x102C7758b7cc0E44C4C8876E002C077d8bd41603': 1, '0x13DB1E0FeFBE7Ef3bfAd5CaD76573296597C38ce': 14, '0x3350c3F44a3225dbC962D62DD82E24B7f6cB8471': 1, '0x37b28e4e7035188D9DCA0d6C93Ed257cd083E1Cc': 1, '0x39AE75E4b81E17fFfE474A036B2fb185d5E29AEF': 2, '0x430Ea7278F74D5765C54588F3D17606779EE416a': 5, '0x46bFcb828de8009c9d1B891f237f483F8E26C05f': 22, '0x483D134ba8724F74FeD95debEa1502DC289B69B7': 3, '0x49Fe4B6E624909d504E4739d31060dC5e00a578e': 4, '0x548E463F92d47d93f01940fd9aeb5ba9A3B5bE0F': 1, '0x5537dc4f0Ac123CD49aAC3A444Ed10693Ba91c6D': 5, '0x579aa338aFcA98afDF99f1c14Da7EA487AC00916': 1, '0x57a5582b5E1508d4Fe138bfa26B882aacEE1F848': 16, '0x59f5E0E38120A95080bf6a002a1f773ad5720eF2': 7, '0x5AB90E240656bc93E8c58C730617A82aF1bC6c98': 1, '0x608c3251Dc8Ad23a591ec41c8F2f15c4fA76B9A6': 3, '0x62c9E9C7C30bD36414D4BfE4b73A397C1236A095': 9, '0x690ec156D12e636a5d45eb0b0184B2f89C838aa6': 1, '0x750C7EA5C4fa95c21905E8B78297C61A78A64C1B': 4, '0x7614a53722658FF897489e838Ac07c703ff3815f': 3, '0x77dDc55dcbeafD7E3DDA5a5C3C1dD0145122A036': 1, '0x7A116c8523E3170107Cd07A2A788615f2A144763': 4, '0x7FefcF6C6C6025830a5DbF1e718b097809b3dB37': 1, '0x86A0cCDbAee9920c670BF7Cc02f73DE96571549B': 16, '0x8ffe255E8555af1387C0524Dcb1b673EC398aB1d': 1, '0x9002a77969C00aB958C9936AD8e74dEb89624e8D': 8, '0xA177b90C3543efaf1406160fa63cD362D58CF329': 1, '0xD0fE5946509AebcE50860F876BA141003D4fEDE9': 3, '0xE4751A8234fa116c9e4e40ca9c9Da6F86404E994': 1, '0xEABB223116c6A75652BDA6CE66Ca6126e1b9C514': 1, '0xFC90529829456BD5cd4107D1434fbedD1315BFf0': 1, '0xFee3E2695fd342e4983b83a2A5931294a74f17f6': 1, '0xa1a40f62A876Be7cbFfD0C7478cB895b927b4E87': 1, '0xa9d2607c36dE09A26A4F20cAa0661B81FE003736': 1, '0xb154a9f4CA2151F61e21519db68Ae339BAAdf405': 3, '0xb266B151084BBA499bF771408DBd8fBe161B5ee2': 1, '0xb66062C56F7438Aa0F1163eEAdfEaF5728C45910': 13, '0xc57431697C9B5f30AD37c8DD57afc67f54ad68C5': 1, '0xcB207FAd1454190a6E27B9396d1AF45dA59B7A1A': 1, '0xd46b944Dc99663df289b03F5bD2e96D2778fd48b': 21, '0xe80ee3A567cC32182D47Ca06af77F4e053439700': 1, '0xea08245042E8Aa315837B85d6e9353C574019550': 1, '0xee2d317445a8d257513dD4B26b5198d2730b26D8': 1, '0xf4446f8A31551775ae515447C5140B9B40c6d489': 8}, 'asks_updated': '2023-11-30T21:10:15.242406701Z', 'gpus': {'': 0}, 'qps': 19.4, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'stats': [{'avzone': 'us-east-1a', 'cluster': 'happypiglet', 'capacity': 0.045838150289017124, 'qps': 5.8}, {'avzone': 'us-east-2a', 'cluster': 'jumpyjackal', 'capacity': 0.4235772357723586, 'qps': 7.6}, {'avzone': 'us-central-1a', 'cluster': 'sassyseal', 'capacity': 0.4403087951475064, 'qps': 6}]}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '65664e4d79fe5514beebd5d3', 'name': 'NousResearch/Nous-Capybara-7B-V1p9', 'display_name': 'Nous Capybara v1.9 (7B)', 'display_type': 'chat', 'description': 'first Nous collection of dataset and models made by fine-tuning mostly on data created by Nous in-house', 'license': 'MIT', 'creator_organization': 'NousResearch', 'hardware_label': 'A100', 'pricing_tier': 'Featured', 'num_parameters': 7241732096, 'release_date': '2023-11-15T00:00:00.000Z', 'show_in_playground': True, 'isFeaturedModel': True, 'config': {'stop': ['USER:', 'ASSISTANT:'], 'prompt_format': 'USER:\\n{prompt}\\nASSISTANT:', 'pre_prompt': ''}, 'pricing': {'input': 50, 'output': 50}, 'created_at': '2023-11-28T20:32:13.026Z', 'update_at': '2023-11-28T20:33:03.163Z', 'access': '', 'link': '', 'descriptionLink': '', 'depth': {'num_asks': 3, 'num_bids': 0, 'num_running': 0, 'asks': {'0x4B981bb934b6F2351c0947c6c4d5c9B7236FAa77': 1, '0x73e916B574621cE804ecd154c3f6eC91369a6c6f': 1, '0xBaD24C21f75FebD4A955cf1a8Ca9DCD3d3dFb222': 1}, 'asks_updated': '2023-11-30T19:29:11.607663012Z', 'gpus': {'': 0}, 'qps': 0.011949811, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'throughput_in': 0.05975463, 'throughput_out': 1.6418321}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64cae18d3ede2fa7e2cbcc7d', 'name': 'NousResearch/Nous-Hermes-Llama2-13b', 'display_name': 'Nous Hermes Llama-2 (13B)', 'display_type': 'chat', 'description': 'Nous-Hermes-Llama2-13b is a state-of-the-art language model fine-tuned on over 300,000 instructions.', 'license': 'mit', 'creator_organization': 'NousResearch', 'hardware_label': '2x A100 80GB', 'pricing_tier': 'featured', 'access': 'open', 'num_parameters': 13000000000, 'show_in_playground': True, 'isFeaturedModel': True, 'context_length': 4096, 'config': {'prompt_format': '### Instruction:\\n{prompt}\\n### Response:\\n', 'stop': ['###', '</s>'], 'chat_template_name': 'llama', 'chat_template': \"{% for message in messages %}{% if message['role'] == 'user' %}{{ '### Instruction:\\n' + message['content'] + '\\n' }}{% else %}{{ '### Response:\\n' + message['content'] + '\\n' }}{% endif %}{% endfor %}{{ '### Response:\\n' }}\"}, 'pricing': {'input': 75, 'output': 75, 'hourly': 0}, 'created_at': '2023-08-02T23:06:53.926Z', 'update_at': '2023-10-07T00:19:33.779Z', 'instances': [{'avzone': 'us-central-1a', 'cluster': 'sassyseal'}, {'avzone': 'us-east-1a', 'cluster': 'happypiglet'}], 'link': '', 'descriptionLink': '', 'depth': {'num_asks': 9, 'num_bids': 0, 'num_running': 0, 'asks': {'0x43Ea90eC8d1c332c02E1ebaE8A47A3e20A0672dB': 1, '0x547067ece967698fde1caEe1Ac01372eC650a2FF': 1, '0x925B2f41d483CF07907D4020A0e68b6E361EB8bb': 1, '0x99eA480870A0cEf766a90a4CE939cf7c916afae1': 1, '0xA6C2C3EB28d45DC8431251dF878cdCCdC3Bcf18C': 1, '0xCC1c1256C5736708c2dad7DDAD286AcB08BecA72': 1, '0xE76b1D2F7AE035c136e94EAc26A7E6bd5344ab8A': 1, '0xe149e0e7C96c5Db20216346a2F96DFF2c7bb52aD': 1}, 'asks_updated': '2023-11-30T20:34:10.813058533Z', 'gpus': {'': 0}, 'qps': 2.666666666666667, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'stats': [{'avzone': 'us-central-1a', 'cluster': 'sassyseal', 'capacity': 0.1655555555555553, 'qps': 1.6}, {'avzone': 'us-east-1a', 'cluster': 'happypiglet', 'capacity': 0.023500000000000014, 'qps': 1.0666666666666667}]}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '6532f0faf94bacfc629b4cf8', 'name': 'NousResearch/Nous-Hermes-Llama2-70b', 'display_name': 'Nous Hermes LLaMA-2 (70B)', 'display_type': 'chat', 'description': 'Nous-Hermes-Llama2-70b is a state-of-the-art language model fine-tuned on over 300,000 instructions.', 'license': 'LLaMA license Agreement (Meta)', 'link': 'https://huggingface.co/NousResearch/Nous-Hermes-Llama2-70b', 'creator_organization': 'NousResearch', 'hardware_label': '2X A100 80GB', 'pricing_tier': 'Featured', 'access': 'open', 'num_parameters': 70000000000, 'show_in_playground': True, 'isFeaturedModel': False, 'context_length': 4096, 'config': {'stop': ['###', '</s>'], 'prompt_format': '### Instruction:\\n{prompt}\\n\\n### Response:\\n', 'chat_template_name': 'llama', 'chat_template': \"{% for message in messages %}{% if message['role'] == 'user' %}{{ '### Instruction:\\n' + message['content'] + '\\n' }}{% else %}{{ '### Response:\\n' + message['content'] + '\\n' }}{% endif %}{% endfor %}{{ '### Response:\\n' }}\"}, 'pricing': {'input': 225, 'output': 225, 'hourly': 0}, 'created_at': '2023-10-20T21:28:26.404Z', 'update_at': '2023-10-24T17:43:39.278Z', 'descriptionLink': '', 'depth': {'num_asks': 5, 'num_bids': 3, 'num_running': 3, 'asks': {'0x15Dfce70c27a9867794e1912A54F1F7949452DaB': 2, '0x9c12E6313B59799fe3c9da9d6D6a2bBc88bC6580': 3}, 'asks_updated': '2023-11-30T21:00:51.736781445Z', 'gpus': {'': 0}, 'qps': 0.037520193, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'throughput_in': 25.097279, 'throughput_out': 17.425407}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '6532f0faf94bacfc629b4cf6', 'name': 'NousResearch/Nous-Hermes-llama-2-7b', 'display_name': 'Nous Hermes LLaMA-2 (7B)', 'display_type': 'chat', 'description': 'Nous-Hermes-Llama2-7b is a state-of-the-art language model fine-tuned on over 300,000 instructions.', 'license': 'LLaMA license Agreement (Meta)', 'link': 'https://huggingface.co/NousResearch/Nous-Hermes-llama-2-7b', 'creator_organization': 'NousResearch', 'hardware_label': 'A100 80GB', 'pricing_tier': 'Featured', 'access': 'open', 'num_parameters': 6738415616, 'show_in_playground': True, 'isFeaturedModel': True, 'context_length': 4096, 'config': {'prompt_format': '### Instruction:\\n{prompt}\\n### Response:\\n', 'stop': ['###', '</s>'], 'chat_template_name': 'llama', 'chat_template': \"{% for message in messages %}{% if message['role'] == 'user' %}{{ '### Instruction:\\n' + message['content'] + '\\n' }}{% else %}{{ '### Response:\\n' + message['content'] + '\\n' }}{% endif %}{% endfor %}{{ '### Response:\\n' }}\"}, 'pricing': {'input': 50, 'output': 50, 'hourly': 0}, 'created_at': '2023-10-20T21:28:26.403Z', 'update_at': '2023-10-24T17:41:52.365Z', 'descriptionLink': '', 'depth': {'num_asks': 4, 'num_bids': 2, 'num_running': 2, 'asks': {'0x551d41A9a88c923cE167CdA27559D5167d45fD5F': 1, '0xA4845663a0c61e906cB0A2A53DcFE488dF651d33': 1, '0xDE5095f4D8a85dAA8360521bA1b1b30CB7027776': 1, '0xa4563A7EF1db4afb51ceD6467ad92956E3E58949': 1}, 'asks_updated': '2023-11-30T21:05:24.892815794Z', 'gpus': {'': 0}, 'qps': 0.02884473, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'throughput_in': 1.1719805, 'throughput_out': 1.8694266}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64f677bdbc372ce719b97f05', 'name': 'NumbersStation/nsql-llama-2-7B', 'display_name': 'NSQL LLaMA-2 (7B)', 'display_type': 'code', 'description': 'NSQL is a family of autoregressive open-source large foundation models (FMs) designed specifically for SQL generation tasks.', 'license': 'llama2', 'creator_organization': 'Numbers Station', 'hardware_label': 'A40 48GB', 'pricing_tier': 'supported', 'num_parameters': 7000000000, 'show_in_playground': True, 'isFeaturedModel': True, 'context_length': 4096, 'config': {'chat_template_name': 'llama'}, 'pricing': {'input': 50, 'output': 50, 'hourly': 0}, 'created_at': '2023-09-05T00:35:09.649Z', 'update_at': '2023-09-05T00:35:09.649Z', 'access': '', 'link': '', 'descriptionLink': '', 'depth': {'num_asks': 1, 'num_bids': 0, 'num_running': 0, 'asks': {'0xBb702A9526c057836fe845DF91dEAa3B5a48cc84': 1}, 'asks_updated': '2023-11-30T16:09:27.084299327Z', 'gpus': {'': 0}, 'qps': 0.026045928, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'throughput_in': 0.4685432, 'throughput_out': 0.52421147}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '6532f0faf94bacfc629b4cf5', 'name': 'Open-Orca/Mistral-7B-OpenOrca', 'display_name': 'OpenOrca Mistral (7B) 8K', 'display_type': 'chat', 'description': 'An OpenOrca dataset fine-tune on top of Mistral 7B by the OpenOrca team.', 'license': 'apache-2.0', 'link': 'https://huggingface.co/Open-Orca/Mistral-7B-OpenOrca', 'creator_organization': 'OpenOrca', 'hardware_label': 'A100 80GB', 'pricing_tier': 'Featured', 'access': 'open', 'num_parameters': 7241748480, 'show_in_playground': True, 'isFeaturedModel': True, 'context_length': 8192, 'config': {'stop': ['<|im_end|>'], 'prompt_format': '<|im_start|>user\\n{prompt}<|im_end|>\\n<|im_start|>assistant\\n', 'add_generation_prompt': True, 'chat_template_name': 'default'}, 'pricing': {'input': 50, 'output': 50, 'hourly': 0}, 'created_at': '2023-10-20T21:28:26.403Z', 'update_at': '2023-10-24T00:01:52.541Z', 'descriptionLink': '', 'depth': {'num_asks': 36, 'num_bids': 34, 'num_running': 34, 'asks': {'0x068257D54fd3eaDc954978230a38fe195cB612d0': 4, '0x1bf93543ed6021E21Ca5e79341B0cbcBF16C2e91': 2, '0x22529a44F3f4399E3d1686F741C3C8cE32aBAbd8': 1, '0x275fa63694aF52f29412C3dC1aE8e6B5A10b990B': 1, '0x2975c4dc20653d24F44998124C06Ce68948a3Ef3': 1, '0x4D828E48e4f5aB6C2d33d063f9f0260C58fd6582': 1, '0x585B57D8D6F8c547b1D20cC01f48F540Bdf57C8B': 5, '0x66ad0b1cD74C7C04840DA9e179fe773bf6e723E5': 1, '0x736dC7C200c2FDc3757E90C6FF3cdc6b4aD16D04': 8, '0x8800d161539ad872ddC53f1351CdfC361EF2516B': 1, '0x89F5b74e5eebBD0C5B0B2550F77A8605E80659Ac': 1, '0x96B8c2E95476a289e1f16358bbb85D9d4aD19f3f': 4, '0xA8B1b968215C9A4423F9EB0Fa26908AFc21cBF9b': 5, '0xcfeC9A83690c2c2e12FA1214B51Cf14545ef7B16': 1}, 'asks_updated': '2023-11-30T20:56:08.21862441Z', 'gpus': {'': 0}, 'qps': 0.7710711, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'throughput_in': 5656.063, 'throughput_out': 876.09204}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64fbbc5adfdb1e4b06b5d5cc', 'name': 'Phind/Phind-CodeLlama-34B-Python-v1', 'display_name': 'Phind Code LLaMA Python v1 (34B)', 'display_type': 'code', 'description': 'This model is fine-tuned from CodeLlama-34B-Python and achieves 69.5% pass@1 on HumanEval.', 'license': 'llama2', 'creator_organization': 'Phind', 'hardware_label': 'A100 80GB', 'pricing_tier': 'supported', 'access': 'open', 'num_parameters': 33743970304, 'show_in_playground': True, 'isFeaturedModel': True, 'context_length': 16384, 'config': {'prompt_format': '### Instruction:\\n{prompt}\\n### Response:\\n', 'stop': ['</s>', '###'], 'chat_template': \"{% for message in messages %}{% if message['role'] == 'user' %}{{ '### Instruction:\\n' + message['content'] + '\\n' }}{% else %}{{ '### Response:\\n' + message['content'] + '\\n' }}{% endif %}{% endfor %}{{ '### Response:\\n' }}\"}, 'pricing': {'input': 200, 'output': 200, 'hourly': 0}, 'created_at': '2023-09-09T00:29:14.496Z', 'update_at': '2023-09-09T00:29:14.496Z', 'link': '', 'descriptionLink': '', 'depth': {'num_asks': 1, 'num_bids': 0, 'num_running': 0, 'asks': {'0x23b26564e6Cc01cDeE6C933fE14C55892225A08C': 1}, 'asks_updated': '2023-11-30T18:46:28.109631464Z', 'gpus': {'': 0}, 'qps': 0.026010403, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'throughput_in': 0.46751302, 'throughput_out': 7.6255445}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64fbbc5adfdb1e4b06b5d5cb', 'name': 'Phind/Phind-CodeLlama-34B-v2', 'display_name': 'Phind Code LLaMA v2 (34B)', 'display_type': 'code', 'description': 'Phind-CodeLlama-34B-v1 trained on additional 1.5B tokens high-quality programming-related data proficient in Python, C/C++, TypeScript, Java, and more.', 'license': 'llama2', 'creator_organization': 'Phind', 'hardware_label': 'A100 80GB', 'pricing_tier': 'supported', 'access': 'open', 'num_parameters': 33743970304, 'show_in_playground': True, 'isFeaturedModel': True, 'context_length': 16384, 'config': {'prompt_format': '### System Prompt\\nYou are an intelligent programming assistant.\\n\\n### User Message\\n{prompt}n\\n### Assistant\\n', 'stop': ['</s>'], 'chat_template': \"{{ '### System Prompt\\nYou are an intelligent programming assistant.\\n\\n' }}{% for message in messages %}{% if message['role'] == 'user' %}{{ '### User Message\\n' + message['content'] + '\\n' }}{% else %}{{ '### Assistant\\n' + message['content'] + '\\n' }}{% endif %}{% endfor %}{{ '### Assistant\\n' }}\"}, 'pricing': {'input': 200, 'output': 200, 'hourly': 0}, 'created_at': '2023-09-09T00:29:14.496Z', 'update_at': '2023-09-09T00:29:14.496Z', 'link': '', 'descriptionLink': '', 'depth': {'num_asks': 5, 'num_bids': 3, 'num_running': 3, 'asks': {'0x4dadba425016Ca6154712e14a68F83b7147F3157': 1, '0x92C124672726325e798A1D55E1Fef1D060657f1b': 2, '0x9D8047723e185c555B9899134ff976f6b6217Ed4': 2}, 'asks_updated': '2023-11-30T20:35:09.7257376Z', 'gpus': {'': 0}, 'qps': 0.039333474, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'throughput_in': 1.4845009, 'throughput_out': 8.781722}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64acee11227f790586239d36', 'name': 'SG161222/Realistic_Vision_V3.0_VAE', 'display_name': 'Realistic Vision 3.0', 'display_type': 'image', 'description': 'Fine-tune version of Stable Diffusion focused on photorealism.', 'license': 'creativeml-openrail-m', 'link': 'https://huggingface.co/SG161222/Realistic_Vision_V1.4', 'creator_organization': 'SG161222', 'hardware_label': 'A40 48GB', 'pricing_tier': 'supported', 'access': 'open', 'show_in_playground': True, 'isFeaturedModel': True, 'external_pricing_url': 'https://www.together.xyz/apis#pricing', 'config': {'height': 1024, 'width': 1024, 'steps': 20, 'number_of_images': 2, 'seed': 42}, 'created_at': '2023-07-11T05:52:17.219Z', 'update_at': '2023-07-11T05:52:17.219Z', 'descriptionLink': '', 'pricing': {'hourly': 0, 'input': 0, 'output': 0, 'base': 0, 'finetune': 0}, 'depth': {'num_asks': 1, 'num_bids': 0, 'num_running': 0, 'asks': {'0x1E128f472069E38aEF6B8f25147B42EF81f0F3C0': 1}, 'asks_updated': '2023-11-30T20:38:57.953116125Z', 'gpus': {'NVIDIA A40': 1}, 'options': {'input=text,image': 1}, 'qps': 0.017565776, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'throughput_in': 0.35131693}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '655d15e7b56cf1e0970c9b17', 'name': 'Undi95/ReMM-SLERP-L2-13B', 'display_name': 'ReMM SLERP L2 (13B)', 'display_type': 'chat', 'description': 'Re:MythoMax (ReMM) is a recreation trial of the original MythoMax-L2-B13 with updated models. This merge use SLERP [TESTING] to merge ReML and Huginn v1.2.', 'license': 'LLaMA license Agreement (Meta)', 'link': 'https://huggingface.co/Undi95/ReMM-SLERP-L2-13B', 'creator_organization': 'Undi95', 'hardware_label': 'A100 80GB', 'pricing_tier': 'Featured', 'access': 'open', 'num_parameters': 13000000000, 'show_in_playground': True, 'isFeaturedModel': False, 'context_length': 4096, 'config': {'stop': ['###'], 'prompt_format': '### Instruction:\\n{prompt}\\n\\n### Response:', 'chat_template': \"{% for message in messages %}{% if message['role'] == 'user' %}{{ '### Instruction:\\n' + message['content'] + '\\n\\n' }}{% else %}{{ '### Response:\\n' + message['content'] + '\\n\\n' }}{% endif %}{% endfor %}{{ '### Response:' }}\"}, 'pricing': {'input': 75, 'output': 75, 'hourly': 0}, 'created_at': '2023-11-21T20:41:11.759Z', 'update_at': '2023-11-21T20:41:11.759Z', 'descriptionLink': '', 'depth': {'num_asks': 2, 'num_bids': 1, 'num_running': 1, 'asks': {'0x346Fd8efcc13051868443157Fd3A5514F5195234': 2}, 'asks_updated': '2023-11-30T21:02:53.968856928Z', 'gpus': {'': 0}, 'qps': 0.0048155934, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'throughput_in': 19.730946, 'throughput_out': 2.6640658}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '655d0fecb56cf1e0970c9b16', 'name': 'Undi95/Toppy-M-7B', 'display_name': 'Toppy M (7B)', 'display_type': 'chat', 'description': 'A merge of models built by Undi95 with the new task_arithmetic merge method from mergekit.', 'license': 'LLaMA license Agreement (Meta)', 'link': 'https://huggingface.co/Undi95/Toppy-M-7B', 'creator_organization': 'Undi95', 'hardware_label': 'A100 80GB', 'pricing_tier': 'Featured', 'access': 'open', 'num_parameters': 7241748480, 'show_in_playground': True, 'isFeaturedModel': False, 'context_length': 4096, 'config': {'stop': ['###'], 'prompt_format': '### Instruction:\\n{prompt}\\n\\n### Response:', 'chat_template': \"{% for message in messages %}{% if message['role'] == 'user' %}{{ '### Instruction:\\n' + message['content'] + '\\n\\n' }}{% else %}{{ '### Response:\\n' + message['content'] + '\\n\\n' }}{% endif %}{% endfor %}{{ '### Response:' }}\"}, 'pricing': {'input': 50, 'output': 50, 'hourly': 0}, 'created_at': '2023-11-21T20:15:40.468Z', 'update_at': '2023-11-21T20:15:40.468Z', 'descriptionLink': '', 'depth': {'num_asks': 2, 'num_bids': 1, 'num_running': 1, 'asks': {'0x2e58c20b3e8090632DdE22091EC734E2F15207AA': 1, '0x8E99D691ef451333CE25553451c625a414dd418E': 1}, 'asks_updated': '2023-11-30T19:18:27.886592075Z', 'gpus': {'': 0}, 'qps': 2.499224e-20, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'throughput_in': 1.9104068e-16, 'throughput_out': 2.0411157e-16}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64fbbc5adfdb1e4b06b5d5cd', 'name': 'WizardLM/WizardCoder-15B-V1.0', 'display_name': 'WizardCoder v1.0 (15B)', 'display_type': 'code', 'description': 'This model empowers Code LLMs with complex instruction fine-tuning, by adapting the Evol-Instruct method to the domain of code.', 'license': 'llama2', 'creator_organization': 'WizardLM', 'hardware_label': 'A100 80GB', 'pricing_tier': 'supported', 'access': 'open', 'num_parameters': 15517462528, 'show_in_playground': True, 'context_length': 8192, 'config': {'prompt_format': '### Instruction:\\n{prompt}\\n\\n### Response:\\n', 'stop': ['###', '<|endoftext|>'], 'chat_template': \"{% for message in messages %}{% if message['role'] == 'user' %}{{ '### Instruction:\\n' + message['content'] + '\\n\\n' }}{% else %}{{ '### Response:\\n' + message['content'] + '\\n\\n' }}{% endif %}{% endfor %}{{ '### Response:\\n' }}\"}, 'pricing': {'input': 75, 'output': 75, 'hourly': 0}, 'created_at': '2023-09-09T00:29:14.496Z', 'update_at': '2023-09-09T00:29:14.496Z', 'link': '', 'descriptionLink': '', 'depth': {'num_asks': 4, 'num_bids': 3, 'num_running': 3, 'asks': {'0x63199A7778a823BbfffebA3432C7c87831595648': 4}, 'asks_updated': '2023-11-30T20:45:31.414840081Z', 'gpus': {'': 0}, 'qps': 0.026010485, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'throughput_in': 0.4675154, 'throughput_out': 0.59048486}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '6567d4e5d1c5e59967640530', 'name': 'WizardLM/WizardLM-13B-V1.2', 'display_name': 'WizardLM v1.2 (13B)', 'display_type': 'chat', 'description': 'This model achieves a substantial and comprehensive improvement on coding, mathematical reasoning and open-domain conversation capacities', 'license': 'llama2', 'creator_organization': 'WizardLM', 'hardware_label': 'A100', 'pricing_tier': 'Featured', 'num_parameters': 13000000000, 'release_date': '2023-11-01T00:00:00.000Z', 'show_in_playground': True, 'isFeaturedModel': True, 'config': {'stop': ['</s>', 'USER:', 'ASSISTANT:'], 'prompt_format': 'USER: {prompt} ASSISTANT:', 'pre_prompt': \"A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions. \"}, 'pricing': {'input': 50, 'output': 50}, 'created_at': '2023-11-30T00:18:45.791Z', 'update_at': '2023-11-30T01:20:01.779Z', 'access': '', 'link': '', 'descriptionLink': '', 'depth': {'num_asks': 1, 'num_bids': 0, 'num_running': 0, 'asks': {'0x47403098D12c575B632Ad32a5666317D2A5d10C4': 1}, 'asks_updated': '2023-11-30T21:01:00.032500924Z', 'gpus': {'': 0}, 'qps': 0, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64f67555bc372ce719b97f03', 'name': 'WizardLM/WizardLM-70B-V1.0', 'display_name': 'WizardLM v1.0 (70B)', 'display_type': 'language', 'description': 'This model achieves a substantial and comprehensive improvement on coding, mathematical reasoning and open-domain conversation capacities.', 'license': 'llama2', 'creator_organization': 'WizardLM', 'hardware_label': '2x A100 80GB', 'pricing_tier': 'supported', 'num_parameters': 70000000000, 'show_in_playground': True, 'isFeaturedModel': True, 'context_length': 4096, 'config': {'stop': ['</s>'], 'prompt_format': 'USER: {prompt} ASSISTANT:', 'chat_template': \"{% for message in messages %}{% if message['role'] == 'user' %}{{ 'USER: ' + message['content'] + ' ' }}{% else %}{{ 'ASSISTANT:' + message['content'] + '\\n' }}{% endif %}{% endfor %}{{ 'ASSISTANT:' }}\"}, 'pricing': {'input': 225, 'output': 225, 'hourly': 0}, 'created_at': '2023-09-05T00:24:53.327Z', 'update_at': '2023-09-05T00:24:53.327Z', 'access': '', 'link': '', 'descriptionLink': '', 'depth': {'num_asks': 1, 'num_bids': 1, 'num_running': 1, 'asks': {'0x9bFb1a1D28Bd50dE78bcb8A79663dA916ade6f3e': 1}, 'asks_updated': '2023-11-30T18:26:48.20363237Z', 'gpus': {'': 0}, 'qps': 0.14918986, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'throughput_in': 592.89496, 'throughput_out': 27.42086}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64f676f7bc372ce719b97f04', 'name': 'garage-bAInd/Platypus2-70B-instruct', 'display_name': 'Platypus2 Instruct (70B)', 'display_type': 'chat', 'description': 'An instruction fine-tuned LLaMA-2 (70B) model by merging Platypus2 (70B) by garage-bAInd and LLaMA-2 Instruct v2 (70B) by upstage.', 'license': 'CC BY-NC-4.0', 'creator_organization': 'garage-bAInd', 'hardware_label': '2x A100 80GB', 'pricing_tier': 'featured', 'num_parameters': 70000000000, 'show_in_playground': True, 'isFeaturedModel': True, 'context_length': 4096, 'config': {'stop': ['</s>', '###'], 'prompt_format': '### Instruction:\\n{prompt}\\n### Response:\\n'}, 'pricing': {'input': 225, 'output': 225, 'hourly': 0}, 'created_at': '2023-09-05T00:31:51.264Z', 'update_at': '2023-09-07T01:46:29.338Z', 'access': '', 'link': '', 'descriptionLink': '', 'depth': {'num_asks': 2, 'num_bids': 1, 'num_running': 1, 'asks': {'0x763611653e222b6a0a8b7E060FB819A1FfcDF025': 2}, 'asks_updated': '2023-11-30T21:01:03.317573413Z', 'gpus': {'': 0}, 'qps': 0.09722284, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'throughput_in': 732.5889, 'throughput_out': 17.587734}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64acea57227f790586239d0d', 'name': 'huggyllama/llama-65b', 'display_name': 'LLaMA (65B)', 'display_type': 'language', 'description': 'An auto-regressive language model, based on the transformer architecture. The model comes in different sizes: 7B, 13B, 33B and 65B parameters.', 'license': 'LLaMA license Agreement (Meta)', 'link': 'https://huggingface.co/decapoda-research/llama-30b-hf-int4/commit/95d097b272bd0a84a164aa8116e8c09661487581#d2h-740129', 'creator_organization': 'Meta', 'hardware_label': '2x A100 80GB', 'pricing_tier': 'supported', 'access': 'open', 'num_parameters': 65000000000, 'show_in_playground': True, 'isFeaturedModel': True, 'context_length': 2048, 'config': {'chat_template_name': 'llama'}, 'pricing': {'input': 225, 'output': 225, 'hourly': 0}, 'created_at': '2023-07-11T05:36:23.656Z', 'update_at': '2023-07-11T05:36:23.656Z', 'descriptionLink': '', 'depth': {'num_asks': 1, 'num_bids': 0, 'num_running': 0, 'asks': {'0x78B092625C02856925454cACa099990A7F543eE7': 1}, 'asks_updated': '2023-11-30T21:10:08.349636032Z', 'gpus': {'': 0}, 'qps': 0.011949835, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'throughput_in': 0.059753448, 'throughput_out': 1.6736442}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64fbbc5adfdb1e4b06b5d5ce', 'name': 'lmsys/vicuna-13b-v1.5-16k', 'display_name': 'Vicuna v1.5 16K (13B)', 'display_type': 'chat', 'description': 'Vicuna is a chat assistant trained by fine-tuning Llama 2 on user-shared conversations collected from ShareGPT.', 'license': 'llama2', 'creator_organization': 'LM Sys', 'hardware_label': 'A100 80GB', 'pricing_tier': 'supported', 'access': 'open', 'num_parameters': 13015864320, 'show_in_playground': True, 'isFeaturedModel': True, 'context_length': 16384, 'config': {'prompt_format': 'USER: {prompt}\\nASSISTANT:', 'stop': ['</s>'], 'chat_template': \"{% for message in messages %}{{message['role'].toLocaleUpperCase() + ': ' + message['content'] + '\\n'}}{% endfor %}{{ 'ASSISTANT:' }}\"}, 'pricing': {'input': 75, 'output': 75, 'hourly': 0}, 'created_at': '2023-09-09T00:29:14.496Z', 'update_at': '2023-09-09T00:29:14.496Z', 'link': '', 'descriptionLink': '', 'depth': {'num_asks': 4, 'num_bids': 5, 'num_running': 4, 'asks': {'0x6FDb2202dDE8386D67b8D64849Fb593E7cABE01B': 1, '0xAcEb074D6C8d98a788A874F2c40b65815cCf313d': 3}, 'asks_updated': '2023-11-30T21:00:29.671953322Z', 'gpus': {'': 0}, 'qps': 0.019168785, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'throughput_in': 0.26910552, 'throughput_out': 1.0166692}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64f678e7bc372ce719b97f06', 'name': 'lmsys/vicuna-13b-v1.5', 'display_name': 'Vicuna v1.5 (13B)', 'display_type': 'chat', 'description': 'Vicuna is a chat assistant trained by fine-tuning Llama 2 on user-shared conversations collected from ShareGPT.', 'license': 'llama2', 'creator_organization': 'LM Sys', 'hardware_label': 'A40 48GB', 'pricing_tier': 'supported', 'access': 'open', 'num_parameters': 13000000000, 'show_in_playground': True, 'isFeaturedModel': True, 'context_length': 4096, 'config': {'stop': ['</s>'], 'prompt_format': 'USER: {prompt}\\nASSISTANT:', 'chat_template': \"{% for message in messages %}{{message['role'].toLocaleUpperCase() + ': ' + message['content'] + '\\n'}}{% endfor %}{{ 'ASSISTANT:' }}\"}, 'pricing': {'input': 75, 'output': 75, 'hourly': 0}, 'created_at': '2023-09-05T00:40:07.763Z', 'update_at': '2023-09-05T00:40:07.763Z', 'link': '', 'descriptionLink': '', 'depth': {'num_asks': 4, 'num_bids': 2, 'num_running': 2, 'asks': {'0x4355788cD083a3DFEd4Ab134b49aeC1B9a4820ae': 3, '0x8FFf4DEeFE3C4Aa5F2810d372617B58D262b064B': 1}, 'asks_updated': '2023-11-30T20:12:43.400463307Z', 'gpus': {'': 0}, 'qps': 0.3363713, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'throughput_in': 1429.3156, 'throughput_out': 253.30592}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '652da26579174a6bc507647f', 'name': 'lmsys/vicuna-7b-v1.5', 'display_name': 'Vicuna v1.5 (7B)', 'display_type': 'chat', 'description': 'Vicuna is a chat assistant trained by fine-tuning Llama 2 on user-shared conversations collected from ShareGPT.', 'license': 'LLaMA license Agreement (Meta)', 'link': 'https://huggingface.co/lmsys/vicuna-7b-v1.5', 'creator_organization': 'LM Sys', 'hardware_label': 'A40 48GB', 'pricing_tier': 'Featured', 'access': 'open', 'num_parameters': 6738415616, 'show_in_playground': True, 'isFeaturedModel': False, 'context_length': 4096, 'config': {'stop': ['</s>', 'USER:'], 'prompt_format': 'USER: {prompt}\\nASSISTANT: Hello!', 'chat_template': \"{% for message in messages %}{{message['role'].toLocaleUpperCase() + ': ' + message['content'] + '\\n'}}{% endfor %}{{ 'ASSISTANT:' }}\"}, 'pricing': {'input': 50, 'output': 50, 'hourly': 0}, 'created_at': '2023-10-16T20:51:49.194Z', 'update_at': '2023-10-16T20:51:49.194Z', 'descriptionLink': '', 'depth': {'num_asks': 1, 'num_bids': 0, 'num_running': 0, 'asks': {'0xb73DBA565275A7403Cc93D0b99Ef5D795D0eeC05': 1}, 'asks_updated': '2023-11-30T19:35:37.606825234Z', 'gpus': {'': 0}, 'qps': 0.034972288, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'throughput_in': 0.7274071, 'throughput_out': 1.0344051}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '6514c873829715ded9cd17b1', 'name': 'mistralai/Mistral-7B-Instruct-v0.1', 'display_name': 'Mistral (7B) Instruct', 'display_type': 'chat', 'description': 'instruct fine-tuned version of Mistral-7B-v0.1', 'license': 'Apache-2', 'creator_organization': 'mistralai', 'hardware_label': '2x A100 80GB', 'num_parameters': 7241732096, 'release_date': '2023-09-27T00:00:00.000Z', 'show_in_playground': True, 'isFeaturedModel': True, 'context_length': 4096, 'config': {'stop': ['[/INST]', '</s>'], 'prompt_format': '<s>[INST] {prompt} [/INST]', 'chat_template_name': 'llama'}, 'pricing': {'input': 50, 'output': 50, 'hourly': 0}, 'created_at': '2023-09-28T00:27:31.815Z', 'update_at': '2023-10-12T01:13:51.840Z', 'instances': [{'avzone': 'us-east-1a', 'cluster': 'happypiglet'}], 'access': '', 'link': '', 'descriptionLink': '', 'depth': {'num_asks': 3, 'num_bids': 0, 'num_running': 0, 'asks': {'0xBE32C7088e5D755e6C4d259d446d927f302FF2fE': 1, '0xe418D299aAede108588E6fBf99F06C25f2671738': 1}, 'asks_updated': '2023-11-30T21:05:57.998259256Z', 'gpus': {'': 0}, 'qps': 14.266666666666667, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'stats': [{'avzone': 'us-east-1a', 'cluster': 'happypiglet', 'capacity': 0.20637126060873617, 'qps': 14.266666666666667}]}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '6514c6ee829715ded9cd17b0', 'name': 'mistralai/Mistral-7B-v0.1', 'display_name': 'Mistral (7B)', 'display_type': 'language', 'description': '7.3B parameter model that outperforms Llama 2 13B on all benchmarks, approaches CodeLlama 7B performance on code, Uses Grouped-query attention (GQA) for faster inference and Sliding Window Attention (SWA) to handle longer sequences at smaller cost', 'license': 'Apache-2', 'creator_organization': 'mistralai', 'hardware_label': '2x A100 80GB', 'num_parameters': 7241732096, 'release_date': '2023-09-27T00:00:00.000Z', 'show_in_playground': True, 'isFeaturedModel': True, 'context_length': 4096, 'config': {'stop': ['</s>'], 'prompt_format': '{prompt}', 'chat_template_name': 'llama'}, 'pricing': {'input': 50, 'output': 50, 'hourly': 0}, 'created_at': '2023-09-28T00:21:02.330Z', 'update_at': '2023-09-28T00:21:02.330Z', 'instances': [{'avzone': 'us-east-1a', 'cluster': 'happypiglet'}], 'access': '', 'link': '', 'descriptionLink': '', 'depth': {'num_asks': 2, 'num_bids': 0, 'num_running': 0, 'asks': {'0xAfFc4830905540bbD64C0a4d8cA10493F75aF0e6': 1}, 'asks_updated': '2023-11-30T20:28:41.913895706Z', 'gpus': {'': 0}, 'qps': 0, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'stats': [{'avzone': 'us-east-1a', 'cluster': 'happypiglet', 'capacity': 0.045454545454545456, 'qps': 0}]}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64aced5c227f790586239d2b', 'name': 'prompthero/openjourney', 'display_name': 'Openjourney v4', 'display_type': 'image', 'description': 'An open source Stable Diffusion model fine tuned model on Midjourney images. ', 'license': 'creativeml-openrail-m', 'link': 'https://huggingface.co/prompthero/openjourney', 'creator_organization': 'Prompt Hero', 'hardware_label': 'A40 48GB', 'pricing_tier': 'featured', 'access': 'open', 'num_parameters': 13000000000, 'show_in_playground': True, 'isFeaturedModel': True, 'external_pricing_url': 'https://www.together.xyz/apis#pricing', 'config': {'height': 512, 'width': 512, 'steps': 20, 'number_of_images': 2, 'seed': 42}, 'pricing': {'input': 75, 'output': 75, 'hourly': 0}, 'created_at': '2023-07-11T05:49:16.586Z', 'update_at': '2023-07-11T05:49:16.586Z', 'descriptionLink': '', 'depth': {'num_asks': 2, 'num_bids': 0, 'num_running': 0, 'asks': {'0x5C5b60Ea2C7046FDdf7F7be3853d046301334a85': 1, '0xB2bFeaa446Cc0376249ed2d7a8f5C32E0705e556': 1}, 'asks_updated': '2023-11-30T19:34:25.278202943Z', 'gpus': {'NVIDIA A40': 2}, 'options': {'input=text,image': 2}, 'qps': 0.039009888, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'throughput_in': 0.46037674}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '6495ff1312907e072b8aece1', 'name': 'runwayml/stable-diffusion-v1-5', 'display_name': 'Stable Diffusion 1.5', 'display_type': 'image', 'description': 'Latent text-to-image diffusion model capable of generating photo-realistic images given any text input.', 'license': 'creativeml-openrail-m', 'link': 'https://huggingface.co/runwayml/stable-diffusion-v1-5', 'creator_organization': 'Runway ML', 'hardware_label': 'A100 80GB', 'pricing_tier': 'featured', 'show_in_playground': True, 'isFeaturedModel': True, 'external_pricing_url': 'https://www.together.xyz/apis#pricing', 'config': {'height': 512, 'width': 512, 'steps': 20, 'number_of_images': 2, 'seed': 42}, 'created_at': '2023-06-23T20:22:43.572Z', 'update_at': '2023-06-23T20:22:43.572Z', 'access': '', 'descriptionLink': '', 'pricing': {'hourly': 0, 'input': 0, 'output': 0, 'base': 0, 'finetune': 0}, 'depth': {'num_asks': 1, 'num_bids': 0, 'num_running': 0, 'asks': {'0x98D41CFC96e488D9810431B65Aa98EBfc87b73c8': 1}, 'asks_updated': '2023-11-30T18:46:34.455704815Z', 'gpus': {'NVIDIA A40': 1}, 'options': {'input=text,image': 1}, 'qps': 0.025350466, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'throughput_in': 0.23628698}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64acef00227f790586239d3b', 'name': 'stabilityai/stable-diffusion-2-1', 'display_name': 'Stable Diffusion 2.1', 'display_type': 'image', 'description': 'Latent text-to-image diffusion model capable of generating photo-realistic images given any text input.', 'license': 'openrail++', 'link': 'https://huggingface.co/stabilityai/stable-diffusion-2-1', 'creator_organization': 'Stability AI', 'hardware_label': 'A100 80GB', 'pricing_tier': 'featured', 'show_in_playground': True, 'isFeaturedModel': True, 'external_pricing_url': 'https://www.together.xyz/apis#pricing', 'created_at': '2023-06-23T20:22:43.572Z', 'update_at': '2023-06-23T20:22:43.572Z', 'access': '', 'descriptionLink': '', 'pricing': {'hourly': 0, 'input': 0, 'output': 0, 'base': 0, 'finetune': 0}, 'depth': {'num_asks': 2, 'num_bids': 0, 'num_running': 0, 'asks': {'0x8e6cadaf8bE88b995920A561DE48434b11b05170': 1, '0xC9494f3A014EAC6DD43De5b03E03364F1AcC9ea7': 1}, 'asks_updated': '2023-11-30T20:10:16.61542858Z', 'gpus': {'NVIDIA A100 80GB PCIe': 2}, 'options': {'input=text,image': 2}, 'qps': 0.027626162, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'throughput_in': 0.35854274}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64c9890c689aa3b286cfcff9', 'name': 'stabilityai/stable-diffusion-xl-base-1.0', 'display_name': 'Stable Diffusion XL 1.0', 'display_type': 'image', 'description': 'A text-to-image generative AI model that excels at creating 1024x1024 images.', 'license': 'openrail++', 'link': 'https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0', 'creator_organization': 'Stability AI', 'hardware_label': 'A100 80GB', 'pricing_tier': 'featured', 'access': 'open', 'show_in_playground': True, 'isFeaturedModel': True, 'external_pricing_url': 'https://www.together.xyz/apis#pricing', 'config': {'height': 1024, 'width': 1024, 'steps': 20, 'number_of_images': 2, 'seed': 42}, 'created_at': '2023-08-01T22:37:00.851Z', 'update_at': '2023-08-01T22:37:00.851Z', 'descriptionLink': '', 'pricing': {'hourly': 0, 'input': 0, 'output': 0, 'base': 0, 'finetune': 0}, 'depth': {'num_asks': 1, 'num_bids': 0, 'num_running': 0, 'asks': {'0x2E595c6ee5e62FeFF9f426b239a2fB0970476593': 1}, 'asks_updated': '2023-11-30T19:58:46.108270933Z', 'gpus': {'NVIDIA A100 80GB PCIe': 1}, 'options': {'input=text,image': 1}, 'qps': 0.038925175, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'throughput_in': 0.39031908}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '653c053fd9679a84df55c4e7', 'name': 'teknium/OpenHermes-2-Mistral-7B', 'display_name': 'OpenHermes-2-Mistral (7B)', 'display_type': 'chat', 'description': 'State of the art Mistral Fine-tuned on extensive public datasets', 'license': 'Apache-2', 'creator_organization': 'teknium', 'hardware_label': 'A40', 'pricing_tier': 'Featured', 'num_parameters': 7241732096, 'release_date': '2023-10-27T00:00:00.000Z', 'show_in_playground': True, 'isFeaturedModel': True, 'config': {'stop': ['<|im_end|>', '<|im_start|>'], 'prompt_format': '<|im_start|>user\\n{prompt}<|im_end|>\\n<|im_start|>assistant\\n', 'pre_prompt': '<|im_start|>system\\nYou are thoughtful, helpful, polite, honest, and friendly<|im_end|>\\n', 'add_generation_prompt': True, 'chat_template_name': 'default'}, 'pricing': {'input': 50, 'output': 50, 'hourly': 0}, 'created_at': '2023-10-27T18:45:19.307Z', 'update_at': '2023-10-27T23:53:05.438Z', 'instances': [{'avzone': 'us-east-2a', 'cluster': 'jumpyjackal'}], 'access': '', 'link': '', 'descriptionLink': '', 'depth': {'num_asks': 18, 'num_bids': 2, 'num_running': 2, 'asks': {'0x1F56D369a573066890cBaD3443c9f222ef10e1D3': 1, '0x2447D4d1e4D0E67F54349f0061c15a2c4d2315D8': 1, '0x2EEE67EE6495C35b5d4e3FDBB56d8A4FBE99EF7a': 1, '0x35c0a2A5F744a0fb52dde9743B93F135895CCeC5': 1, '0x3e7b96F15cEC21A9405c5cF73A9bfE1c8dB5963d': 1, '0x5C351909412afD37f8A4e49DD7C1Ce6C26D58045': 1, '0x7594203Fb8614e6921a9197038Bb98A029fBaE07': 1, '0x96e984a8EA5eBD07e5ACF5E7761aC66c03A0457C': 1, '0x9778EB18C6694e1934e92bA67340c06B7BD35530': 1, '0x9f850AC6941891f0ce2893F67f97DBc0f3839cDB': 1, '0xA59b2541da93726954C2F250d438b17Dc15E2F7E': 1, '0xACe1778e4601b49e9C86b97Fd42c9C35E871aE44': 1, '0xC665333e614839113Ca630773cC60De20B179EC5': 1, '0xD8d0A5999D87b21E7Dd619e58b5Db048e5e9dA58': 1, '0xF93afA632a4Ae317212d9be258D35c69af76CaCb': 1, '0xa4BfEAc05f1E055fA8E804dD1A3C104851e1c1B7': 1, '0xfE3dd65473d02C0B21eaa481386004dDaa382Da4': 1}, 'asks_updated': '2023-11-30T21:06:22.319370675Z', 'gpus': {'': 0}, 'qps': 9.266666666666667, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'stats': [{'avzone': 'us-east-2a', 'cluster': 'jumpyjackal', 'capacity': 0.5097136568311011, 'qps': 9.266666666666667}]}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '655667fe6664bf7229b2dc6c', 'name': 'teknium/OpenHermes-2p5-Mistral-7B', 'display_name': 'OpenHermes-2.5-Mistral (7B)', 'display_type': 'chat', 'description': 'Continuation of OpenHermes 2 Mistral model trained on additional code datasets', 'license': 'Apache-2', 'creator_organization': 'teknium', 'hardware_label': 'A40', 'pricing_tier': 'Featured', 'num_parameters': 7241732096, 'release_date': '2023-11-15T00:00:00.000Z', 'show_in_playground': True, 'isFeaturedModel': True, 'config': {'stop': ['<|im_end|>', '<|im_start|>'], 'prompt_format': '<|im_start|>user\\n{prompt}<|im_end|>\\n<|im_start|>assistant\\n', 'add_generation_prompt': True, 'chat_template_name': 'default'}, 'pricing': {'input': 50, 'output': 50}, 'created_at': '2023-11-16T19:05:34.976Z', 'update_at': '2023-11-16T19:12:24.883Z', 'instances': [{'avzone': 'us-east-2a', 'cluster': 'jumpyjackal'}], 'access': '', 'link': '', 'descriptionLink': '', 'depth': {'num_asks': 2, 'num_bids': 0, 'num_running': 0, 'asks': {'0xfBa03CcfDCA1822BfB65c647a985b9B7D8CE7415': 1}, 'asks_updated': '2023-11-30T20:11:23.071650666Z', 'gpus': {'': 0}, 'qps': 1.4, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'stats': [{'avzone': 'us-east-2a', 'cluster': 'jumpyjackal', 'capacity': 0.2685571309424521, 'qps': 1.4}]}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64e78eba589782acafe17820', 'name': 'togethercomputer/CodeLlama-13b-Instruct', 'display_name': 'Code Llama Instruct (13B)', 'display_type': 'chat', 'description': 'Code Llama is a family of large language models for code based on Llama 2 providing infilling capabilities, support for large input contexts, and zero-shot instruction following ability for programming tasks.', 'license': 'LLAMA 2 Community license Agreement (Meta)', 'creator_organization': 'Meta', 'hardware_label': 'A100 80GB', 'num_parameters': '13016028160', 'show_in_playground': True, 'finetuning_supported': True, 'isFeaturedModel': True, 'context_length': 8192, 'config': {'prompt_format': '[INST] {prompt} [/INST]', 'stop': ['</s>', '[INST]'], 'chat_template_name': 'llama'}, 'pricing': {'input': 56.25, 'output': 56.25, 'hourly': 0}, 'created_at': '2023-08-24T17:09:14.381Z', 'update_at': '2023-08-24T17:09:14.381Z', 'instances': [{'avzone': 'us-east-1a', 'cluster': 'happypiglet'}], 'access': '', 'link': '', 'descriptionLink': '', 'depth': {'num_asks': 3, 'num_bids': 1, 'num_running': 1, 'asks': {'0x9503fB851b50A1395D24F961dbEa14239D7FFb75': 1, '0xD7447A0a89a34EdA080357Bc9ffd71F339a6bAB3': 1}, 'asks_updated': '2023-11-30T20:36:58.728775483Z', 'gpus': {'': 0}, 'qps': 0, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'stats': [{'avzone': 'us-east-1a', 'cluster': 'happypiglet', 'capacity': 0.17857142857142855, 'qps': 0}]}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64e78eba589782acafe1781f', 'name': 'togethercomputer/CodeLlama-13b-Python', 'display_name': 'Code Llama Python (13B)', 'display_type': 'code', 'description': 'Code Llama is a family of large language models for code based on Llama 2 providing infilling capabilities, support for large input contexts, and zero-shot instruction following ability for programming tasks.', 'license': 'LLAMA 2 Community license Agreement (Meta)', 'creator_organization': 'Meta', 'hardware_label': 'A100 80GB', 'num_parameters': '13016028160', 'show_in_playground': True, 'finetuning_supported': True, 'isFeaturedModel': True, 'context_length': 8192, 'config': {'stop': ['</s>'], 'chat_template_name': 'llama'}, 'pricing': {'input': 56.25, 'output': 56.25, 'hourly': 0}, 'created_at': '2023-08-24T17:09:14.381Z', 'update_at': '2023-08-24T17:09:14.381Z', 'instances': [{'avzone': 'us-central-1a', 'cluster': 'sassyseal'}, {'avzone': 'us-east-1a', 'cluster': 'happypiglet'}], 'access': '', 'link': '', 'descriptionLink': '', 'depth': {'num_asks': 3, 'num_bids': 0, 'num_running': 0, 'asks': {'0x0fd44704EBaE5c6E7604bEd3b2FcA3A54e53a6C5': 1, '0x12aDF7E8EbA62640A9f48e8b148e95A84b90A44A': 1}, 'asks_updated': '2023-11-30T21:08:12.155034604Z', 'gpus': {'': 0}, 'qps': 0, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'stats': [{'avzone': 'us-central-1a', 'cluster': 'sassyseal', 'capacity': 0.14285714285714285, 'qps': 0}, {'avzone': 'us-east-1a', 'cluster': 'happypiglet', 'capacity': 0.14285714285714285, 'qps': 0}]}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64e78eba589782acafe1781e', 'name': 'togethercomputer/CodeLlama-13b', 'display_name': 'Code Llama (13B)', 'display_type': 'code', 'description': 'Code Llama is a family of large language models for code based on Llama 2 providing infilling capabilities, support for large input contexts, and zero-shot instruction following ability for programming tasks.', 'license': 'LLAMA 2 Community license Agreement (Meta)', 'creator_organization': 'Meta', 'hardware_label': 'A100 80GB', 'num_parameters': '13016028160', 'show_in_playground': True, 'finetuning_supported': True, 'isFeaturedModel': True, 'context_length': 8192, 'config': {'stop': ['</s>'], 'chat_template_name': 'llama'}, 'pricing': {'input': 56.25, 'output': 56.25, 'hourly': 0}, 'created_at': '2023-08-24T17:09:14.381Z', 'update_at': '2023-08-24T17:09:14.381Z', 'instances': [{'avzone': 'us-east-1a', 'cluster': 'happypiglet'}], 'access': '', 'link': '', 'descriptionLink': '', 'depth': {'num_asks': 2, 'num_bids': 0, 'num_running': 0, 'asks': {'0x8e1F3327B53B044D9c71A84b0506A77aE45511F6': 1}, 'asks_updated': '2023-11-30T21:11:53.411360677Z', 'gpus': {'': 0}, 'qps': 0, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'stats': [{'avzone': 'us-east-1a', 'cluster': 'happypiglet', 'capacity': 0.19047619047619047, 'qps': 0}]}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64e7934a589782acafe17823', 'name': 'togethercomputer/CodeLlama-34b-Instruct', 'display_name': 'Code Llama Instruct (34B)', 'display_type': 'chat', 'description': 'Code Llama is a family of large language models for code based on Llama 2 providing infilling capabilities, support for large input contexts, and zero-shot instruction following ability for programming tasks.', 'license': 'LLAMA 2 Community license Agreement (Meta)', 'creator_organization': 'Meta', 'hardware_label': 'A100 80GB', 'num_parameters': 34000000000, 'show_in_playground': True, 'isFeaturedModel': True, 'context_length': 8192, 'config': {'prompt_format': '[INST] {prompt} [/INST]', 'stop': ['</s>', '[INST]'], 'chat_template_name': 'llama'}, 'pricing': {'input': 200, 'output': 200, 'hourly': 0}, 'created_at': '2023-08-24T17:28:42.172Z', 'update_at': '2023-08-24T17:28:42.172Z', 'instances': [{'avzone': 'us-east-1a', 'cluster': 'happypiglet'}], 'access': '', 'link': '', 'descriptionLink': '', 'depth': {'num_asks': 4, 'num_bids': 1, 'num_running': 1, 'asks': {'0x40296D800102366b9Fe1085598BF6Ff66c9c5022': 1, '0x419C1B2BE24a9052ca50C97d6EB1E636F530b0C5': 1, '0xa4DcBF61a846056CF35fC50871CD5C5183aFA66B': 1}, 'asks_updated': '2023-11-30T20:45:02.686252325Z', 'gpus': {'': 0}, 'qps': 0.2, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'stats': [{'avzone': 'us-east-1a', 'cluster': 'happypiglet', 'capacity': 0.0681818181818182, 'qps': 0.2}]}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64e7934a589782acafe17822', 'name': 'togethercomputer/CodeLlama-34b-Python', 'display_name': 'Code Llama Python (34B)', 'display_type': 'code', 'description': 'Code Llama is a family of large language models for code based on Llama 2 providing infilling capabilities, support for large input contexts, and zero-shot instruction following ability for programming tasks.', 'license': 'LLAMA 2 Community license Agreement (Meta)', 'creator_organization': 'Meta', 'hardware_label': 'A100 80GB', 'num_parameters': 34000000000, 'show_in_playground': True, 'isFeaturedModel': True, 'context_length': 8192, 'config': {'stop': ['</s>'], 'chat_template_name': 'llama'}, 'pricing': {'input': 200, 'output': 200, 'hourly': 0}, 'created_at': '2023-08-24T17:28:42.172Z', 'update_at': '2023-08-24T17:28:42.172Z', 'instances': [{'avzone': 'us-east-1a', 'cluster': 'happypiglet'}], 'access': '', 'link': '', 'descriptionLink': '', 'depth': {'num_asks': 2, 'num_bids': 0, 'num_running': 0, 'asks': {'0xaD8115f5949C5729Ca840D12CCd000986EAE1d98': 1}, 'asks_updated': '2023-11-30T20:03:05.635534419Z', 'gpus': {'': 0}, 'qps': 0, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'stats': [{'avzone': 'us-east-1a', 'cluster': 'happypiglet', 'capacity': 0.06666666666666667, 'qps': 0}]}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64e7934a589782acafe17821', 'name': 'togethercomputer/CodeLlama-34b', 'display_name': 'Code Llama (34B)', 'display_type': 'code', 'description': 'Code Llama is a family of large language models for code based on Llama 2 providing infilling capabilities, support for large input contexts, and zero-shot instruction following ability for programming tasks.', 'license': 'LLAMA 2 Community license Agreement (Meta)', 'creator_organization': 'Meta', 'hardware_label': 'A100 80GB', 'num_parameters': 34000000000, 'show_in_playground': True, 'isFeaturedModel': True, 'context_length': 8192, 'config': {'stop': ['</s>'], 'chat_template_name': 'llama'}, 'pricing': {'input': 200, 'output': 200, 'hourly': 0}, 'created_at': '2023-08-24T17:28:42.172Z', 'update_at': '2023-08-24T17:28:42.172Z', 'instances': [{'avzone': 'us-east-1a', 'cluster': 'happypiglet'}], 'access': '', 'link': '', 'descriptionLink': '', 'depth': {'num_asks': 2, 'num_bids': 0, 'num_running': 0, 'asks': {'0xb9904738F08BdFA268cdD6C22029C924075c32f5': 1}, 'asks_updated': '2023-11-30T18:20:44.196528879Z', 'gpus': {'': 0}, 'qps': 0, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'stats': [{'avzone': 'us-east-1a', 'cluster': 'happypiglet', 'capacity': 0.06666666666666667, 'qps': 0}]}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64e78e89589782acafe1781d', 'name': 'togethercomputer/CodeLlama-7b-Instruct', 'display_name': 'Code Llama Instruct (7B)', 'display_type': 'chat', 'description': 'Code Llama is a family of large language models for code based on Llama 2 providing infilling capabilities, support for large input contexts, and zero-shot instruction following ability for programming tasks.', 'license': 'LLAMA 2 Community license Agreement (Meta)', 'creator_organization': 'Meta', 'hardware_label': 'A100 80GB', 'num_parameters': '6738546688', 'show_in_playground': True, 'finetuning_supported': True, 'isFeaturedModel': True, 'context_length': 8192, 'config': {'prompt_format': '[INST] {prompt} [/INST]', 'stop': ['</s>', '[INST]'], 'chat_template_name': 'llama'}, 'pricing': {'input': 50, 'output': 50, 'hourly': 0}, 'created_at': '2023-08-24T17:08:25.379Z', 'update_at': '2023-08-24T17:08:25.379Z', 'access': '', 'link': '', 'descriptionLink': '', 'depth': {'num_asks': 4, 'num_bids': 2, 'num_running': 2, 'asks': {'0x4394c63F1239626B62dCd57055B1cC6C8838A873': 3, '0x5216d6CA97cACeD33b1090433fEb1e83886406C2': 1}, 'asks_updated': '2023-11-30T18:39:47.9536506Z', 'gpus': {'': 0}, 'qps': 0.095403776, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'throughput_in': 80.03227, 'throughput_out': 31.102757}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64e78e89589782acafe1781c', 'name': 'togethercomputer/CodeLlama-7b-Python', 'display_name': 'Code Llama Python (7B)', 'display_type': 'code', 'description': 'Code Llama is a family of large language models for code based on Llama 2 providing infilling capabilities, support for large input contexts, and zero-shot instruction following ability for programming tasks.', 'license': 'LLAMA 2 Community license Agreement (Meta)', 'creator_organization': 'Meta', 'hardware_label': 'A100 80GB', 'num_parameters': '6738546688', 'show_in_playground': True, 'finetuning_supported': True, 'isFeaturedModel': True, 'context_length': 8192, 'config': {'stop': ['</s>'], 'chat_template_name': 'llama'}, 'pricing': {'input': 50, 'output': 50, 'hourly': 0}, 'created_at': '2023-08-24T17:08:25.379Z', 'update_at': '2023-08-24T17:08:25.379Z', 'access': '', 'link': '', 'descriptionLink': '', 'depth': {'num_asks': 2, 'num_bids': 0, 'num_running': 0, 'asks': {'0x3e1FDd24eAdC6dA6F24b672E995bB58B2Ba9ACc7': 1, '0x8ff44C68db56E66E200C6a7a51740d09D18Cd93b': 1}, 'asks_updated': '2023-11-30T19:13:03.370031146Z', 'gpus': {'': 0}, 'qps': 0.0348777, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'throughput_in': 0.5454187, 'throughput_out': 5.2436385}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64e78e89589782acafe1781b', 'name': 'togethercomputer/CodeLlama-7b', 'display_name': 'Code Llama (7B)', 'display_type': 'code', 'description': 'Code Llama is a family of large language models for code based on Llama 2 providing infilling capabilities, support for large input contexts, and zero-shot instruction following ability for programming tasks.', 'license': 'LLAMA 2 Community license Agreement (Meta)', 'creator_organization': 'Meta', 'hardware_label': 'A100 80GB', 'num_parameters': '6738546688', 'show_in_playground': True, 'finetuning_supported': True, 'isFeaturedModel': True, 'context_length': 8192, 'config': {'stop': ['</s>'], 'chat_template_name': 'llama'}, 'pricing': {'input': 50, 'output': 50, 'hourly': 0}, 'created_at': '2023-08-24T17:08:25.379Z', 'update_at': '2023-08-24T17:08:25.379Z', 'access': '', 'link': '', 'descriptionLink': '', 'depth': {'num_asks': 2, 'num_bids': 0, 'num_running': 0, 'asks': {'0x06F3a0760639A6514e65080b526108DD5FdA491E': 1, '0x2529004E1F328c64aefE70d0a78BC636f9a10C67': 1}, 'asks_updated': '2023-11-30T21:06:49.47924953Z', 'gpus': {'': 0}, 'qps': 0.033905387, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'throughput_in': 0.6247982, 'throughput_out': 1.8257746}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '6495ff1312907e072b8aece2', 'name': 'togethercomputer/GPT-JT-6B-v1', 'display_name': 'GPT-JT (6B)', 'display_type': 'language', 'description': 'Fork of GPT-J instruction tuned to excel at few-shot prompts (blog post).', 'descriptionLink': 'https://www.together.xyz/blog/releasing-v1-of-gpt-jt-powered-by-open-source-ai', 'license': 'apache-2.0', 'link': 'https://huggingface.co/togethercomputer/GPT-JT-6B-v1', 'creator_organization': 'Together', 'hardware_label': 'A40 48GB', 'pricing_tier': 'featured', 'access': 'open', 'num_parameters': 6700000000, 'release_date': '2022-11-29T00:00:00.000Z', 'show_in_playground': True, 'isFeaturedModel': True, 'context_length': 2048, 'config': {'chat_template_name': 'gpt'}, 'pricing': {'input': 50, 'output': 50, 'hourly': 0}, 'created_at': '2023-06-23T20:22:43.617Z', 'update_at': '2023-06-23T20:22:43.617Z', 'depth': {'num_asks': 2, 'num_bids': 0, 'num_running': 0, 'asks': {'0x347ed480e16d8df64575Af1b19A9bb84fA787149': 1, '0x825c2eEAf8e191c9c65D333F6e97C91b3459F06C': 1}, 'asks_updated': '2023-11-30T21:05:28.250966409Z', 'gpus': {'': 0}, 'qps': 0.024496254, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'throughput_in': 0.75152045, 'throughput_out': 2.8978028}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '6495ff1312907e072b8aece3', 'name': 'togethercomputer/GPT-JT-Moderation-6B', 'display_name': 'GPT-JT-Moderation (6B)', 'display_type': 'language', 'description': \"This model can be used to moderate other chatbot models. Built using GPT-JT model fine-tuned on Ontocord.ai's OIG-moderation dataset v0.1.\", 'license': 'apache-2.0', 'link': 'https://huggingface.co/togethercomputer/GPT-JT-Moderation-6B', 'creator_organization': 'Together', 'hardware_label': 'A40 48GB', 'pricing_tier': 'featured', 'access': 'open', 'num_parameters': 6700000000, 'show_in_playground': True, 'isFeaturedModel': True, 'context_length': 2048, 'config': {'chat_template_name': 'gpt'}, 'pricing': {'input': 50, 'output': 50, 'hourly': 0}, 'created_at': '2023-06-23T20:22:43.657Z', 'update_at': '2023-06-23T20:22:43.657Z', 'descriptionLink': '', 'depth': {'num_asks': 2, 'num_bids': 0, 'num_running': 0, 'asks': {'0x6ab061898c6c0b6E7595BFa12c7d3F410a79D480': 1, '0xfDb481fb1949C07e4096111E92C426821516AC67': 1}, 'asks_updated': '2023-11-30T20:19:49.322788399Z', 'gpus': {'NVIDIA A100 80GB PCIe': 2}, 'qps': 0.03556686, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'throughput_in': 0.71972364, 'throughput_out': 4.0413117}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '6495ff1312907e072b8aece4', 'name': 'togethercomputer/GPT-NeoXT-Chat-Base-20B', 'display_name': 'GPT-NeoXT-Chat-Base (20B)', 'display_type': 'chat', 'description': 'Chat model fine-tuned from EleutherAIs GPT-NeoX with over 40 million instructions on carbon reduced compute.', 'license': 'apache-2.0', 'link': 'https://huggingface.co/togethercomputer/GPT-NeoXT-Chat-Base-20B', 'creator_organization': 'Together', 'hardware_label': 'A40 48GB', 'pricing_tier': 'featured', 'access': 'open', 'num_parameters': 20000000000, 'show_in_playground': True, 'isFeaturedModel': True, 'context_length': 2048, 'config': {'prompt_format': '<human>: {prompt}\\n<bot>:', 'stop': ['<human>'], 'chat_template_name': 'gpt'}, 'max_tokens': 995, 'pricing': {'input': 75, 'output': 75, 'hourly': 0}, 'created_at': '2023-06-23T20:22:43.702Z', 'update_at': '2023-06-23T20:22:43.702Z', 'descriptionLink': '', 'depth': {'num_asks': 2, 'num_bids': 0, 'num_running': 0, 'asks': {'0x0648b3363589FE937639A018781Ea6A1367AeDA3': 1, '0xF336AF86FBFf5dc323F0964f2DF9C8fE9ce804DB': 1}, 'asks_updated': '2023-11-30T20:47:20.752154364Z', 'gpus': {'': 0}, 'qps': 0.02712019, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'throughput_in': 0.49966508, 'throughput_out': 1.4104111}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64c28e8742fa06a9511509d1', 'name': 'togethercomputer/LLaMA-2-7B-32K', 'display_name': 'LLaMA-2-32K (7B)', 'display_type': 'language', 'description': \"Extending LLaMA-2 to 32K context, built with Meta's Position Interpolation and Together AI's data recipe and system optimizations.\", 'license': 'Meta license', 'link': 'https://huggingface.co/togethercomputer/LLaMA-2-7B-32K', 'creator_organization': 'Together', 'hardware_label': '2x A100 80GB', 'pricing_tier': 'supported', 'access': 'open', 'num_parameters': '6738415616', 'show_in_playground': True, 'finetuning_supported': True, 'isFeaturedModel': True, 'context_length': 32768, 'config': {'stop': ['\\n\\n\\n\\n', '<|endoftext|>'], 'chat_template_name': 'llama'}, 'pricing': {'input': 50, 'output': 50, 'hourly': 0}, 'created_at': '2023-07-27T15:34:31.581Z', 'update_at': '2023-08-17T17:07:36.346Z', 'descriptionLink': '', 'depth': {'num_asks': 2, 'num_bids': 0, 'num_running': 0, 'asks': {'0x5e4d8140190F6b1A6098e20Faf53CE2912f86e24': 1, '0x9DA91a58b69ECa0080221784A1B037648d03c73F': 1}, 'asks_updated': '2023-11-30T20:51:04.307050085Z', 'gpus': {'': 0}, 'qps': 0.028623726, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'throughput_in': 0.54329646, 'throughput_out': 0.9703029}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64de96090d052d10425df3c9', 'name': 'togethercomputer/Llama-2-7B-32K-Instruct', 'display_name': 'LLaMA-2-7B-32K-Instruct (7B)', 'display_type': 'chat', 'description': \"Extending LLaMA-2 to 32K context, built with Meta's Position Interpolation and Together AI's data recipe and system optimizations, instruction tuned by Together\", 'license': 'Meta license', 'creator_organization': 'Together', 'hardware_label': '2X A100 80GB', 'pricing_tier': 'supported', 'num_parameters': 7000000000, 'show_in_playground': True, 'finetuning_supported': True, 'isFeaturedModel': True, 'context_length': 32768, 'config': {'prompt_format': '[INST]\\n {prompt} \\n[/INST]\\n\\n', 'stop': ['[INST]', '\\n\\n'], 'chat_template_name': 'llama'}, 'pricing': {'input': 50, 'output': 50, 'hourly': 0}, 'access': '', 'link': '', 'descriptionLink': '', 'depth': {'num_asks': 4, 'num_bids': 1, 'num_running': 1, 'asks': {'0x3D6eD2De2148B00b96C37C646E4Aaa5a51de6768': 1, '0x3c82375Cbb63c659Ae960Aaa7b92434b34C3F455': 2, '0x6a3aB552e8841502c2f1Db37287503Cb9d6ADf05': 1}, 'asks_updated': '2023-11-30T20:33:51.261066704Z', 'gpus': {'': 0}, 'qps': 0.02202476, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'throughput_in': 0.3519281, 'throughput_out': 1.5456473}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '6495ff1412907e072b8aecee', 'name': 'togethercomputer/Pythia-Chat-Base-7B-v0.16', 'display_name': 'Pythia-Chat-Base (7B)', 'display_type': 'chat', 'description': 'Chat model based on EleutherAIs Pythia-7B model, and is fine-tuned with data focusing on dialog-style interactions.', 'license': 'apache-2.0', 'creator_organization': 'Together', 'hardware_label': 'A40 48GB', 'pricing_tier': 'featured', 'access': 'open', 'num_parameters': 7000000000, 'show_in_playground': True, 'finetuning_supported': True, 'isFeaturedModel': True, 'context_length': 2048, 'config': {'prompt_format': '<human>: {prompt}\\n<bot>:', 'stop': ['<human>'], 'chat_template_name': 'gpt'}, 'pricing': {'input': 50, 'output': 50, 'hourly': 0}, 'created_at': '2023-06-23T20:22:44.251Z', 'update_at': '2023-06-23T20:22:44.251Z', 'link': '', 'descriptionLink': '', 'depth': {'num_asks': 1, 'num_bids': 0, 'num_running': 0, 'asks': {'0x42899d444e0669B867ECa64983143469F097D9c5': 1}, 'asks_updated': '2023-11-30T20:58:52.947635553Z', 'gpus': {'': 0}, 'qps': 0.033278313, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'throughput_in': 0.67828155, 'throughput_out': 1.0539014}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64efd5511b76196fc5a54872', 'name': 'togethercomputer/Qwen-7B-Chat', 'display_name': 'Qwen-Chat (7B)', 'display_type': 'chat', 'description': '7B-parameter version of the large language model series, Qwen (abbr. Tongyi Qianwen), proposed by Aibaba Cloud. Qwen-7B-Chat is a large-model-based AI assistant, which is trained with alignment techniques.\\xa0 \\xa0', 'license': 'Tongyi Qianwen LICENSE AGREEMENT', 'creator_organization': 'Qwen', 'hardware_label': '1x A100 80GB', 'num_parameters': 7000000000, 'release_date': '2023-08-01T00:00:00.000Z', 'show_in_playground': True, 'isFeaturedModel': True, 'context_length': 8192, 'config': {'stop': ['<|im_end|>', '<|im_start|>'], 'prompt_format': '\\n<|im_start|>user\\n{prompt}<|im_end|>\\n<|im_start|>assistant\\n', 'add_generation_prompt': True, 'chat_template_name': 'default'}, 'pricing': {'input': 50, 'output': 50, 'hourly': 0}, 'created_at': '2023-08-30T23:48:33.852Z', 'update_at': '2023-09-07T01:49:42.840Z', 'access': '', 'link': '', 'descriptionLink': '', 'depth': {'num_asks': 3, 'num_bids': 2, 'num_running': 2, 'asks': {'0x3A30F87675923F5dE4d7468Ef492015CC6a862c7': 3}, 'asks_updated': '2023-11-30T21:00:33.009126122Z', 'gpus': {'': 0}, 'qps': 0.022062685, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'throughput_in': 0.3530283, 'throughput_out': 2.5770352}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64efcc2a1b76196fc5a54870', 'name': 'togethercomputer/Qwen-7B', 'display_name': 'Qwen (7B)', 'display_type': 'language', 'description': '7B-parameter version of the large language model series, Qwen (abbr. Tongyi Qianwen), proposed by Aibaba Cloud. Qwen-7B is a Transformer-based large language model, which is pretrained on a large volume of data, including web texts, books, codes, etc.\\xa0', 'license': 'Tongyi Qianwen LICENSE AGREEMENT', 'creator_organization': 'Qwen', 'hardware_label': '1x A100 80GB', 'num_parameters': 7000000000, 'release_date': '2023-08-01T00:00:00.000Z', 'show_in_playground': True, 'isFeaturedModel': True, 'context_length': 8192, 'config': {'stop': ['<|im_end|>', '<|endoftext|>'], 'add_generation_prompt': True, 'chat_template_name': 'default'}, 'pricing': {'input': 50, 'output': 50, 'hourly': 0}, 'created_at': '2023-08-30T23:09:30.570Z', 'update_at': '2023-09-07T01:49:24.716Z', 'access': '', 'link': '', 'descriptionLink': '', 'depth': {'num_asks': 3, 'num_bids': 2, 'num_running': 2, 'asks': {'0x3b8A3B15fBa1c9528653acBA88C329baE2a5a43D': 3}, 'asks_updated': '2023-11-30T20:35:22.946360092Z', 'gpus': {'': 0}, 'qps': 0.024937099, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'throughput_in': 0.43638426, 'throughput_out': 1.5966041}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '6495ff1412907e072b8aeceb', 'name': 'togethercomputer/RedPajama-INCITE-7B-Base', 'display_name': 'RedPajama-INCITE (7B)', 'display_type': 'language', 'description': 'Base model that aims to replicate the LLaMA recipe as closely as possible (blog post).', 'descriptionLink': 'https://www.together.xyz/blog/redpajama-models-v1', 'license': 'apache-2.0', 'link': 'https://huggingface.co/togethercomputer/RedPajama-INCITE-7B-Base', 'creator_organization': 'Together', 'hardware_label': 'A40 48GB', 'pricing_tier': 'featured', 'access': 'open', 'num_parameters': '6857302016', 'show_in_playground': True, 'finetuning_supported': True, 'isFeaturedModel': True, 'context_length': 2048, 'config': {'chat_template_name': 'gpt'}, 'pricing': {'input': 50, 'output': 50, 'hourly': 0}, 'created_at': '2023-06-23T20:22:44.033Z', 'update_at': '2023-06-23T20:22:44.033Z', 'depth': {'num_asks': 2, 'num_bids': 0, 'num_running': 0, 'asks': {'0x7c7007A3ffF953bA357CF3eeF853DD8613B07209': 1, '0xa5c71572Cfa868Ef8616Bb33FccB05B49dA88d8B': 1}, 'asks_updated': '2023-11-30T19:35:28.992680314Z', 'gpus': {'': 0}, 'qps': 0.024796637, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'throughput_in': 0.43231082, 'throughput_out': 0.8073162}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '6495ff1412907e072b8aeced', 'name': 'togethercomputer/RedPajama-INCITE-7B-Chat', 'display_name': 'RedPajama-INCITE Chat (7B)', 'display_type': 'chat', 'description': 'Chat model fine-tuned using data from Dolly 2.0 and Open Assistant over the RedPajama-INCITE-Base-7B-v1 base model.', 'license': 'apache-2.0', 'link': 'https://huggingface.co/togethercomputer/RedPajama-INCITE-7B-Chat', 'creator_organization': 'Together', 'hardware_label': 'A100 80GB', 'pricing_tier': 'featured', 'access': 'open', 'num_parameters': '6857302016', 'show_in_playground': True, 'finetuning_supported': True, 'isFeaturedModel': True, 'context_length': 2048, 'config': {'prompt_format': '<human>: {prompt}\\n<bot>:', 'stop': ['<human>'], 'chat_template_name': 'gpt'}, 'pricing': {'input': 50, 'output': 50, 'hourly': 0}, 'created_at': '2023-06-23T20:22:44.190Z', 'update_at': '2023-06-23T20:22:44.190Z', 'descriptionLink': '', 'depth': {'num_asks': 2, 'num_bids': 0, 'num_running': 0, 'asks': {'0xcC9323401A6f39efd3C5fc8bFAc74D7b512abd69': 1, '0xd21D8158D6065D9D38d68DEAcd5946F228499b16': 1}, 'asks_updated': '2023-11-30T20:22:40.941537739Z', 'gpus': {'': 0}, 'qps': 0.035190415, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'throughput_in': 0.7337324, 'throughput_out': 1.4313009}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '6495ff1412907e072b8aecec', 'name': 'togethercomputer/RedPajama-INCITE-7B-Instruct', 'display_name': 'RedPajama-INCITE Instruct (7B)', 'display_type': 'language', 'description': 'Designed for few-shot prompts, fine-tuned over the RedPajama-INCITE-Base-7B-v1 base model.', 'license': 'apache-2.0', 'link': 'https://huggingface.co/togethercomputer/RedPajama-INCITE-7B-Instruct', 'creator_organization': 'Together', 'hardware_label': 'A100 80GB', 'pricing_tier': 'featured', 'access': 'open', 'num_parameters': '6857302016', 'show_in_playground': True, 'finetuning_supported': True, 'isFeaturedModel': True, 'context_length': 2048, 'config': {'chat_template_name': 'gpt'}, 'pricing': {'input': 50, 'output': 50, 'hourly': 0}, 'created_at': '2023-06-23T20:22:44.083Z', 'update_at': '2023-06-23T20:22:44.083Z', 'descriptionLink': '', 'depth': {'num_asks': 2, 'num_bids': 0, 'num_running': 0, 'asks': {'0x30D9d6EaFcA72F8913A8661450722E512bD06a9F': 1, '0xF68F3AfE6f0e6a29A16CB73cFB3BEb86E88Df043': 1}, 'asks_updated': '2023-11-30T21:00:03.760092555Z', 'gpus': {'': 0}, 'qps': 0.030103829, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'throughput_in': 0.68970174, 'throughput_out': 4.3015447}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '6495ff1312907e072b8aece5', 'name': 'togethercomputer/RedPajama-INCITE-Base-3B-v1', 'display_name': 'RedPajama-INCITE (3B)', 'display_type': 'language', 'description': 'Base model that aims to replicate the LLaMA recipe as closely as possible (blog post).', 'descriptionLink': 'https://www.together.xyz/blog/redpajama-models-v1', 'license': 'apache-2.0', 'link': 'https://huggingface.co/togethercomputer/RedPajama-INCITE-Base-3B-v1', 'creator_organization': 'Together', 'hardware_label': 'A40 48GB', 'pricing_tier': 'featured', 'access': 'open', 'num_parameters': '2775864320', 'show_in_playground': True, 'finetuning_supported': True, 'isFeaturedModel': True, 'context_length': 2048, 'config': {'chat_template_name': 'gpt'}, 'pricing': {'input': 25, 'output': 25, 'hourly': 0}, 'created_at': '2023-06-23T20:22:43.751Z', 'update_at': '2023-06-23T20:22:43.751Z', 'depth': {'num_asks': 2, 'num_bids': 0, 'num_running': 0, 'asks': {'0x0aBe21E3ca185164261ef34A239C247300ac8443': 1, '0x930312eb45cEDC07Ca1cFFf399e46693e1f6b0B9': 1}, 'asks_updated': '2023-11-30T19:17:41.662092493Z', 'gpus': {'': 0}, 'qps': 0.022620702, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'throughput_in': 0.36920875, 'throughput_out': 0.5320296}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '6495ff1312907e072b8aece7', 'name': 'togethercomputer/RedPajama-INCITE-Chat-3B-v1', 'display_name': 'RedPajama-INCITE Chat (3B)', 'display_type': 'chat', 'description': 'Chat model fine-tuned using data from Dolly 2.0 and Open Assistant over the RedPajama-INCITE-Base-3B-v1 base model.', 'license': 'apache-2.0', 'link': 'https://huggingface.co/togethercomputer/RedPajama-INCITE-Chat-3B-v1', 'creator_organization': 'Together', 'hardware_label': 'A40 48GB', 'pricing_tier': 'featured', 'access': 'open', 'num_parameters': '2775864320', 'show_in_playground': True, 'finetuning_supported': True, 'isFeaturedModel': True, 'context_length': 2048, 'config': {'prompt_format': '<human>: {prompt}\\n<bot>:', 'stop': ['<human>'], 'chat_template_name': 'gpt'}, 'pricing': {'input': 25, 'output': 25, 'hourly': 0}, 'created_at': '2023-06-23T20:22:43.839Z', 'update_at': '2023-06-23T20:22:43.839Z', 'descriptionLink': '', 'depth': {'num_asks': 2, 'num_bids': 0, 'num_running': 0, 'asks': {'0x314e601Ca3c385ade582C39Ea568fc5F93024899': 1, '0xE5CdaceFC11371aF54F4CEa9B825E299605fC0DB': 1}, 'asks_updated': '2023-11-30T20:12:36.690075085Z', 'gpus': {'': 0}, 'qps': 0.03143822, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'throughput_in': 0.6249188, 'throughput_out': 1.8960631}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '6495ff1312907e072b8aece6', 'name': 'togethercomputer/RedPajama-INCITE-Instruct-3B-v1', 'display_name': 'RedPajama-INCITE Instruct (3B)', 'display_type': 'language', 'description': 'Designed for few-shot prompts, fine-tuned over the RedPajama-INCITE-Base-3B-v1 base model.', 'license': 'apache-2.0', 'link': 'https://huggingface.co/togethercomputer/RedPajama-INCITE-Instruct-3B-v1', 'creator_organization': 'Together', 'hardware_label': 'A40 48GB', 'pricing_tier': 'featured', 'access': 'open', 'num_parameters': '2775864320', 'show_in_playground': True, 'finetuning_supported': True, 'isFeaturedModel': True, 'context_length': 2048, 'config': {'chat_template_name': 'gpt'}, 'pricing': {'input': 25, 'output': 25, 'hourly': 0}, 'created_at': '2023-06-23T20:22:43.796Z', 'update_at': '2023-06-23T20:22:43.796Z', 'descriptionLink': '', 'depth': {'num_asks': 2, 'num_bids': 0, 'num_running': 0, 'asks': {'0x9212cc97439F70f4a4611c5D93F37087d5DF111b': 1, '0xc627592f6023D78F544e7D643e5aF32c055EEA9D': 1}, 'asks_updated': '2023-11-30T21:10:32.653302665Z', 'gpus': {'': 0}, 'qps': 0.024931053, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'throughput_in': 0.4362089, 'throughput_out': 1.012691}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64ace317227f790586239ce2', 'name': 'togethercomputer/alpaca-7b', 'display_name': 'Alpaca (7B)', 'display_type': 'chat', 'description': 'Fine-tuned from the LLaMA 7B model on 52K instruction-following demonstrations. ', 'license': 'cc-by-nc-4.0', 'link': 'https://huggingface.co/tatsu-lab/alpaca-7b-wdiff', 'creator_organization': 'Stanford', 'hardware_label': 'A40 48GB', 'pricing_tier': 'supported', 'access': 'open', 'num_parameters': 7000000000, 'show_in_playground': True, 'isFeaturedModel': True, 'context_length': 2048, 'config': {'stop': ['</s>', '###'], 'prompt_format': '### Instruction:\\n{prompt}\\n### Response:\\n', 'chat_template': \"{% for message in messages %}{% if message['role'] == 'user' %}{{ '### Instruction:\\n' + message['content'] + '\\n' }}{% else %}{{ '### Response:\\n' + message['content'] + '\\n' }}{% endif %}{% endfor %}{{ '### Response:\\n' }}\"}, 'pricing': {'input': 50, 'output': 50, 'hourly': 0}, 'created_at': '2023-07-11T05:05:27.713Z', 'update_at': '2023-07-11T05:05:27.713Z', 'descriptionLink': '', 'depth': {'num_asks': 1, 'num_bids': 0, 'num_running': 0, 'asks': {'0x4174A3c81710BCd6C43b1F8e8f8a91B1137Baf55': 1}, 'asks_updated': '2023-11-30T18:49:28.612295866Z', 'gpus': {'': 0}, 'qps': 0.027270943, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'throughput_in': 0.50406694, 'throughput_out': 1.3554901}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64ace614227f790586239cf7', 'name': 'togethercomputer/falcon-40b-instruct', 'display_name': 'Falcon Instruct (40B)', 'display_type': 'chat', 'description': 'Falcon-40B-Instruct is a causal decoder-only model built by TII based on Falcon-40B and finetuned on a mixture of Baize. ', 'license': 'apache-2.0', 'link': 'https://huggingface.co/tiiuae/falcon-40b-instruct', 'creator_organization': 'TII UAE', 'hardware_label': '2X A40 48GB', 'pricing_tier': 'supported', 'access': 'open', 'num_parameters': 40000000000, 'show_in_playground': True, 'isFeaturedModel': True, 'context_length': 2048, 'config': {'prompt_format': 'User: {prompt}\\nAssistant:', 'stop': ['User:', '</s>'], 'chat_template_name': 'default'}, 'pricing': {'input': 200, 'output': 200, 'hourly': 0}, 'created_at': '2023-07-11T05:18:12.323Z', 'update_at': '2023-07-11T05:18:12.323Z', 'descriptionLink': '', 'depth': {'num_asks': 1, 'num_bids': 0, 'num_running': 0, 'asks': {'0x0b5481F80C5DEe44b73CC49BA6091F6245545716': 1}, 'asks_updated': '2023-11-30T21:07:01.047492377Z', 'gpus': {'': 0}, 'qps': 0.022826035, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'throughput_in': 0.37635365, 'throughput_out': 1.5828124}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64ace59f227f790586239cf5', 'name': 'togethercomputer/falcon-40b', 'display_name': 'Falcon (40B)', 'display_type': 'language', 'description': 'Falcon-40B is a causal decoder-only model built by TII and trained on 1,000B tokens of RefinedWeb enhanced with curated corpora.', 'license': 'apache-2.0', 'link': 'https://huggingface.co/tiiuae/falcon-40b', 'creator_organization': 'TII UAE', 'hardware_label': '2X A40 48GB', 'pricing_tier': 'supported', 'access': 'open', 'num_parameters': 40000000000, 'show_in_playground': True, 'isFeaturedModel': True, 'context_length': 2048, 'config': {'stop': ['<|endoftext|>'], 'chat_template_name': 'default'}, 'pricing': {'input': 200, 'output': 200, 'hourly': 0}, 'created_at': '2023-07-11T05:16:15.898Z', 'update_at': '2023-07-11T05:16:15.898Z', 'descriptionLink': '', 'depth': {'num_asks': 1, 'num_bids': 0, 'num_running': 0, 'asks': {'0x42C59dDFA7fEF158a7d11a675317669893CE0EbC': 1}, 'asks_updated': '2023-11-30T20:50:51.823991516Z', 'gpus': {'': 0}, 'qps': 0.0247777, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'throughput_in': 0.43176138, 'throughput_out': 0.7145751}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64ace63d227f790586239cf8', 'name': 'togethercomputer/falcon-7b-instruct', 'display_name': 'Falcon Instruct (7B)', 'display_type': 'chat', 'description': 'Casual decoder-only model built by TII based on Falcon-7B and finetuned on a mixture of chat/instruct datasets. ', 'license': 'apache-2.0', 'link': 'https://huggingface.co/tiiuae/falcon-7b-instruct', 'creator_organization': 'TII UAE', 'hardware_label': 'A40 48GB', 'pricing_tier': 'featured', 'access': 'open', 'num_parameters': 7000000000, 'show_in_playground': True, 'isFeaturedModel': True, 'context_length': 2048, 'config': {'prompt_format': 'User: {prompt}\\nAssistant:', 'stop': ['User:', '</s>'], 'chat_template_name': 'default'}, 'pricing': {'input': 50, 'output': 50, 'hourly': 0}, 'created_at': '2023-07-11T05:18:53.623Z', 'update_at': '2023-07-11T05:18:53.623Z', 'descriptionLink': '', 'depth': {'num_asks': 1, 'num_bids': 0, 'num_running': 0, 'asks': {'0x2b665036860161c962147A49c5Baf87CFbFC6c4b': 1}, 'asks_updated': '2023-11-30T21:03:29.912106569Z', 'gpus': {'': 0}, 'qps': 0.021254407, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'throughput_in': 0.3295876, 'throughput_out': 1.0607077}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64ace5dd227f790586239cf6', 'name': 'togethercomputer/falcon-7b', 'display_name': 'Falcon (7B)', 'display_type': 'language', 'description': 'Causal decoder-only model built by TII and trained on 1,500B tokens of RefinedWeb enhanced with curated corpora.', 'license': 'apache-2.0', 'link': 'https://huggingface.co/tiiuae/falcon-7b', 'creator_organization': 'TII UAE', 'hardware_label': 'A40 48GB', 'pricing_tier': 'featured', 'access': 'open', 'num_parameters': 7000000000, 'show_in_playground': True, 'isFeaturedModel': True, 'context_length': 2048, 'config': {'stop': ['<|endoftext|>'], 'chat_template_name': 'default'}, 'pricing': {'input': 50, 'output': 50, 'hourly': 0}, 'created_at': '2023-07-11T05:17:17.883Z', 'update_at': '2023-07-11T05:17:17.883Z', 'descriptionLink': '', 'depth': {'num_asks': 1, 'num_bids': 0, 'num_running': 0, 'asks': {'0xeA9aAE19f2f4423f83eBF38571Cc6F4BC990174d': 1}, 'asks_updated': '2023-11-30T21:07:56.929255158Z', 'gpus': {'': 0}, 'qps': 0.030003719, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'throughput_in': 0.58331597, 'throughput_out': 1.3435571}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64b7165fcccc52103e2f07e8', 'name': 'togethercomputer/llama-2-13b-chat', 'display_name': 'LLaMA-2 Chat (13B)', 'display_type': 'chat', 'description': 'Llama 2-chat leverages publicly available instruction datasets and over 1 million human annotations. Available in three sizes: 7B, 13B and 70B parameters', 'license': 'LLaMA license Agreement (Meta)', 'link': 'https://huggingface.co/togethercomputer/llama-2-13b-chat', 'creator_organization': 'Meta', 'hardware_label': '2X A100 80GB', 'pricing_tier': 'Featured', 'access': 'open', 'num_parameters': '13015864320', 'show_in_playground': True, 'finetuning_supported': True, 'isFeaturedModel': True, 'context_length': 4096, 'config': {'prompt_format': '[INST] {prompt} [/INST]', 'stop': ['[/INST]', '</s>'], 'chat_template_name': 'llama'}, 'pricing': {'input': 56.25, 'output': 56.25, 'hourly': 0}, 'created_at': '2023-07-18T22:46:55.042Z', 'update_at': '2023-07-18T22:46:55.042Z', 'instances': [{'avzone': 'us-east-1a', 'cluster': 'happypiglet'}], 'descriptionLink': '', 'depth': {'num_asks': 5, 'num_bids': 0, 'num_running': 0, 'asks': {'0x5Da09CD1EdF3e771B8F781AA61c24d58Ad818C25': 1, '0xB55115d37767D2e3CDe83c29EF363ca0e36912bB': 1, '0xB5Cc7Af02C5aE6eAEF91b98EedFF46e654628720': 1, '0xE4fec5B651a66255Cace2F5Dee048AEC80b32dfe': 1}, 'asks_updated': '2023-11-30T20:37:33.686496441Z', 'gpus': {'': 0}, 'qps': 0.8, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'stats': [{'avzone': 'us-east-1a', 'cluster': 'happypiglet', 'capacity': 0.02820512820512822, 'qps': 0.8}]}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64b7165fcccc52103e2f07e7', 'name': 'togethercomputer/llama-2-13b', 'display_name': 'LLaMA-2 (13B)', 'display_type': 'language', 'description': 'Language model trained on 2 trillion tokens with double the context length of Llama 1. Available in three sizes: 7B, 13B and 70B parameters', 'license': 'LLaMA license Agreement (Meta)', 'link': 'https://huggingface.co/togethercomputer/llama-2-13b', 'creator_organization': 'Meta', 'hardware_label': '2X A100 80GB', 'pricing_tier': 'Featured', 'access': 'open', 'num_parameters': '13015864320', 'show_in_playground': True, 'finetuning_supported': True, 'isFeaturedModel': True, 'context_length': 4096, 'config': {'chat_template_name': 'llama'}, 'pricing': {'input': 56.25, 'output': 56.25, 'hourly': 0}, 'created_at': '2023-07-18T22:46:55.042Z', 'update_at': '2023-07-18T22:46:55.042Z', 'instances': [{'avzone': 'us-east-1a', 'cluster': 'happypiglet'}, {'avzone': 'us-east-2a', 'cluster': 'jumpyjackal'}], 'descriptionLink': '', 'depth': {'num_asks': 5, 'num_bids': 0, 'num_running': 0, 'asks': {'0x5088dC715714fe3ACeC2C5b93bcd9B5b60B41D1C': 1, '0x60a094F7CBf1db8e0BA62c50c5A2ee25A273B145': 1, '0xE3D4371DFf66bDAC60a35fFfcd8cEd65D145D7a4': 1, '0xFEC24537885b347650f48C6809a9C1fA4Ed880E5': 1}, 'asks_updated': '2023-11-30T20:34:23.430784026Z', 'gpus': {'': 0}, 'qps': 22.133333333333333, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'stats': [{'avzone': 'us-east-1a', 'cluster': 'happypiglet', 'capacity': 0.10615215600109904, 'qps': 10.2}, {'avzone': 'us-east-2a', 'cluster': 'jumpyjackal', 'capacity': 0.10299601388710349, 'qps': 11.933333333333334}]}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64b7165fcccc52103e2f07ea', 'name': 'togethercomputer/llama-2-70b-chat', 'display_name': 'LLaMA-2 Chat (70B)', 'display_type': 'chat', 'description': 'Llama 2-chat leverages publicly available instruction datasets and over 1 million human annotations. Available in three sizes: 7B, 13B and 70B parameters', 'license': 'LLaMA license Agreement (Meta)', 'link': 'https://huggingface.co/togethercomputer/llama-2-70b-chat', 'creator_organization': 'Meta', 'hardware_label': '2X A100 80GB', 'pricing_tier': 'Featured', 'access': 'open', 'num_parameters': '68976648192', 'show_in_playground': True, 'finetuning_supported': True, 'isFeaturedModel': True, 'context_length': 4096, 'config': {'prompt_format': '[INST] {prompt} [/INST]', 'stop': ['[/INST]', '</s>'], 'chat_template_name': 'llama'}, 'pricing': {'input': 225, 'output': 225, 'hourly': 0}, 'created_at': '2023-07-18T22:46:55.042Z', 'update_at': '2023-07-18T22:46:55.042Z', 'autopilot_pool': 'cr-a100-80-2x', 'instances': [{'avzone': 'us-east-1a', 'cluster': 'happypiglet'}], 'descriptionLink': '', 'depth': {'num_asks': 9, 'num_bids': 0, 'num_running': 0, 'asks': {'0x0897b7173F81f3d323fC287C9049E4541f5bBF32': 1, '0x2e2B7aB32FFB80b8Bbb583A1C17Ff3336700111B': 1, '0x7C581517e418A31046269aee7A2411FEa8CC1BD0': 1, '0x8a20df4af9049D57B4f08875eB4f98E9678D3AcE': 1, '0xB52F81EFaA46D921B2d6Cf86FeDecf1847956AB7': 1, '0xBAd39DBE4eB99E1185aEe028AFAe184f01B38596': 1, '0xF8c041b5687bcBc2702D4037120F677C8dFB5103': 1, '0xfe2259baF27B4a3B8BE704416aa02F235fC8beEA': 1}, 'asks_updated': '2023-11-30T20:32:29.58932331Z', 'gpus': {'': 0}, 'qps': 7.2, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'throughput_in': 4.3976323e-25, 'throughput_out': 3.938749e-24, 'stats': [{'avzone': 'us-east-1a', 'cluster': 'happypiglet', 'capacity': 0.17130489864864865, 'qps': 7.2}]}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64b7165fcccc52103e2f07e9', 'name': 'togethercomputer/llama-2-70b', 'display_name': 'LLaMA-2 (70B)', 'display_type': 'language', 'description': 'Language model trained on 2 trillion tokens with double the context length of Llama 1. Available in three sizes: 7B, 13B and 70B parameters', 'license': 'LLaMA license Agreement (Meta)', 'link': 'https://huggingface.co/togethercomputer/llama-2-70b', 'creator_organization': 'Meta', 'hardware_label': '2X A100 80GB', 'pricing_tier': 'Featured', 'access': 'open', 'num_parameters': '68976648192', 'show_in_playground': True, 'finetuning_supported': True, 'isFeaturedModel': True, 'context_length': 4096, 'config': {'chat_template_name': 'llama'}, 'pricing': {'input': 225, 'output': 225, 'hourly': 0}, 'created_at': '2023-07-18T22:46:55.042Z', 'update_at': '2023-07-18T22:46:55.042Z', 'autopilot_pool': 'cr-a100-80-2x', 'instances': [{'avzone': 'us-east-1a', 'cluster': 'happypiglet'}], 'descriptionLink': '', 'depth': {'num_asks': 3, 'num_bids': 0, 'num_running': 0, 'asks': {'0x6d024295Fe0369978762D09815dE85f2F60A1ecd': 1, '0xD2AEb96bdf3B886A196F68dE9D84B381308AA7EA': 1}, 'asks_updated': '2023-11-30T18:40:01.51629425Z', 'gpus': {'': 0}, 'qps': 0, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'stats': [{'avzone': 'us-east-1a', 'cluster': 'happypiglet', 'capacity': 0.01694915254237288, 'qps': 0}]}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64b7165fcccc52103e2f07e6', 'name': 'togethercomputer/llama-2-7b-chat', 'display_name': 'LLaMA-2 Chat (7B)', 'display_type': 'chat', 'description': 'Llama 2-chat leverages publicly available instruction datasets and over 1 million human annotations. Available in three sizes: 7B, 13B and 70B parameters', 'license': 'LLaMA license Agreement (Meta)', 'link': 'https://huggingface.co/togethercomputer/llama-2-7b-chat', 'creator_organization': 'Meta', 'hardware_label': 'A100 80GB', 'pricing_tier': 'Featured', 'access': 'open', 'num_parameters': '6738415616', 'show_in_playground': True, 'finetuning_supported': True, 'isFeaturedModel': True, 'context_length': 4096, 'config': {'prompt_format': '[INST] {prompt} [/INST]', 'stop': ['[/INST]', '</s>'], 'chat_template_name': 'llama'}, 'pricing': {'input': 50, 'output': 50, 'hourly': 0}, 'created_at': '2023-07-18T22:46:55.042Z', 'update_at': '2023-07-18T22:46:55.042Z', 'instances': [{'avzone': 'us-east-1a', 'cluster': 'happypiglet'}], 'descriptionLink': '', 'depth': {'num_asks': 2, 'num_bids': 0, 'num_running': 0, 'asks': {'0x7b26c6138a649F91Eb542906284389e49A2f56F5': 1}, 'asks_updated': '2023-11-30T12:41:59.052809486Z', 'gpus': {'': 0}, 'qps': 0.06666666666666667, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'stats': [{'avzone': 'us-east-1a', 'cluster': 'happypiglet', 'capacity': 0.0625, 'qps': 0.06666666666666667}]}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64b7165fcccc52103e2f07e5', 'name': 'togethercomputer/llama-2-7b', 'display_name': 'LLaMA-2 (7B)', 'display_type': 'language', 'description': 'Language model trained on 2 trillion tokens with double the context length of Llama 1. Available in three sizes: 7B, 13B and 70B parameters', 'license': 'LLaMA license Agreement (Meta)', 'link': 'https://huggingface.co/togethercomputer/llama-2-7b', 'creator_organization': 'Meta', 'hardware_label': 'A100 80GB', 'pricing_tier': 'Featured', 'access': 'open', 'num_parameters': '6738415616', 'show_in_playground': True, 'finetuning_supported': True, 'isFeaturedModel': True, 'context_length': 4096, 'config': {'chat_template_name': 'llama'}, 'pricing': {'input': 50, 'output': 50, 'hourly': 0}, 'created_at': '2023-07-18T22:46:55.042Z', 'update_at': '2023-07-18T22:46:55.042Z', 'instances': [{'avzone': 'us-east-1a', 'cluster': 'happypiglet'}], 'descriptionLink': '', 'depth': {'num_asks': 2, 'num_bids': 0, 'num_running': 0, 'asks': {'0xe80502a69732A5b012E8E5c0837e53099A059174': 1}, 'asks_updated': '2023-11-30T21:04:28.117030709Z', 'gpus': {'': 0}, 'qps': 20.733333333333334, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'stats': [{'avzone': 'us-east-1a', 'cluster': 'happypiglet', 'capacity': 0.6667555081734187, 'qps': 20.733333333333334}]}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64ee72a0aa4f1b1b2c66f0a5', 'name': 'upstage/SOLAR-0-70b-16bit', 'display_name': 'SOLAR v0 (70B)', 'display_type': 'chat', 'description': 'Language model instruction fine-tuned by upstage.ai on Orca and Alpaca style datasets that reached the top spot in openLLM rankings', 'license': 'CC BY-NC-4.0', 'creator_organization': 'Upstage', 'hardware_label': '2x A100 80GB', 'num_parameters': 70000000000, 'release_date': '2023-08-01T00:00:00.000Z', 'show_in_playground': True, 'isFeaturedModel': True, 'context_length': 4096, 'config': {'stop': ['###'], 'prompt_format': '### System:\\nYou are a respectful and helpful assistant.\\n### User:\\n{prompt}\\n### Assistant:', 'chat_template': \"{{ '### System:\\nYou are a respectful and helpful assistant.\\n' }}{% for message in messages %}{% if message['role'] == 'user' %}{{ '### User:\\n' + message['content'] + '\\n' }}{% else %}{{ '### Assistant:\\n' + message['content'] + '\\n' }}{% endif %}{% endfor %}{{ '### Assistant:' }}\"}, 'pricing': {'input': 225, 'output': 225, 'hourly': 0}, 'created_at': '2023-08-29T22:35:12.294Z', 'update_at': '2023-08-29T22:35:12.294Z', 'access': '', 'link': '', 'descriptionLink': '', 'depth': {'num_asks': 20, 'num_bids': 14, 'num_running': 14, 'asks': {'0x0e8Bdb1Ff57faE9f6C8D8c9a4F56A98B69aef114': 1, '0x27aF4Aa79cAF4474BFAE3bdE9D270d5aA66d653e': 6, '0x28c6482fc89503c6b1e31df21af94804e82609D5': 3, '0x4490a9356Bdd49156142e78388ed80114a4Bc1E6': 2, '0x8E3ed25250B5152Ac86935386cdC0F2228EBEC9C': 5, '0xF43B38c82e5b1357Ab601aa4f2855E621Ee303d8': 3}, 'asks_updated': '2023-11-30T21:05:47.311385094Z', 'gpus': {'': 0}, 'qps': 0.3014099, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'throughput_in': 1291.789, 'throughput_out': 269.83542}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64ace3af227f790586239ce6', 'name': 'wavymulder/Analog-Diffusion', 'display_name': 'Analog Diffusion', 'display_type': 'image', 'description': 'Dreambooth model trained on a diverse set of analog photographs to provide an analog film effect. ', 'license': 'creativeml-openrail-m', 'link': 'https://huggingface.co/wavymulder/Analog-Diffusion', 'creator_organization': 'Wavymulder', 'hardware_label': 'A40 48GB', 'pricing_tier': 'supported', 'access': 'open', 'num_parameters': 0, 'show_in_playground': True, 'isFeaturedModel': True, 'external_pricing_url': 'https://www.together.xyz/apis#pricing', 'created_at': '2023-07-11T05:07:59.364Z', 'update_at': '2023-07-11T05:07:59.364Z', 'descriptionLink': '', 'pricing': {'hourly': 0, 'input': 0, 'output': 0, 'base': 0, 'finetune': 0}, 'depth': {'num_asks': 1, 'num_bids': 0, 'num_running': 0, 'asks': {'0xC830b3583bcA51887185318c0184fbdB622A55f5': 1}, 'asks_updated': '2023-11-30T21:07:34.45717266Z', 'gpus': {'NVIDIA A40': 1}, 'options': {'input=text,image': 1}, 'qps': 0.02451885, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'throughput_in': 0.49037817}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '655e703de94c78d2e9a9bc70', 'name': 'mifu67@stanford.edu/llama-2-7b-chat-young-han-new-data-3--1e-05-2023-11-22-21-08-10', 'display_type': 'chat', 'description': 'Llama 2-chat leverages publicly available instruction datasets and over 1 million human annotations. Available in three sizes: 7B, 13B and 70B parameters', 'creator_organization': 'mifu67@stanford.edu', 'hardware_label': 'L40', 'num_parameters': '6738415616', 'release_date': '2023-11-22T21:18:53.292Z', 'show_in_playground': True, 'owner': 'mifu67@stanford.edu', 'owner_address': '0xebd597774b313d8e8d22af4629b75ec7d567f678', 'owner_userid': '6552b4a556bb2d3952ed7a14', 'parent': 'togethercomputer/llama-2-7b-chat', 'base': 'togethercomputer/llama-2-7b-chat', 'path': 'r2://together-dev/finetune/6552b4a556bb2d3952ed7a14/mifu67@stanford.edu/llama-2-7b-chat-young-han-new-data-3--1e-05-2023-11-22-21-08-10/ft-5ff6785e-ae32-4636-a4ff-ce6bec016053-2023-11-22-13-14-06', 'files': [{'filename': 'added_tokens.json', 'size': 21, 'hash': 'ddfe5408fa8791d2ce96f5aeeb2bb76', 'modified': '2023-11-22T21:14:10.452Z'}, {'filename': 'config.json', 'size': 603, 'hash': 'f238117b38b277bf76354fb70287646', 'modified': '2023-11-22T21:14:09.351Z'}, {'filename': 'generation_config.json', 'size': 132, 'hash': '8cfc95df8bad11477f8efa77123af44', 'modified': '2023-11-22T21:14:10.155Z'}, {'filename': 'pytorch_model-00001-of-00002.bin', 'size': 9976620122, 'hash': 'e48eb921582519988e30b2ff600fd03f-119', 'modified': '2023-11-22T21:16:35.798Z'}, {'filename': 'pytorch_model-00002-of-00002.bin', 'size': 3500310787, 'hash': '71b70ef9908000aa8cbcf4b4c06c9dc5-41', 'modified': '2023-11-22T21:15:09.221Z'}, {'filename': 'pytorch_model.bin.index.json', 'size': 23950, 'hash': '14bb4de8f69434fc50ee5fe1b30adea', 'modified': '2023-11-22T21:14:10.224Z'}, {'filename': 'special_tokens_map.json', 'size': 435, 'hash': '413c7f9a8a6517c52c937eed27f1884', 'modified': '2023-11-22T21:14:10.272Z'}, {'filename': 'tokenizer.model', 'size': 499723, 'hash': 'eeec4125e9c7560836b4873b6f8e302', 'modified': '2023-11-22T21:14:10.462Z'}, {'filename': 'tokenizer_config.json', 'size': 825, 'hash': '0b458d0721f67a36c18821b20b4d65f', 'modified': '2023-11-22T21:14:10.237Z'}], 'config': {'prompt_format': '[INST] {prompt} [/INST]', 'stop': ['[/INST]', '</s>']}, 'worker_config': None, 'worker_template': None, 'pricing': {'hourly': 1400000000, 'input': 0, 'output': 0, 'finetune': 0, 'base': 0}, 'created_at': '2023-11-22T21:18:53.509Z', 'update_at': '2023-11-22T21:18:53.509Z', 'autopilot_pool': None, 'has_wandb_telemetry': False, 'wandb_url': '', 'access': '', 'depth': {'num_asks': 0, 'num_bids': 0, 'num_running': 0, 'asks_updated': '2023-11-22T21:41:56.745587576Z', 'qps': 0, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}}, 'link': '', 'license': '', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '65603ee6297c0d1aa331f724', 'name': 'mifu67@stanford.edu/llama-2-7b-chat-han-first-3--1e-05-2023-11-24-05-56-02', 'display_type': 'chat', 'description': 'Llama 2-chat leverages publicly available instruction datasets and over 1 million human annotations. Available in three sizes: 7B, 13B and 70B parameters', 'creator_organization': 'mifu67@stanford.edu', 'hardware_label': 'L40', 'num_parameters': '6738415616', 'release_date': '2023-11-24T06:12:54.772Z', 'show_in_playground': True, 'owner': 'mifu67@stanford.edu', 'owner_address': '0xebd597774b313d8e8d22af4629b75ec7d567f678', 'owner_userid': '6552b4a556bb2d3952ed7a14', 'parent': 'togethercomputer/llama-2-7b-chat', 'base': 'togethercomputer/llama-2-7b-chat', 'path': 'r2://together-dev/finetune/6552b4a556bb2d3952ed7a14/mifu67@stanford.edu/llama-2-7b-chat-han-first-3--1e-05-2023-11-24-05-56-02/ft-5c5faba8-4c1a-41b1-8f8a-c22c5772128f-2023-11-23-22-08-26', 'files': [{'filename': 'added_tokens.json', 'size': 21, 'hash': 'ddfe5408fa8791d2ce96f5aeeb2bb76', 'modified': '2023-11-24T06:08:29.647Z'}, {'filename': 'config.json', 'size': 603, 'hash': 'f238117b38b277bf76354fb70287646', 'modified': '2023-11-24T06:08:30.181Z'}, {'filename': 'generation_config.json', 'size': 132, 'hash': '8cfc95df8bad11477f8efa77123af44', 'modified': '2023-11-24T06:08:30.202Z'}, {'filename': 'pytorch_model-00001-of-00002.bin', 'size': 9976620122, 'hash': '46325810d92b773e010a4836bbe68a9f-119', 'modified': '2023-11-24T06:10:45.375Z'}, {'filename': 'pytorch_model-00002-of-00002.bin', 'size': 3500310787, 'hash': '10333b6016655f4baf1462b6731902af-41', 'modified': '2023-11-24T06:09:25.802Z'}, {'filename': 'pytorch_model.bin.index.json', 'size': 23950, 'hash': '14bb4de8f69434fc50ee5fe1b30adea', 'modified': '2023-11-24T06:08:30.183Z'}, {'filename': 'special_tokens_map.json', 'size': 435, 'hash': '413c7f9a8a6517c52c937eed27f1884', 'modified': '2023-11-24T06:08:30.158Z'}, {'filename': 'tokenizer.model', 'size': 499723, 'hash': 'eeec4125e9c7560836b4873b6f8e302', 'modified': '2023-11-24T06:08:30.566Z'}, {'filename': 'tokenizer_config.json', 'size': 825, 'hash': '0b458d0721f67a36c18821b20b4d65f', 'modified': '2023-11-24T06:08:30.150Z'}], 'config': {'prompt_format': '[INST] {prompt} [/INST]', 'stop': ['[/INST]', '</s>']}, 'worker_config': None, 'worker_template': None, 'pricing': {'hourly': 1400000000, 'input': 0, 'output': 0, 'finetune': 0, 'base': 0}, 'created_at': '2023-11-24T06:12:54.971Z', 'update_at': '2023-11-24T06:12:54.971Z', 'autopilot_pool': None, 'has_wandb_telemetry': False, 'wandb_url': '', 'access': '', 'depth': {'num_asks': 0, 'num_bids': 0, 'num_running': 0, 'asks_updated': '2023-11-29T02:06:36.507874782Z', 'qps': 0, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}}, 'link': '', 'license': '', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '655e7c91e94c78d2e9a9bc78', 'name': 'mifu67@stanford.edu/llama-2-7b-chat-young-han-new-data-6--1e-05-2023-11-22-21-56-35', 'display_type': 'chat', 'description': 'Llama 2-chat leverages publicly available instruction datasets and over 1 million human annotations. Available in three sizes: 7B, 13B and 70B parameters', 'creator_organization': 'mifu67@stanford.edu', 'hardware_label': 'L40', 'num_parameters': '6738415616', 'release_date': '2023-11-22T22:11:28.854Z', 'show_in_playground': True, 'owner': 'mifu67@stanford.edu', 'owner_address': '0xebd597774b313d8e8d22af4629b75ec7d567f678', 'owner_userid': '6552b4a556bb2d3952ed7a14', 'parent': 'togethercomputer/llama-2-7b-chat', 'base': 'togethercomputer/llama-2-7b-chat', 'path': 'r2://together-dev/finetune/6552b4a556bb2d3952ed7a14/mifu67@stanford.edu/llama-2-7b-chat-young-han-new-data-6--1e-05-2023-11-22-21-56-35/ft-4dd9ec0a-d19e-4bf6-bf44-f360b14cee1c-2023-11-22-14-06-51', 'files': [{'filename': 'added_tokens.json', 'size': 21, 'hash': 'ddfe5408fa8791d2ce96f5aeeb2bb76', 'modified': '2023-11-22T22:06:55.120Z'}, {'filename': 'config.json', 'size': 603, 'hash': 'f238117b38b277bf76354fb70287646', 'modified': '2023-11-22T22:06:55.189Z'}, {'filename': 'generation_config.json', 'size': 132, 'hash': '8cfc95df8bad11477f8efa77123af44', 'modified': '2023-11-22T22:06:55.166Z'}, {'filename': 'pytorch_model-00001-of-00002.bin', 'size': 9976620122, 'hash': '36b2baef72d07f27713e22a0ade0fa09-119', 'modified': '2023-11-22T22:09:11.047Z'}, {'filename': 'pytorch_model-00002-of-00002.bin', 'size': 3500310787, 'hash': 'b64fda8565064857c0bc050507f22072-41', 'modified': '2023-11-22T22:07:56.571Z'}, {'filename': 'pytorch_model.bin.index.json', 'size': 23950, 'hash': '14bb4de8f69434fc50ee5fe1b30adea', 'modified': '2023-11-22T22:06:55.141Z'}, {'filename': 'special_tokens_map.json', 'size': 435, 'hash': '413c7f9a8a6517c52c937eed27f1884', 'modified': '2023-11-22T22:06:55.217Z'}, {'filename': 'tokenizer.model', 'size': 499723, 'hash': 'eeec4125e9c7560836b4873b6f8e302', 'modified': '2023-11-22T22:06:55.510Z'}, {'filename': 'tokenizer_config.json', 'size': 825, 'hash': '0b458d0721f67a36c18821b20b4d65f', 'modified': '2023-11-22T22:06:54.646Z'}], 'config': {'prompt_format': '[INST] {prompt} [/INST]', 'stop': ['[/INST]', '</s>']}, 'worker_config': None, 'worker_template': None, 'pricing': {'hourly': 1400000000, 'input': 0, 'output': 0, 'finetune': 0, 'base': 0}, 'created_at': '2023-11-22T22:11:29.045Z', 'update_at': '2023-11-22T22:11:29.045Z', 'autopilot_pool': None, 'has_wandb_telemetry': False, 'wandb_url': '', 'access': '', 'depth': {'num_asks': 0, 'num_bids': 0, 'num_running': 0, 'asks_updated': '2023-11-30T09:15:30.795310454Z', 'qps': 0, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}}, 'link': '', 'license': '', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '65627212297c0d1aa331f7a1', 'name': 'mifu67@stanford.edu/llama-2-7b-chat-old-han-first-5--1e-05-2023-11-25-21-58-35', 'display_type': 'chat', 'description': 'Llama 2-chat leverages publicly available instruction datasets and over 1 million human annotations. Available in three sizes: 7B, 13B and 70B parameters', 'creator_organization': 'mifu67@stanford.edu', 'hardware_label': 'L40', 'num_parameters': '6738415616', 'release_date': '2023-11-25T22:15:46.522Z', 'show_in_playground': True, 'owner': 'mifu67@stanford.edu', 'owner_address': '0xebd597774b313d8e8d22af4629b75ec7d567f678', 'owner_userid': '6552b4a556bb2d3952ed7a14', 'parent': 'togethercomputer/llama-2-7b-chat', 'base': 'togethercomputer/llama-2-7b-chat', 'path': 'r2://together-dev/finetune/6552b4a556bb2d3952ed7a14/mifu67@stanford.edu/llama-2-7b-chat-old-han-first-5--1e-05-2023-11-25-21-58-35/ft-b28914ad-08ca-42fc-9807-3b61fede621f-2023-11-25-14-11-35', 'files': [{'filename': 'added_tokens.json', 'size': 21, 'hash': 'ddfe5408fa8791d2ce96f5aeeb2bb76', 'modified': '2023-11-25T22:11:39.223Z'}, {'filename': 'config.json', 'size': 603, 'hash': 'f238117b38b277bf76354fb70287646', 'modified': '2023-11-25T22:11:38.608Z'}, {'filename': 'generation_config.json', 'size': 132, 'hash': '8cfc95df8bad11477f8efa77123af44', 'modified': '2023-11-25T22:11:39.409Z'}, {'filename': 'pytorch_model-00001-of-00002.bin', 'size': 9976620122, 'hash': '2b9c408550c1a6a690ac4c083e62d8c5-119', 'modified': '2023-11-25T22:13:56.728Z'}, {'filename': 'pytorch_model-00002-of-00002.bin', 'size': 3500310787, 'hash': 'b9f27acd5a26a1d69dac86c9b7cd587b-41', 'modified': '2023-11-25T22:13:09.411Z'}, {'filename': 'pytorch_model.bin.index.json', 'size': 23950, 'hash': '14bb4de8f69434fc50ee5fe1b30adea', 'modified': '2023-11-25T22:11:39.224Z'}, {'filename': 'special_tokens_map.json', 'size': 435, 'hash': '413c7f9a8a6517c52c937eed27f1884', 'modified': '2023-11-25T22:11:39.152Z'}, {'filename': 'tokenizer.model', 'size': 499723, 'hash': 'eeec4125e9c7560836b4873b6f8e302', 'modified': '2023-11-25T22:11:39.668Z'}, {'filename': 'tokenizer_config.json', 'size': 825, 'hash': '0b458d0721f67a36c18821b20b4d65f', 'modified': '2023-11-25T22:11:39.575Z'}], 'config': {'prompt_format': '[INST] {prompt} [/INST]', 'stop': ['[/INST]', '</s>']}, 'worker_config': None, 'worker_template': None, 'pricing': {'hourly': 1400000000, 'input': 0, 'output': 0, 'finetune': 0, 'base': 0}, 'created_at': '2023-11-25T22:15:46.729Z', 'update_at': '2023-11-25T22:15:46.729Z', 'autopilot_pool': None, 'has_wandb_telemetry': False, 'wandb_url': '', 'access': '', 'depth': {'num_asks': 0, 'num_bids': 0, 'num_running': 0, 'asks_updated': '2023-11-27T06:13:46.19718036Z', 'qps': 0, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}}, 'link': '', 'license': '', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '65627b1c297c0d1aa331f7b0', 'name': 'mifu67@stanford.edu/llama-2-7b-chat-old-han-second-10--1e-05-2023-11-25-22-27-37', 'display_type': 'chat', 'description': 'Llama 2-chat leverages publicly available instruction datasets and over 1 million human annotations. Available in three sizes: 7B, 13B and 70B parameters', 'creator_organization': 'mifu67@stanford.edu', 'hardware_label': 'L40', 'num_parameters': '6738415616', 'release_date': '2023-11-25T22:54:20.361Z', 'show_in_playground': True, 'owner': 'mifu67@stanford.edu', 'owner_address': '0xebd597774b313d8e8d22af4629b75ec7d567f678', 'owner_userid': '6552b4a556bb2d3952ed7a14', 'parent': 'togethercomputer/llama-2-7b-chat', 'base': 'togethercomputer/llama-2-7b-chat', 'path': 'r2://together-dev/finetune/6552b4a556bb2d3952ed7a14/mifu67@stanford.edu/llama-2-7b-chat-old-han-second-10--1e-05-2023-11-25-22-27-37/ft-4bf5839f-2e92-45bc-acf2-a51d8a7d1031-2023-11-25-14-50-31', 'files': [{'filename': 'added_tokens.json', 'size': 21, 'hash': 'ddfe5408fa8791d2ce96f5aeeb2bb76', 'modified': '2023-11-25T22:50:35.465Z'}, {'filename': 'config.json', 'size': 603, 'hash': 'f238117b38b277bf76354fb70287646', 'modified': '2023-11-25T22:50:34.541Z'}, {'filename': 'generation_config.json', 'size': 132, 'hash': '8cfc95df8bad11477f8efa77123af44', 'modified': '2023-11-25T22:50:35.538Z'}, {'filename': 'pytorch_model-00001-of-00002.bin', 'size': 9976620122, 'hash': '56c1a077891cc2393a4c8bc442be0f62-119', 'modified': '2023-11-25T22:52:37.727Z'}, {'filename': 'pytorch_model-00002-of-00002.bin', 'size': 3500310787, 'hash': '51bf7d04a1b065d65cf423b3a149ef5d-41', 'modified': '2023-11-25T22:51:36.709Z'}, {'filename': 'pytorch_model.bin.index.json', 'size': 23950, 'hash': '14bb4de8f69434fc50ee5fe1b30adea', 'modified': '2023-11-25T22:50:35.607Z'}, {'filename': 'special_tokens_map.json', 'size': 435, 'hash': '413c7f9a8a6517c52c937eed27f1884', 'modified': '2023-11-25T22:50:35.553Z'}, {'filename': 'tokenizer.model', 'size': 499723, 'hash': 'eeec4125e9c7560836b4873b6f8e302', 'modified': '2023-11-25T22:50:36.156Z'}, {'filename': 'tokenizer_config.json', 'size': 825, 'hash': '0b458d0721f67a36c18821b20b4d65f', 'modified': '2023-11-25T22:50:36.365Z'}], 'config': {'prompt_format': '[INST] {prompt} [/INST]', 'stop': ['[/INST]', '</s>']}, 'worker_config': None, 'worker_template': None, 'pricing': {'hourly': 1400000000, 'input': 0, 'output': 0, 'finetune': 0, 'base': 0}, 'created_at': '2023-11-25T22:54:20.575Z', 'update_at': '2023-11-25T22:54:20.575Z', 'autopilot_pool': None, 'has_wandb_telemetry': False, 'wandb_url': '', 'access': '', 'depth': {'num_asks': 0, 'num_bids': 0, 'num_running': 0, 'asks_updated': '2023-11-28T07:39:07.794403116Z', 'qps': 0, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}}, 'link': '', 'license': '', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '65641c69297c0d1aa331f7fe', 'name': 'mifu67@stanford.edu/llama-2-7b-chat-old-han-second-20--1e-05-2023-11-27-03-45-03', 'display_type': 'chat', 'description': 'Llama 2-chat leverages publicly available instruction datasets and over 1 million human annotations. Available in three sizes: 7B, 13B and 70B parameters', 'creator_organization': 'mifu67@stanford.edu', 'hardware_label': 'L40', 'num_parameters': '6738415616', 'release_date': '2023-11-27T04:34:48.917Z', 'show_in_playground': True, 'owner': 'mifu67@stanford.edu', 'owner_address': '0xebd597774b313d8e8d22af4629b75ec7d567f678', 'owner_userid': '6552b4a556bb2d3952ed7a14', 'parent': 'togethercomputer/llama-2-7b-chat', 'base': 'togethercomputer/llama-2-7b-chat', 'path': 'r2://together-dev/finetune/6552b4a556bb2d3952ed7a14/mifu67@stanford.edu/llama-2-7b-chat-old-han-second-20--1e-05-2023-11-27-03-45-03/ft-89dab9cf-f09a-40f8-8fe6-74db4202fb3b-2023-11-26-20-30-00', 'files': [{'filename': 'added_tokens.json', 'size': 21, 'hash': 'ddfe5408fa8791d2ce96f5aeeb2bb76', 'modified': '2023-11-27T04:30:04.663Z'}, {'filename': 'config.json', 'size': 603, 'hash': 'f238117b38b277bf76354fb70287646', 'modified': '2023-11-27T04:30:04.028Z'}, {'filename': 'generation_config.json', 'size': 132, 'hash': '8cfc95df8bad11477f8efa77123af44', 'modified': '2023-11-27T04:30:04.559Z'}, {'filename': 'pytorch_model-00001-of-00002.bin', 'size': 9976620122, 'hash': 'f8c72121a0bc888e0c72354b000c96b2-119', 'modified': '2023-11-27T04:32:19.893Z'}, {'filename': 'pytorch_model-00002-of-00002.bin', 'size': 3500310787, 'hash': 'd0f4d6fcccb298a4795285703fa2ecf7-41', 'modified': '2023-11-27T04:31:14.747Z'}, {'filename': 'pytorch_model.bin.index.json', 'size': 23950, 'hash': '14bb4de8f69434fc50ee5fe1b30adea', 'modified': '2023-11-27T04:30:04.495Z'}, {'filename': 'special_tokens_map.json', 'size': 435, 'hash': '413c7f9a8a6517c52c937eed27f1884', 'modified': '2023-11-27T04:30:04.478Z'}, {'filename': 'tokenizer.model', 'size': 499723, 'hash': 'eeec4125e9c7560836b4873b6f8e302', 'modified': '2023-11-27T04:30:04.671Z'}, {'filename': 'tokenizer_config.json', 'size': 825, 'hash': '0b458d0721f67a36c18821b20b4d65f', 'modified': '2023-11-27T04:30:04.787Z'}], 'config': {'prompt_format': '[INST] {prompt} [/INST]', 'stop': ['[/INST]', '</s>']}, 'worker_config': None, 'worker_template': None, 'pricing': {'hourly': 1400000000, 'input': 0, 'output': 0, 'finetune': 0, 'base': 0}, 'created_at': '2023-11-27T04:34:49.103Z', 'update_at': '2023-11-27T04:34:49.103Z', 'autopilot_pool': None, 'has_wandb_telemetry': False, 'wandb_url': '', 'access': '', 'depth': {'num_asks': 0, 'num_bids': 0, 'num_running': 0, 'asks_updated': '0001-01-01T00:00:00Z', 'qps': 0, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}}, 'link': '', 'license': '', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '65641caa297c0d1aa331f800', 'name': 'mifu67@stanford.edu/llama-2-7b-chat-old-han-third-20--1e-05-2023-11-27-03-46-19', 'display_type': 'chat', 'description': 'Llama 2-chat leverages publicly available instruction datasets and over 1 million human annotations. Available in three sizes: 7B, 13B and 70B parameters', 'creator_organization': 'mifu67@stanford.edu', 'hardware_label': 'L40', 'num_parameters': '6738415616', 'release_date': '2023-11-27T04:35:54.335Z', 'show_in_playground': True, 'owner': 'mifu67@stanford.edu', 'owner_address': '0xebd597774b313d8e8d22af4629b75ec7d567f678', 'owner_userid': '6552b4a556bb2d3952ed7a14', 'parent': 'togethercomputer/llama-2-7b-chat', 'base': 'togethercomputer/llama-2-7b-chat', 'path': 'r2://together-dev/finetune/6552b4a556bb2d3952ed7a14/mifu67@stanford.edu/llama-2-7b-chat-old-han-third-20--1e-05-2023-11-27-03-46-19/ft-9a50dddf-094e-4bdd-953b-0eab313d70e7-2023-11-26-20-31-53', 'files': [{'filename': 'added_tokens.json', 'size': 21, 'hash': 'ddfe5408fa8791d2ce96f5aeeb2bb76', 'modified': '2023-11-27T04:31:56.691Z'}, {'filename': 'config.json', 'size': 603, 'hash': 'f238117b38b277bf76354fb70287646', 'modified': '2023-11-27T04:31:55.934Z'}, {'filename': 'generation_config.json', 'size': 132, 'hash': '8cfc95df8bad11477f8efa77123af44', 'modified': '2023-11-27T04:31:56.462Z'}, {'filename': 'pytorch_model-00001-of-00002.bin', 'size': 9976620122, 'hash': '358431f7275bb26f1f86694591eb9569-119', 'modified': '2023-11-27T04:34:01.231Z'}, {'filename': 'pytorch_model-00002-of-00002.bin', 'size': 3500310787, 'hash': '10bbd161cfc669e4de9c692374c66976-41', 'modified': '2023-11-27T04:33:21.721Z'}, {'filename': 'pytorch_model.bin.index.json', 'size': 23950, 'hash': '14bb4de8f69434fc50ee5fe1b30adea', 'modified': '2023-11-27T04:31:56.263Z'}, {'filename': 'special_tokens_map.json', 'size': 435, 'hash': '413c7f9a8a6517c52c937eed27f1884', 'modified': '2023-11-27T04:31:56.430Z'}, {'filename': 'tokenizer.model', 'size': 499723, 'hash': 'eeec4125e9c7560836b4873b6f8e302', 'modified': '2023-11-27T04:31:56.548Z'}, {'filename': 'tokenizer_config.json', 'size': 825, 'hash': '0b458d0721f67a36c18821b20b4d65f', 'modified': '2023-11-27T04:31:56.579Z'}], 'config': {'prompt_format': '[INST] {prompt} [/INST]', 'stop': ['[/INST]', '</s>']}, 'worker_config': None, 'worker_template': None, 'pricing': {'hourly': 1400000000, 'input': 0, 'output': 0, 'finetune': 0, 'base': 0}, 'created_at': '2023-11-27T04:35:54.597Z', 'update_at': '2023-11-27T04:35:54.597Z', 'autopilot_pool': None, 'has_wandb_telemetry': False, 'wandb_url': '', 'access': '', 'depth': {'num_asks': 0, 'num_bids': 0, 'num_running': 0, 'asks_updated': '2023-11-29T17:52:55.645578622Z', 'qps': 0, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}}, 'link': '', 'license': '', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '6557d5a5c8fe37c1d548da4f', 'name': 'mifu67@stanford.edu/llama-2-7b-chat-my-demo-finetune-2023-11-17-20-51-22', 'display_type': 'chat', 'description': 'Llama 2-chat leverages publicly available instruction datasets and over 1 million human annotations. Available in three sizes: 7B, 13B and 70B parameters', 'creator_organization': 'mifu67@stanford.edu', 'hardware_label': 'L40', 'num_parameters': '6738415616', 'release_date': '2023-11-17T21:05:40.815Z', 'show_in_playground': True, 'owner': 'mifu67@stanford.edu', 'owner_address': '0xebd597774b313d8e8d22af4629b75ec7d567f678', 'owner_userid': '6552b4a556bb2d3952ed7a14', 'parent': 'togethercomputer/llama-2-7b-chat', 'base': 'togethercomputer/llama-2-7b-chat', 'path': 'r2://together-dev/finetune/6552b4a556bb2d3952ed7a14/mifu67@stanford.edu/llama-2-7b-chat-my-demo-finetune-2023-11-17-20-51-22/ft-43158f66-36ae-481d-a40b-f396019113ff-2023-11-17-13-01-42', 'files': [{'filename': 'added_tokens.json', 'size': 21, 'hash': 'ddfe5408fa8791d2ce96f5aeeb2bb76', 'modified': '2023-11-17T21:01:45.901Z'}, {'filename': 'config.json', 'size': 603, 'hash': 'f238117b38b277bf76354fb70287646', 'modified': '2023-11-17T21:01:45.749Z'}, {'filename': 'generation_config.json', 'size': 132, 'hash': '8cfc95df8bad11477f8efa77123af44', 'modified': '2023-11-17T21:01:44.954Z'}, {'filename': 'pytorch_model-00001-of-00002.bin', 'size': 9976620122, 'hash': '4763a46138d621b8de4277debd9b20da-119', 'modified': '2023-11-17T21:03:58.715Z'}, {'filename': 'pytorch_model-00002-of-00002.bin', 'size': 3500310787, 'hash': 'd63cb28f9b2c9100ec6094ff39a7197f-41', 'modified': '2023-11-17T21:02:57.012Z'}, {'filename': 'pytorch_model.bin.index.json', 'size': 23950, 'hash': '14bb4de8f69434fc50ee5fe1b30adea', 'modified': '2023-11-17T21:01:45.760Z'}, {'filename': 'special_tokens_map.json', 'size': 435, 'hash': '413c7f9a8a6517c52c937eed27f1884', 'modified': '2023-11-17T21:01:45.806Z'}, {'filename': 'tokenizer.model', 'size': 499723, 'hash': 'eeec4125e9c7560836b4873b6f8e302', 'modified': '2023-11-17T21:01:45.989Z'}, {'filename': 'tokenizer_config.json', 'size': 825, 'hash': '0b458d0721f67a36c18821b20b4d65f', 'modified': '2023-11-17T21:01:45.643Z'}], 'config': {'prompt_format': '[INST] {prompt} [/INST]', 'stop': ['[/INST]', '</s>']}, 'worker_config': None, 'worker_template': None, 'pricing': {'hourly': 1400000000, 'input': 0, 'output': 0, 'finetune': 0, 'base': 0}, 'created_at': '2023-11-17T21:05:41.026Z', 'update_at': '2023-11-17T21:05:41.026Z', 'autopilot_pool': None, 'has_wandb_telemetry': False, 'wandb_url': '', 'access': '', 'depth': {'num_asks': 0, 'num_bids': 0, 'num_running': 0, 'asks_updated': '2023-11-18T02:20:51.068199522Z', 'qps': 0, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}}, 'link': '', 'license': '', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '65582d676865deb9bb51e2fa', 'name': 'mifu67@stanford.edu/llama-2-70b-chat-my-demo-finetune-2023-11-17-20-51-35', 'display_type': 'chat', 'description': 'Llama 2-chat leverages publicly available instruction datasets and over 1 million human annotations. Available in three sizes: 7B, 13B and 70B parameters', 'creator_organization': 'mifu67@stanford.edu', 'hardware_label': '2x A100 80GB', 'num_parameters': '68976648192', 'release_date': '2023-11-18T03:20:07.317Z', 'show_in_playground': True, 'owner': 'mifu67@stanford.edu', 'owner_address': '0xebd597774b313d8e8d22af4629b75ec7d567f678', 'owner_userid': '6552b4a556bb2d3952ed7a14', 'parent': 'togethercomputer/llama-2-70b-chat', 'base': 'togethercomputer/llama-2-70b-chat', 'path': 'r2://together-dev/finetune/6552b4a556bb2d3952ed7a14/mifu67@stanford.edu/llama-2-70b-chat-my-demo-finetune-2023-11-17-20-51-35/ft-3625edb3-0c2d-4cf7-9164-e45532dfea2b-2023-11-17-18-48-43', 'files': [{'filename': 'README.md', 'size': 1469, 'hash': '32bbb3ddde59255848c98ed438d90d2', 'modified': '2023-11-18T02:48:46.718Z'}, {'filename': 'all_results.json', 'size': 434, 'hash': 'b802e58ae4f673867384ac0dc9a439f', 'modified': '2023-11-18T02:48:46.261Z'}, {'filename': 'config.json', 'size': 687, 'hash': '996cb86147e7a25fc1e18b7cceb1f88', 'modified': '2023-11-18T02:48:46.623Z'}, {'filename': 'eval_results.json', 'size': 264, 'hash': 'd1962ed75c1e9ef1144d56def6d9780', 'modified': '2023-11-18T02:48:46.927Z'}, {'filename': 'generation_config.json', 'size': 132, 'hash': '8272d56fb279e1fbfcc6bfc841c968a', 'modified': '2023-11-18T02:48:46.584Z'}, {'filename': 'pytorch_model-00001-of-00015.bin', 'size': 9852601804, 'hash': '753d7aa19e4bab5cfd6b0823857d3cb8-117', 'modified': '2023-11-18T02:57:00.276Z'}, {'filename': 'pytorch_model-00002-of-00015.bin', 'size': 9798109380, 'hash': 'eff59207ae39ef60d5c3ee4f357f285e-116', 'modified': '2023-11-18T02:56:41.546Z'}, {'filename': 'pytorch_model-00003-of-00015.bin', 'size': 9965880502, 'hash': 'c71b064c73a381f3724e6089a870f5cb-118', 'modified': '2023-11-18T02:57:22.698Z'}, {'filename': 'pytorch_model-00004-of-00015.bin', 'size': 9798075916, 'hash': 'ebb94280fc17aef79293a4cbe92f4a04-116', 'modified': '2023-11-18T02:56:50.740Z'}, {'filename': 'pytorch_model-00005-of-00015.bin', 'size': 9798109360, 'hash': '2796d62b1908aea9a267eea1df4592d7-116', 'modified': '2023-11-18T02:56:54.678Z'}, {'filename': 'pytorch_model-00006-of-00015.bin', 'size': 9798109444, 'hash': '6f3ac8cd135b4b6c88a14469f4352396-116', 'modified': '2023-11-18T03:04:25.309Z'}, {'filename': 'pytorch_model-00007-of-00015.bin', 'size': 9965880502, 'hash': 'e26e216a30d8bd74544767d24d4e6b76-118', 'modified': '2023-11-18T03:04:40.535Z'}, {'filename': 'pytorch_model-00008-of-00015.bin', 'size': 9798075916, 'hash': 'a7d73b3e21787b6d8e5e68ce725392d3-116', 'modified': '2023-11-18T03:04:41.318Z'}, {'filename': 'pytorch_model-00009-of-00015.bin', 'size': 9798109360, 'hash': '0d1cd89baf3309f3c9e1c37966ed6183-116', 'modified': '2023-11-18T03:04:45.941Z'}, {'filename': 'pytorch_model-00010-of-00015.bin', 'size': 9798109444, 'hash': '4316ad29b2d4e884fae73b56941e1a62-116', 'modified': '2023-11-18T03:05:03.671Z'}, {'filename': 'pytorch_model-00011-of-00015.bin', 'size': 9965880502, 'hash': 'b8aad3f1112e8cf652082d3cfe17d152-118', 'modified': '2023-11-18T03:10:24.198Z'}, {'filename': 'pytorch_model-00012-of-00015.bin', 'size': 9798075916, 'hash': 'e1ff7d60a523c6f2b140b9cbddbafc2b-116', 'modified': '2023-11-18T03:10:29.455Z'}, {'filename': 'pytorch_model-00013-of-00015.bin', 'size': 9798109360, 'hash': 'a98c8838ad394781353923dc43687f5c-116', 'modified': '2023-11-18T03:10:30.710Z'}, {'filename': 'pytorch_model-00014-of-00015.bin', 'size': 9496134826, 'hash': '5e2cf53c3d273e9287353c1f565998c9-113', 'modified': '2023-11-18T03:10:24.610Z'}, {'filename': 'pytorch_model-00015-of-00015.bin', 'size': 524289413, 'hash': '795220f8f55fd8ee1c0b48f6a726fe1a-6', 'modified': '2023-11-18T03:05:26.444Z'}, {'filename': 'pytorch_model.bin.index.json', 'size': 59615, 'hash': '5bb77a095a762a7d1a6c3448a796f01', 'modified': '2023-11-18T03:05:26.790Z'}, {'filename': 'special_tokens_map.json', 'size': 435, 'hash': '413c7f9a8a6517c52c937eed27f1884', 'modified': '2023-11-18T03:05:27.064Z'}, {'filename': 'tokenizer.json', 'size': 1843030, 'hash': 'e4696245cb7913263030b4880dde3de', 'modified': '2023-11-18T03:05:27.897Z'}, {'filename': 'tokenizer.model', 'size': 499723, 'hash': 'eeec4125e9c7560836b4873b6f8e302', 'modified': '2023-11-18T03:05:28.163Z'}, {'filename': 'tokenizer_config.json', 'size': 812, 'hash': 'a86eaa9d2d5476d7a41d43834c0ad39', 'modified': '2023-11-18T03:05:28.262Z'}, {'filename': 'train_results.json', 'size': 190, 'hash': 'b3cf6ea7221c429a761f5af6e42f1eb', 'modified': '2023-11-18T03:05:28.734Z'}, {'filename': 'trainer_state.json', 'size': 889, 'hash': '69b91298ed1023ff6ca591ebd92f065', 'modified': '2023-11-18T03:05:28.942Z'}, {'filename': 'training_args.bin', 'size': 6392, 'hash': '02372f37a15dfc300e9a2fdd0399448', 'modified': '2023-11-18T03:05:29.188Z'}], 'config': {'prompt_format': '[INST] {prompt} [/INST]', 'stop': ['[/INST]', '</s>']}, 'worker_config': None, 'worker_template': None, 'pricing': {'hourly': 6170000000, 'input': 0, 'output': 0, 'finetune': 0, 'base': 0}, 'created_at': '2023-11-18T03:20:07.562Z', 'update_at': '2023-11-18T03:20:07.562Z', 'autopilot_pool': 'cr-a100-80-2x', 'has_wandb_telemetry': False, 'wandb_url': '', 'access': '', 'depth': {'num_asks': 0, 'num_bids': 0, 'num_running': 0, 'asks_updated': '0001-01-01T00:00:00Z', 'qps': 0, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}}, 'link': '', 'license': '', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '65677372629b5834216f25f0', 'name': 'mifu67@stanford.edu/llama-2-7b-chat-middle-han-second-10--1e-05-2023-11-29-06-01-02', 'display_type': 'chat', 'description': 'Llama 2-chat leverages publicly available instruction datasets and over 1 million human annotations. Available in three sizes: 7B, 13B and 70B parameters', 'creator_organization': 'mifu67@stanford.edu', 'hardware_label': 'L40', 'num_parameters': '6738415616', 'release_date': '2023-11-29T17:22:57.977Z', 'show_in_playground': True, 'owner': 'mifu67@stanford.edu', 'owner_address': '0xebd597774b313d8e8d22af4629b75ec7d567f678', 'owner_userid': '6552b4a556bb2d3952ed7a14', 'parent': 'togethercomputer/llama-2-7b-chat', 'base': 'togethercomputer/llama-2-7b-chat', 'path': 'r2://together-dev/finetune/6552b4a556bb2d3952ed7a14/mifu67@stanford.edu/llama-2-7b-chat-middle-han-second-10--1e-05-2023-11-29-06-01-02/ft-1c17315c-eebb-47a8-bdd9-f76272bb05ce-2023-11-29-09-18-55', 'files': [{'filename': 'added_tokens.json', 'size': 21, 'hash': 'ddfe5408fa8791d2ce96f5aeeb2bb76', 'modified': '2023-11-29T17:19:00.272Z'}, {'filename': 'config.json', 'size': 603, 'hash': 'f238117b38b277bf76354fb70287646', 'modified': '2023-11-29T17:19:00.335Z'}, {'filename': 'generation_config.json', 'size': 132, 'hash': '8cfc95df8bad11477f8efa77123af44', 'modified': '2023-11-29T17:18:59.436Z'}, {'filename': 'pytorch_model-00001-of-00002.bin', 'size': 9976620122, 'hash': '2618cbce9429b6aa8e994553f4f97730-119', 'modified': '2023-11-29T17:21:05.060Z'}, {'filename': 'pytorch_model-00002-of-00002.bin', 'size': 3500310787, 'hash': 'f942dafa770519486e133571101ea0b6-41', 'modified': '2023-11-29T17:20:05.714Z'}, {'filename': 'pytorch_model.bin.index.json', 'size': 23950, 'hash': '14bb4de8f69434fc50ee5fe1b30adea', 'modified': '2023-11-29T17:19:00.193Z'}, {'filename': 'special_tokens_map.json', 'size': 435, 'hash': '413c7f9a8a6517c52c937eed27f1884', 'modified': '2023-11-29T17:19:00.338Z'}, {'filename': 'tokenizer.model', 'size': 499723, 'hash': 'eeec4125e9c7560836b4873b6f8e302', 'modified': '2023-11-29T17:19:00.456Z'}, {'filename': 'tokenizer_config.json', 'size': 825, 'hash': '0b458d0721f67a36c18821b20b4d65f', 'modified': '2023-11-29T17:18:59.748Z'}], 'config': {'prompt_format': '[INST] {prompt} [/INST]', 'stop': ['[/INST]', '</s>'], 'chat_template_name': 'llama'}, 'worker_config': None, 'worker_template': None, 'pricing': {'hourly': 1400000000, 'input': 0, 'output': 0, 'finetune': 0, 'base': 0}, 'created_at': '2023-11-29T17:22:58.194Z', 'update_at': '2023-11-29T17:22:58.194Z', 'autopilot_pool': None, 'has_wandb_telemetry': False, 'wandb_url': '', 'access': '', 'depth': {'num_asks': 0, 'num_bids': 0, 'num_running': 0, 'asks_updated': '0001-01-01T00:00:00Z', 'qps': 0, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}}, 'link': '', 'license': '', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '6495ff1112907e072b8aecbe', 'name': 'EleutherAI/pythia-1b-v0', 'display_name': 'Pythia (1B)', 'display_type': 'language', 'description': 'The Pythia Scaling Suite is a collection of models developed to facilitate interpretability research.', 'license': '', 'link': '', 'creator_organization': 'EleutherAI', 'hardware_label': 'A40 48GB', 'pricing_tier': 'supported', 'num_parameters': 1000000000, 'show_in_playground': True, 'isFeaturedModel': False, 'context_length': 2048, 'config': {'chat_template_name': 'gpt'}, 'pricing': {'input': 25, 'output': 25, 'hourly': 0}, 'created_at': '2023-06-23T20:22:41.925Z', 'update_at': '2023-06-23T20:22:41.925Z', 'access': '', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '6495ff1412907e072b8aecf1', 'name': 'togethercomputer/codegen2-16B', 'display_name': 'CodeGen2 (16B)', 'display_type': 'code', 'description': 'An autoregressive language models for program synthesis.', 'license': '', 'link': '', 'creator_organization': 'Salesforce', 'hardware_label': 'A40 48GB', 'pricing_tier': 'supported', 'access': 'open', 'num_parameters': 16000000000, 'release_date': '2022-03-25T00:00:00.000Z', 'show_in_playground': True, 'isFeaturedModel': False, 'context_length': 2048, 'config': {'stop': ['\\n\\n'], 'chat_template_name': 'gpt'}, 'pricing': {'input': 75, 'output': 75, 'hourly': 0}, 'created_at': '2023-06-23T20:22:44.453Z', 'update_at': '2023-06-23T20:22:44.453Z', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '649e1ccca073332e47742415', 'name': 'togethercomputer/replit-code-v1-3b', 'display_name': 'Replit-Code-v1 (3B)', 'display_type': 'code', 'description': 'replit-code-v1-3b is a 2.7B Causal Language Model focused on Code Completion. The model has been trained on a subset of the Stack Dedup v1.2 dataset.', 'license': '', 'link': '', 'creator_organization': 'Replit', 'hardware_label': 'A40 48GB', 'pricing_tier': 'featured', 'access': 'limited', 'num_parameters': 3000000000, 'release_date': '2023-04-26T00:00:00.000Z', 'show_in_playground': 'true', 'isFeaturedModel': False, 'pricing': {'input': 25, 'output': 25, 'hourly': 0}, 'created_at': '2023-06-30T00:07:40.594Z', 'update_at': '2023-07-07T20:09:09.965Z', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64aceada227f790586239d11', 'name': 'togethercomputer/mpt-7b', 'display_name': 'MPT (7B)', 'display_type': 'language', 'description': 'Decoder-style transformer pretrained from scratch on 1T tokens of English text and code.', 'license': '', 'link': '', 'creator_organization': 'Mosaic ML', 'hardware_label': 'A40 48GB', 'pricing_tier': 'supported', 'access': 'open', 'num_parameters': 7000000000, 'show_in_playground': True, 'isFeaturedModel': False, 'config': {'stop': ['<|endoftext|>'], 'chat_template_name': 'default', 'add_generation_prompt': True}, 'pricing': {'input': 50, 'output': 50, 'hourly': 0}, 'created_at': '2023-07-11T05:38:34.852Z', 'update_at': '2023-07-15T03:06:20.780Z', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64aceb0e227f790586239d12', 'name': 'togethercomputer/mpt-30b-chat', 'display_name': 'MPT-Chat (30B)', 'display_type': 'chat', 'description': 'Chat model for dialogue generation finetuned on ShareGPT-Vicuna, Camel-AI, GPTeacher, Guanaco, Baize and some generated datasets.', 'license': '', 'link': '', 'creator_organization': 'Mosaic ML', 'hardware_label': 'A100 80GB', 'pricing_tier': 'supported', 'access': 'open', 'num_parameters': 30000000000, 'show_in_playground': True, 'isFeaturedModel': False, 'context_length': 2048, 'config': {'stop': ['<|im_end|>'], 'prompt_format': '<|im_start|>user\\n{prompt}<|im_end|>\\n<|im_start|>assistant', 'chat_template_name': 'default', 'add_generation_prompt': True}, 'pricing': {'input': 200, 'output': 200, 'hourly': 0}, 'created_at': '2023-07-11T05:39:26.078Z', 'update_at': '2023-07-11T05:39:26.078Z', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '6495ff1212907e072b8aecc5', 'name': 'google/flan-t5-xxl', 'display_name': 'Flan T5 XXL (11B)', 'display_type': 'language', 'description': 'Flan T5 XXL (11B parameters) is T5 fine-tuned on 1.8K tasks ([paper](https://arxiv.org/pdf/2210.11416.pdf)).', 'creator_organization': 'Google', 'hardware_label': 'A40 48GB', 'access': 'open', 'show_in_playground': True, 'isFeaturedModel': False, 'config': {'chat_template_name': 'default'}, 'pricing': {'input': 25, 'output': 25, 'hourly': 0}, 'created_at': '2023-06-23T20:22:42.261Z', 'update_at': '2023-09-01T14:35:00.161Z', 'license': '', 'link': '', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64ace6df227f790586239cfc', 'name': 'google/flan-t5-xl', 'display_name': 'Flan T5 XL (3B)', 'display_type': 'language', 'description': 'T5 fine-tuned on more than 1000 additional tasks covering also more languages, making it better than T5 at majority of tasks. ', 'license': '', 'link': '', 'creator_organization': 'Google', 'hardware_label': 'A40 48GB', 'pricing_tier': 'featured', 'access': 'open', 'num_parameters': 3000000000, 'show_in_playground': True, 'isFeaturedModel': False, 'config': {'chat_template_name': 'default'}, 'pricing': {'input': 25, 'output': 25, 'hourly': 0}, 'created_at': '2023-06-23T20:22:42.261Z', 'update_at': '2023-06-23T20:22:42.261Z', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64aceb6f227f790586239d15', 'name': 'togethercomputer/mpt-7b-instruct', 'display_name': 'MPT-Instruct (7B)', 'display_type': 'language', 'description': 'Designed for short-form instruction following, finetuned on Dolly and Anthropic HH-RLHF and other datasets', 'license': '', 'link': '', 'creator_organization': 'Mosaic ML', 'hardware_label': 'A40 48GB', 'pricing_tier': 'supported', 'access': 'open', 'num_parameters': 7000000000, 'show_in_playground': True, 'isFeaturedModel': False, 'config': {'stop': ['<|endoftext|>'], 'chat_template_name': 'default', 'add_generation_prompt': True}, 'pricing': {'input': 50, 'output': 50, 'hourly': 0}, 'created_at': '2023-07-11T05:41:03.757Z', 'update_at': '2023-07-11T05:41:03.757Z', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64acebe0227f790586239d17', 'name': 'NumbersStation/nsql-6B', 'display_name': 'NSQL (6B)', 'display_type': 'language', 'description': 'Foundation model designed specifically for SQL generation tasks. Pre-trained for 3 epochs and fine-tuned for 10 epochs.', 'license': '', 'creator_organization': 'Numbers Station', 'hardware_label': 'A40 48GB', 'pricing_tier': 'supported', 'access': 'open', 'num_parameters': 6000000000, 'show_in_playground': True, 'isFeaturedModel': False, 'config': {'stop': ['<|endoftext|>'], 'chat_template_name': 'default'}, 'pricing': {'input': 50, 'output': 50, 'hourly': 0}, 'created_at': '2023-07-11T05:42:56.540Z', 'update_at': '2023-07-11T05:42:56.540Z', 'link': '', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64ace9ca227f790586239d09', 'name': 'togethercomputer/Koala-7B', 'display_name': 'Koala (7B)', 'display_type': 'chat', 'description': 'Chatbot trained by fine-tuning LLaMA on dialogue data gathered from the web.', 'license': '', 'link': '', 'creator_organization': 'LM Sys', 'hardware_label': 'A40 48GB', 'pricing_tier': 'featured', 'access': 'open', 'num_parameters': 7000000000, 'show_in_playground': True, 'isFeaturedModel': False, 'config': {'stop': ['</s>'], 'prompt_format': 'USER: {prompt} GPT:', 'chat_template': \"{% for message in messages %}{% if message['role'] == 'user' %}{{ 'USER: ' + message['content'] + ' ' }}{% else %}{{ 'GPT: ' + message['content'] + '\\n' }}{% endif %}{% endfor %}{{ 'GPT:' }}\"}, 'pricing': {'input': 50, 'output': 50, 'hourly': 0}, 'created_at': '2023-07-11T05:34:02.521Z', 'update_at': '2023-07-11T05:34:02.521Z', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '6495ff1212907e072b8aecc0', 'name': 'EleutherAI/pythia-6.9b', 'display_name': 'Pythia (6.9B)', 'display_type': 'language', 'description': 'The Pythia Scaling Suite is a collection of models developed to facilitate interpretability research.', 'license': '', 'creator_organization': 'EleutherAI', 'hardware_label': 'A40 48GB', 'pricing_tier': 'featured', 'num_parameters': 6900000000, 'show_in_playground': True, 'isFeaturedModel': False, 'context_length': 2048, 'config': {'stop': ['<|endoftext|>'], 'chat_template_name': 'gpt'}, 'pricing': {'input': 50, 'output': 50, 'hourly': 0}, 'created_at': '2023-06-23T20:22:42.044Z', 'update_at': '2023-06-23T20:22:42.044Z', 'access': '', 'link': '', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '6495ff1112907e072b8aecb8', 'name': 'databricks/dolly-v2-12b', 'display_name': 'Dolly v2 (12B)', 'display_type': 'chat', 'description': 'An instruction-following LLM based on pythia-12b, and trained on ~15k instruction/response fine tuning records generated by Databricks employees.', 'license': '', 'link': '', 'creator_organization': 'Databricks', 'hardware_label': 'A40 48GB', 'pricing_tier': 'supported', 'num_parameters': 12000000000, 'show_in_playground': True, 'isFeaturedModel': False, 'context_length': 2048, 'config': {'stop': ['### End'], 'prompt_format': '### Instruction:\\n{prompt}\\n### Response:', 'chat_template': \"{% for message in messages %}{% if message['role'] == 'user' %}{{ '### Instruction:\\n' + message['content'] + '\\n' }}{% else %}{{ '### Response:\\n' + message['content'] + '\\n' }}{% endif %}{% endfor %}{{ '### Response:' }}\"}, 'pricing': {'input': 75, 'output': 75, 'hourly': 0}, 'created_at': '2023-06-23T20:22:41.607Z', 'update_at': '2023-06-23T20:22:41.607Z', 'access': '', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '6495ff1112907e072b8aecb6', 'name': 'databricks/dolly-v2-3b', 'display_name': 'Dolly v2 (3B)', 'display_type': 'chat', 'description': 'An instruction-following LLM based on pythia-3b, and trained on ~15k instruction/response fine tuning records generated by Databricks employees.', 'license': '', 'link': '', 'creator_organization': 'Databricks', 'hardware_label': 'A40 48GB', 'pricing_tier': 'supported', 'num_parameters': 3000000000, 'show_in_playground': True, 'isFeaturedModel': False, 'context_length': 2048, 'config': {'stop': ['### End'], 'prompt_format': '### Instruction:\\n{prompt}\\n### Response:', 'chat_template': \"{% for message in messages %}{% if message['role'] == 'user' %}{{ '### Instruction:\\n' + message['content'] + '\\n' }}{% else %}{{ '### Response:\\n' + message['content'] + '\\n' }}{% endif %}{% endfor %}{{ '### Response:' }}\"}, 'pricing': {'input': 25, 'output': 25, 'hourly': 0}, 'created_at': '2023-06-23T20:22:41.524Z', 'update_at': '2023-06-23T20:22:41.524Z', 'access': '', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '6495ff1212907e072b8aecc2', 'name': 'EleutherAI/gpt-neox-20b', 'display_name': 'GPT-NeoX (20B)', 'display_type': 'language', 'description': 'Autoregressive language model trained on the Pile. Its architecture intentionally resembles that of GPT-3, and is almost identical to that of GPT-J 6B.', 'license': '', 'link': '', 'creator_organization': 'EleutherAI', 'hardware_label': 'A40 48GB', 'pricing_tier': 'supported', 'num_parameters': 20000000000, 'show_in_playground': True, 'isFeaturedModel': False, 'config': {'chat_template_name': 'gpt'}, 'pricing': {'input': 75, 'output': 75, 'hourly': 0}, 'created_at': '2023-06-23T20:22:42.132Z', 'update_at': '2023-06-23T20:22:42.132Z', 'access': '', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '6495ff1112907e072b8aecbf', 'name': 'EleutherAI/pythia-2.8b-v0', 'display_name': 'Pythia (2.8B)', 'display_type': 'language', 'description': 'The Pythia Scaling Suite is a collection of models developed to facilitate interpretability research.', 'license': '', 'creator_organization': 'EleutherAI', 'hardware_label': 'A40 48GB', 'num_parameters': 2800000000, 'show_in_playground': True, 'isFeaturedModel': False, 'context_length': 2048, 'config': {'stop': ['<|endoftext|>'], 'chat_template_name': 'gpt'}, 'pricing': {'input': 25, 'output': 25, 'hourly': 0}, 'created_at': '2023-06-23T20:22:41.975Z', 'update_at': '2023-06-23T20:22:41.975Z', 'access': '', 'link': '', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64acebb2227f790586239d16', 'name': 'NousResearch/Nous-Hermes-13b', 'display_name': 'Nous Hermes (13B)', 'display_type': 'language', 'description': 'LLaMA 13B fine-tuned on over 300,000 instructions. Designed for long responses, low hallucination rate, and absence of censorship mechanisms.', 'license': '', 'link': '', 'creator_organization': 'Nous Research', 'hardware_label': 'A40 48GB', 'pricing_tier': 'supported', 'access': 'open', 'num_parameters': 13000000000, 'show_in_playground': True, 'isFeaturedModel': False, 'context_length': 2048, 'config': {'chat_template_name': 'llama', 'chat_template': \"{% for message in messages %}{% if message['role'] == 'user' %}{{ '### Instruction:\\n' + message['content'] + '\\n' }}{% else %}{{ '### Response:\\n' + message['content'] + '\\n' }}{% endif %}{% endfor %}{{ '### Response:\\n' }}\"}, 'pricing': {'input': 75, 'output': 75, 'hourly': 0}, 'created_at': '2023-07-11T05:42:10.444Z', 'update_at': '2023-07-11T05:42:10.444Z', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64ace8d1227f790586239d03', 'name': 'togethercomputer/guanaco-65b', 'display_name': 'Guanaco (65B) ', 'display_type': 'chat', 'description': 'Instruction-following language model built on LLaMA. Expanding upon the initial 52K dataset from the Alpaca model, an additional 534,530 focused on multi-lingual tasks.', 'license': '', 'link': '', 'creator_organization': 'Tim Dettmers', 'hardware_label': '2X A100 80GB', 'pricing_tier': 'Supported', 'access': 'open', 'num_parameters': 65000000000, 'show_in_playground': True, 'isFeaturedModel': False, 'context_length': 2048, 'config': {'stop': ['###'], 'prompt_format': '### Human: {prompt} ### Assistant:', 'chat_template': \"{% for message in messages %}{% if message['role'] == 'user' %}{{ '### Human: ' + message['content'] + ' ' }}{% else %}{{ '### Assistant: ' + message['content'] + '\\n' }}{% endif %}{% endfor %}{{ '### Assistant:' }}\"}, 'pricing': {'input': 225, 'output': 225, 'hourly': 0}, 'created_at': '2023-07-11T05:29:53.740Z', 'update_at': '2023-07-11T05:29:53.740Z', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64acec99227f790586239d1c', 'name': 'OpenAssistant/oasst-sft-6-llama-30b-xor', 'display_name': 'Open-Assistant LLaMA SFT-6 (30B)', 'display_type': 'chat', 'description': 'Chat-based and open-source assistant. The vision of the project is to make a large language model that can run on a single high-end consumer GPU. ', 'license': '', 'link': '', 'creator_organization': 'LAION', 'hardware_label': 'A100 80GB', 'pricing_tier': 'supported', 'show_in_playground': True, 'isFeaturedModel': False, 'config': {'stop': ['<|endoftext|>'], 'prompt_format': '<|prompter|>{prompt}<|endoftext|><|assistant|>', 'chat_template': \"{% for message in messages %}{% if message['role'] == 'user' %}{{ '<|prompter|>' + message['content'] + '<|endoftext|>' }}{% else %}{{ '<|assistant|>' + message['content'] + '<|endoftext|>\\n' }}{% endif %}{% endfor %}{{ '<|assistant|>' }}\"}, 'pricing': {'input': 25, 'output': 25, 'hourly': 0}, 'created_at': '2023-06-23T20:22:42.469Z', 'update_at': '2023-06-23T20:22:42.469Z', 'access': '', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64ace955227f790586239d06', 'name': 'Salesforce/instructcodet5p-16b', 'display_name': 'InstructCodeT5 (16B)', 'display_type': 'chat', 'description': 'Code large language model that can flexibly operate in different modes to support a wide range of code understanding and generation tasks. ', 'license': '', 'link': '', 'creator_organization': 'Salesforce', 'hardware_label': 'A40 48GB', 'pricing_tier': 'supported', 'access': 'open', 'num_parameters': 33000000000, 'show_in_playground': True, 'isFeaturedModel': False, 'config': {'chat_template_name': 'default'}, 'pricing': {'input': 200, 'output': 200, 'hourly': 0}, 'created_at': '2023-07-11T05:32:05.369Z', 'update_at': '2023-07-11T05:32:05.369Z', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64acf031227f790586239d44', 'name': 'lmsys/fastchat-t5-3b-v1.0', 'display_name': 'Vicuna-FastChat-T5 (3B)', 'display_type': 'chat', 'description': 'Chatbot trained by fine-tuning Flan-t5-xl on user-shared conversations collected from ShareGPT.', 'license': '', 'link': '', 'creator_organization': 'LM Sys', 'hardware_label': 'A40 48GB', 'pricing_tier': 'featured', 'num_parameters': 3000000000, 'show_in_playground': True, 'isFeaturedModel': False, 'context_length': 512, 'config': {'stop': ['###', '</s>'], 'prompt_format': '### Human: {prompt}\\n### Assistant:', 'chat_template': \"{% for message in messages %}{% if message['role'] == 'user' %}{{ '### Human: ' + message['content'] + '\\n' }}{% else %}{{ '### Assistant: ' + message['content'] + '\\n' }}{% endif %}{% endfor %}{{ '### Assistant:' }}\"}, 'pricing': {'input': 25, 'output': 25, 'hourly': 0}, 'created_at': '2023-07-11T06:01:21.713Z', 'update_at': '2023-07-11T06:01:21.713Z', 'access': '', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64acea6e227f790586239d0e', 'name': 'huggyllama/llama-7b', 'display_name': 'LLaMA (7B)', 'display_type': 'language', 'description': 'An auto-regressive language model, based on the transformer architecture. The model comes in different sizes: 7B, 13B, 33B and 65B parameters.', 'license': '', 'link': '', 'creator_organization': 'Meta', 'hardware_label': 'A100 80GB', 'pricing_tier': 'supported', 'access': 'open', 'num_parameters': 7000000000, 'show_in_playground': True, 'isFeaturedModel': False, 'context_length': 2048, 'config': {'chat_template_name': 'llama'}, 'pricing': {'input': 50, 'output': 50, 'hourly': 0}, 'created_at': '2023-07-11T05:36:46.255Z', 'update_at': '2023-07-11T05:36:46.255Z', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '6495ff1212907e072b8aecc9', 'name': 'OpenAssistant/stablelm-7b-sft-v7-epoch-3', 'display_name': 'Open-Assistant StableLM SFT-7 (7B)', 'display_type': 'chat', 'description': 'Chat-based and open-source assistant. The vision of the project is to make a large language model that can run on a single high-end consumer GPU. ', 'license': '', 'link': '', 'creator_organization': 'LAION', 'hardware_label': 'A40 48GB', 'pricing_tier': 'supported', 'num_parameters': 7000000000, 'show_in_playground': True, 'isFeaturedModel': False, 'context_length': 4096, 'config': {'stop': ['<|endoftext|>'], 'prompt_format': '<|prompter|>{prompt}<|endoftext|><|assistant|>', 'chat_template': \"{% for message in messages %}{% if message['role'] == 'user' %}{{ '<|prompter|>' + message['content'] + '<|endoftext|>' }}{% else %}{{ '<|assistant|>' + message['content'] + '<|endoftext|>\\n' }}{% endif %}{% endfor %}{{ '<|assistant|>' }}\"}, 'pricing': {'input': 50, 'output': 50, 'hourly': 0}, 'created_at': '2023-06-23T20:22:42.425Z', 'update_at': '2023-06-23T20:22:42.425Z', 'access': '', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '6495ff1212907e072b8aecc1', 'name': 'EleutherAI/pythia-12b-v0', 'display_name': 'Pythia (12B)', 'display_type': 'language', 'description': 'The Pythia Scaling Suite is a collection of models developed to facilitate interpretability research.', 'license': '', 'link': '', 'creator_organization': 'EleutherAI', 'hardware_label': 'A40 48GB', 'pricing_tier': 'supported', 'num_parameters': 12000000000, 'show_in_playground': True, 'isFeaturedModel': False, 'context_length': 2048, 'config': {'stop': ['<|endoftext|>'], 'chat_template_name': 'gpt'}, 'pricing': {'input': 75, 'output': 75, 'hourly': 0}, 'created_at': '2023-06-23T20:22:42.091Z', 'update_at': '2023-06-23T20:22:42.091Z', 'access': '', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64aceb28227f790586239d13', 'name': 'togethercomputer/mpt-7b-chat', 'display_name': 'MPT-Chat (7B)', 'display_type': 'chat', 'description': 'Chat model for dialogue generation finetuned on ShareGPT-Vicuna, Camel-AI, GPTeacher, Guanaco, Baize and some generated datasets.', 'license': '', 'link': '', 'creator_organization': 'Mosaic ML', 'hardware_label': 'A40 48GB', 'pricing_tier': 'supported', 'access': 'open', 'num_parameters': 7000000000, 'show_in_playground': True, 'isFeaturedModel': False, 'context_length': 2048, 'config': {'stop': ['<|im_end|>'], 'prompt_format': '<|im_start|>user\\n{prompt}<|im_end|>\\n<|im_start|>assistant', 'chat_template_name': 'default', 'add_generation_prompt': True}, 'pricing': {'input': 50, 'output': 50, 'hourly': 0}, 'created_at': '2023-07-11T05:39:52.024Z', 'update_at': '2023-07-11T05:39:52.024Z', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '6495ff1212907e072b8aecc8', 'name': 'OpenAssistant/oasst-sft-4-pythia-12b-epoch-3.5', 'display_name': 'Open-Assistant Pythia SFT-4 (12B)', 'display_type': 'chat', 'description': 'Chat-based and open-source assistant. The vision of the project is to make a large language model that can run on a single high-end consumer GPU. ', 'license': '', 'link': '', 'creator_organization': 'LAION', 'hardware_label': 'A40 48GB', 'pricing_tier': 'supported', 'num_parameters': 12000000000, 'show_in_playground': True, 'isFeaturedModel': False, 'context_length': 2048, 'config': {'stop': ['<|endoftext|>'], 'prompt_format': '<|prompter|>{prompt}<|endoftext|><|assistant|>', 'chat_template': \"{% for message in messages %}{% if message['role'] == 'user' %}{{ '<|prompter|>' + message['content'] + '<|endoftext|>' }}{% else %}{{ '<|assistant|>' + message['content'] + '<|endoftext|>\\n' }}{% endif %}{% endfor %}{{ '<|assistant|>' }}\"}, 'pricing': {'input': 75, 'output': 75, 'hourly': 0}, 'created_at': '2023-06-23T20:22:42.383Z', 'update_at': '2023-06-23T20:22:42.383Z', 'access': '', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '6495ff1112907e072b8aecbc', 'name': 'EleutherAI/gpt-j-6b', 'display_name': 'GPT-J (6B)', 'display_type': 'language', 'description': \"Transformer model trained using Ben Wang's Mesh Transformer JAX. \", 'license': '', 'link': '', 'creator_organization': 'EleutherAI', 'hardware_label': 'A40 48GB', 'pricing_tier': 'supported', 'access': 'open', 'num_parameters': 6000000000, 'release_date': '2021-06-04T00:00:00.000Z', 'show_in_playground': True, 'isFeaturedModel': False, 'config': {'chat_template_name': 'gpt'}, 'pricing': {'input': 50, 'output': 50, 'hourly': 0}, 'created_at': '2023-06-23T20:22:41.831Z', 'update_at': '2023-06-23T20:22:41.831Z', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64acf013227f790586239d43', 'name': 'lmsys/vicuna-7b-v1.3', 'display_name': 'Vicuna v1.3 (7B)', 'display_type': 'chat', 'description': 'Chatbot trained by fine-tuning LLaMA on user-shared conversations collected from ShareGPT. Auto-regressive model, based on the transformer architecture.', 'license': '', 'link': '', 'creator_organization': 'LM Sys', 'hardware_label': 'A40 48GB', 'pricing_tier': 'supported', 'access': 'open', 'num_parameters': 7000000000, 'show_in_playground': True, 'isFeaturedModel': False, 'context_length': 2048, 'config': {'stop': ['</s>'], 'prompt_format': 'USER: {prompt}\\nASSISTANT:', 'chat_template': \"{% for message in messages %}{{message['role'].toLocaleUpperCase() + ': ' + message['content'] + '\\n'}}{% endfor %}{{ 'ASSISTANT:' }}\"}, 'pricing': {'input': 50, 'output': 50, 'hourly': 0}, 'created_at': '2023-07-11T06:00:51.553Z', 'update_at': '2023-07-11T06:00:51.553Z', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64ace476227f790586239cef', 'name': 'togethercomputer/codegen2-7B', 'display_name': 'CodeGen2 (7B)', 'display_type': 'code', 'description': 'An autoregressive language models for program synthesis.', 'license': '', 'link': '', 'creator_organization': 'Salesforce', 'hardware_label': 'A40 48GB', 'pricing_tier': 'supported', 'access': 'open', 'num_parameters': 7000000000, 'release_date': '2022-03-25T00:00:00.000Z', 'show_in_playground': True, 'isFeaturedModel': False, 'context_length': 2048, 'config': {'stop': ['\\n\\n'], 'chat_template_name': 'gpt'}, 'pricing': {'input': 50, 'output': 50, 'hourly': 0}, 'created_at': '2023-07-11T05:11:18.328Z', 'update_at': '2023-07-11T05:11:18.328Z', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64f0de22caa9e2eb543b373b', 'name': 'togethercomputer/guanaco-13b', 'display_name': 'Guanaco (13B) ', 'display_type': 'chat', 'description': 'Instruction-following language model built on LLaMA. Expanding upon the initial 52K dataset from the Alpaca model, an additional 534,530 focused on multi-lingual tasks.', 'license': '', 'link': '', 'creator_organization': 'Tim Dettmers', 'hardware_label': 'A40 48GB', 'pricing_tier': 'Supported', 'access': 'open', 'num_parameters': 13000000000, 'show_in_playground': True, 'isFeaturedModel': False, 'context_length': 2048, 'config': {'stop': ['###'], 'prompt_format': '### Human: {prompt} ### Assistant:', 'chat_template': \"{% for message in messages %}{% if message['role'] == 'user' %}{{ '### Human: ' + message['content'] + ' ' }}{% else %}{{ '### Assistant: ' + message['content'] + '\\n' }}{% endif %}{% endfor %}{{ '### Assistant:' }}\"}, 'pricing': {'input': 75, 'output': 75, 'hourly': 0}, 'created_at': '2023-07-11T05:29:07.717Z', 'update_at': '2023-07-11T05:29:07.717Z', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64acefe5227f790586239d41', 'name': 'lmsys/vicuna-13b-v1.3', 'display_name': 'Vicuna v1.3 (13B)', 'display_type': 'chat', 'description': 'Chatbot trained by fine-tuning LLaMA on user-shared conversations collected from ShareGPT. Auto-regressive model, based on the transformer architecture.', 'license': '', 'link': '', 'creator_organization': 'LM Sys', 'hardware_label': 'A40 48GB', 'pricing_tier': 'supported', 'access': 'open', 'num_parameters': 13000000000, 'show_in_playground': True, 'isFeaturedModel': False, 'context_length': 2048, 'config': {'stop': ['</s>'], 'prompt_format': 'USER: {prompt}\\nASSISTANT:', 'chat_template': \"{% for message in messages %}{{message['role'].toLocaleUpperCase() + ': ' + message['content'] + '\\n'}}{% endfor %}{{ 'ASSISTANT:' }}\"}, 'pricing': {'input': 75, 'output': 75, 'hourly': 0}, 'created_at': '2023-07-11T06:00:05.166Z', 'update_at': '2023-07-15T03:08:44.173Z', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64acea0b227f790586239d0b', 'name': 'huggyllama/llama-13b', 'display_name': 'LLaMA (13B)', 'display_type': 'language', 'description': 'An auto-regressive language model, based on the transformer architecture. The model comes in different sizes: 7B, 13B, 33B and 65B parameters.', 'license': '', 'link': '', 'creator_organization': 'Meta', 'hardware_label': 'A100 80GB', 'pricing_tier': 'supported', 'access': 'open', 'num_parameters': 13000000000, 'show_in_playground': True, 'isFeaturedModel': False, 'context_length': 2048, 'config': {'chat_template_name': 'llama'}, 'pricing': {'input': 75, 'output': 75, 'hourly': 0}, 'created_at': '2023-07-11T05:35:07.955Z', 'update_at': '2023-07-11T05:35:07.955Z', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64acefbe227f790586239d40', 'name': 'HuggingFaceH4/starchat-alpha', 'display_name': 'StarCoderChat Alpha (16B)', 'display_type': 'chat', 'description': 'Fine-tuned from StarCoder to act as a helpful coding assistant. As an alpha release is only intended for educational or research purpopses.', 'license': '', 'link': '', 'creator_organization': 'HuggingFaceH4', 'hardware_label': 'A40 48GB', 'pricing_tier': 'supported', 'num_parameters': 16000000000, 'show_in_playground': True, 'isFeaturedModel': False, 'context_length': 8192, 'config': {'stop': ['<|endoftext|>', '<|end|>'], 'prompt_format': '<|system|>\\n<|end|>\\n<|user|>\\n{prompt}<|end|>\\n<|assistant|>', 'chat_template_name': 'default'}, 'pricing': {'input': 75, 'output': 75, 'hourly': 0}, 'created_at': '2023-07-11T05:59:26.298Z', 'update_at': '2023-07-11T05:59:26.298Z', 'access': '', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64acea35227f790586239d0c', 'name': 'huggyllama/llama-30b', 'display_name': 'LLaMA (30B)', 'display_type': 'language', 'description': 'An auto-regressive language model, based on the transformer architecture. The model comes in different sizes: 7B, 13B, 33B and 65B parameters.', 'license': '', 'link': '', 'creator_organization': 'Meta', 'hardware_label': 'A100 80GB', 'access': 'open', 'num_parameters': 33000000000, 'show_in_playground': True, 'isFeaturedModel': False, 'context_length': 2048, 'config': {'chat_template_name': 'llama'}, 'pricing': {'input': 200, 'output': 200, 'hourly': 0}, 'created_at': '2023-07-11T05:35:49.870Z', 'update_at': '2023-07-11T05:35:49.870Z', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '6495ff1512907e072b8aecf5', 'name': 'stabilityai/stablelm-base-alpha-7b', 'display_name': 'StableLM-Base-Alpha (7B)', 'display_type': 'language', 'description': 'Decoder-only language model pre-trained on a diverse collection of English and Code datasets with a sequence length of 4096.', 'license': '', 'link': '', 'creator_organization': 'Stability AI', 'hardware_label': 'A40 48GB', 'pricing_tier': 'supported', 'num_parameters': 7000000000, 'show_in_playground': True, 'isFeaturedModel': False, 'config': {'chat_template_name': 'gpt'}, 'pricing': {'input': 50, 'output': 50, 'hourly': 0}, 'created_at': '2023-06-23T20:22:45.249Z', 'update_at': '2023-06-23T20:22:45.249Z', 'access': '', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '6495ff1412907e072b8aecf4', 'name': 'stabilityai/stablelm-base-alpha-3b', 'display_name': 'StableLM-Base-Alpha (3B)', 'display_type': 'language', 'description': 'Decoder-only language model pre-trained on a diverse collection of English and Code datasets with a sequence length of 4096.', 'license': '', 'link': '', 'creator_organization': 'Stability AI', 'hardware_label': 'A40 48GB', 'pricing_tier': 'supported', 'num_parameters': 3000000000, 'show_in_playground': True, 'isFeaturedModel': False, 'config': {'chat_template_name': 'gpt'}, 'pricing': {'input': 25, 'output': 25, 'hourly': 0}, 'created_at': '2023-06-23T20:22:44.907Z', 'update_at': '2023-06-23T20:22:44.907Z', 'access': '', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64f67987bc372ce719b97f07', 'name': 'defog/sqlcoder', 'display_name': 'Sqlcoder (15B)', 'display_type': 'language', 'description': \"Defog's SQLCoder is a state-of-the-art LLM for converting natural language questions to SQL queries, fine-tuned from Bigcode's Starcoder 15B model.\", 'license': '', 'creator_organization': 'Defog', 'hardware_label': 'A40 48GB', 'pricing_tier': 'supported', 'access': 'open', 'num_parameters': 15000000000, 'show_in_playground': True, 'isFeaturedModel': False, 'context_length': 8192, 'config': {'stop': ['<|endoftext|>'], 'prompt_format': '### Instructions:\\n\\n{prompt}\\n\\n### Response:\\n'}, 'pricing': {'input': 75, 'output': 75, 'hourly': 0}, 'created_at': '2023-09-05T00:42:47.496Z', 'update_at': '2023-09-05T00:42:47.496Z', 'link': '', 'descriptionLink': ''}]\n",
      "117 models available\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import json\n",
    "import together\n",
    "from apikey import TOG_KEY\n",
    "\n",
    "OLD_HAN_PATH = './trainingdata/hansolo/old-han-data.jsonl'\n",
    "# PROTECTED_PATH = './trainingdata/hansolo/young-han-protective-new.jsonl'\n",
    "\n",
    "together.api_key = TOG_KEY\n",
    "\n",
    "model_list = together.Models.list()\n",
    "print(model_list[:-5])\n",
    "\n",
    "print(f\"{len(model_list)} models available\")\n",
    "\n",
    "# print the first 10 models on the menu\n",
    "# model_names = [model_dict['name'] for model_dict in model_list]\n",
    "# print(model_names[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading ./trainingdata/hansolo/old-han-data.jsonl: 100%|| 2.79M/2.79M [00:00<00:00, 3.09MB/s]\n"
     ]
    }
   ],
   "source": [
    "resp = together.Files.upload(file=OLD_HAN_PATH)\n",
    "file_id = resp[\"id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'filename': 'young-han-data-new.jsonl',\n",
       "  'bytes': 948468,\n",
       "  'created_at': 1700686846,\n",
       "  'id': 'file-10d2233d-0f67-4457-9baa-59ef5c874dac',\n",
       "  'purpose': 'fine-tune',\n",
       "  'object': 'file',\n",
       "  'LineCount': 0,\n",
       "  'Processed': True},\n",
       " {'filename': 'han-data.jsonl',\n",
       "  'bytes': 2208884,\n",
       "  'created_at': 1700805318,\n",
       "  'id': 'file-5350fa6b-2ad1-4a4d-8717-fcb1522be037',\n",
       "  'purpose': 'fine-tune',\n",
       "  'object': 'file',\n",
       "  'LineCount': 0,\n",
       "  'Processed': True},\n",
       " {'filename': 'old-han-data.jsonl',\n",
       "  'bytes': 2920963,\n",
       "  'created_at': 1700949437,\n",
       "  'id': 'file-04c71832-ca56-45de-81af-483b42b70b7b',\n",
       "  'purpose': 'fine-tune',\n",
       "  'object': 'file',\n",
       "  'LineCount': 0,\n",
       "  'Processed': True}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files_list = together.Files.list()\n",
    "files_list['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'file-bb280f38-2b64-42a9-9349-6e7eb2ad2d05',\n",
       " 'object': 'file',\n",
       " 'deleted': 'true'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "together.Files.delete('file-bb280f38-2b64-42a9-9349-6e7eb2ad2d05')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'training_file': 'file-5350fa6b-2ad1-4a4d-8717-fcb1522be037', 'validation_file': '', 'model_output_name': 'mifu67@stanford.edu/llama-2-7b-chat-middle-han-second-10--1e-05-2023-11-29-06-01-02', 'model_output_path': 's3://together-dev/finetune/6552b4a556bb2d3952ed7a14/mifu67@stanford.edu/llama-2-7b-chat-middle-han-second-10--1e-05-2023-11-29-06-01-02/ft-1c17315c-eebb-47a8-bdd9-f76272bb05ce', 'Suffix': 'middle-han-second-10--1e-05', 'model': 'togethercomputer/llama-2-7b-chat', 'n_epochs': 10, 'n_checkpoints': 1, 'batch_size': 4, 'learning_rate': 1e-05, 'user_id': '6552b4a556bb2d3952ed7a14', 'lora': False, 'lora_r': 8, 'lora_alpha': 8, 'lora_dropout': 0, 'staring_epoch': 0, 'training_offset': 0, 'checkspoint_path': '', 'random_seed': '', 'created_at': '2023-11-29T06:01:02.988Z', 'updated_at': '2023-11-29T06:01:02.988Z', 'status': 'pending', 'owner_address': '0xebd597774b313d8e8d22af4629b75ec7d567f678', 'id': 'ft-1c17315c-eebb-47a8-bdd9-f76272bb05ce', 'job_id': '', 'token_count': 0, 'param_count': 0, 'total_price': 0, 'epochs_completed': 0, 'events': [{'object': 'fine-tune-event', 'created_at': '2023-11-29T06:01:02.988Z', 'level': '', 'message': 'Fine tune request created', 'type': 'JOB_PENDING', 'param_count': 0, 'token_count': 0, 'wandb_url': '', 'checkpoint_path': '', 'model_path': '', 'training_offset': 0, 'hash': ''}], 'queue_depth': 0, 'wandb_key': '', 'wandb_project_name': '', 'wandb_url': '', 'enable_checkpoints': False, 'internal_flags': ''}\n"
     ]
    }
   ],
   "source": [
    "n_ep = 10\n",
    "lr = 1e-5\n",
    "\n",
    "resp = together.Finetune.create(\n",
    "  training_file = 'file-5350fa6b-2ad1-4a4d-8717-fcb1522be037',\n",
    "  model = 'togethercomputer/llama-2-7b-chat',\n",
    "  n_epochs = n_ep,\n",
    "  n_checkpoints = 1,\n",
    "  batch_size = 4,\n",
    "  learning_rate = lr,\n",
    "  suffix = f'middle-han-second-{n_ep}--{lr}',\n",
    ")\n",
    "\n",
    "fine_tune_id = resp['id']\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'training_file': 'file-5350fa6b-2ad1-4a4d-8717-fcb1522be037',\n",
       " 'validation_file': '',\n",
       " 'model_output_name': 'mifu67@stanford.edu/llama-2-7b-chat-middle-han-second-10--1e-05-2023-11-29-06-01-02',\n",
       " 'model_output_path': 's3://together-dev/finetune/6552b4a556bb2d3952ed7a14/mifu67@stanford.edu/llama-2-7b-chat-middle-han-second-10--1e-05-2023-11-29-06-01-02/ft-1c17315c-eebb-47a8-bdd9-f76272bb05ce-2023-11-29-09-18-55',\n",
       " 'Suffix': 'middle-han-second-10--1e-05',\n",
       " 'model': 'togethercomputer/llama-2-7b-chat',\n",
       " 'n_epochs': 10,\n",
       " 'n_checkpoints': 1,\n",
       " 'batch_size': 4,\n",
       " 'learning_rate': 1e-05,\n",
       " 'user_id': '6552b4a556bb2d3952ed7a14',\n",
       " 'lora': False,\n",
       " 'lora_r': 8,\n",
       " 'lora_alpha': 8,\n",
       " 'lora_dropout': 0,\n",
       " 'staring_epoch': 0,\n",
       " 'training_offset': 0,\n",
       " 'checkspoint_path': '',\n",
       " 'random_seed': '',\n",
       " 'created_at': '2023-11-29T06:01:02.988Z',\n",
       " 'updated_at': '2023-11-29T17:22:57.957Z',\n",
       " 'status': 'completed',\n",
       " 'owner_address': '0xebd597774b313d8e8d22af4629b75ec7d567f678',\n",
       " 'id': 'ft-1c17315c-eebb-47a8-bdd9-f76272bb05ce',\n",
       " 'job_id': '7049',\n",
       " 'token_count': 688510,\n",
       " 'param_count': 6738415616,\n",
       " 'total_price': 5000000000,\n",
       " 'epochs_completed': 10,\n",
       " 'events': [{'object': 'fine-tune-event',\n",
       "   'created_at': '2023-11-29T06:01:02.988Z',\n",
       "   'level': '',\n",
       "   'message': 'Fine tune request created',\n",
       "   'type': 'JOB_PENDING',\n",
       "   'param_count': 0,\n",
       "   'token_count': 0,\n",
       "   'wandb_url': '',\n",
       "   'checkpoint_path': '',\n",
       "   'model_path': '',\n",
       "   'training_offset': 0,\n",
       "   'hash': ''},\n",
       "  {'object': 'fine-tune-event',\n",
       "   'created_at': '2023-11-29T17:00:54.578Z',\n",
       "   'level': 'info',\n",
       "   'message': 'Job started at Wed Nov 29 09:00:53 PST 2023',\n",
       "   'type': 'JOB_START',\n",
       "   'param_count': 0,\n",
       "   'token_count': 0,\n",
       "   'wandb_url': '',\n",
       "   'checkpoint_path': '',\n",
       "   'model_path': '',\n",
       "   'training_offset': 0,\n",
       "   'hash': '8497730042872359476'},\n",
       "  {'object': 'fine-tune-event',\n",
       "   'created_at': '2023-11-29T17:02:13.287Z',\n",
       "   'level': 'info',\n",
       "   'message': 'Model data downloaded for togethercomputer/llama-2-7b-chat at Wed Nov 29 09:02:12 PST 2023',\n",
       "   'type': 'MODEL_DOWNLOAD_COMPLETE',\n",
       "   'param_count': 0,\n",
       "   'token_count': 0,\n",
       "   'wandb_url': '',\n",
       "   'checkpoint_path': '',\n",
       "   'model_path': '',\n",
       "   'training_offset': 0,\n",
       "   'hash': '-2941435665401099257'},\n",
       "  {'object': 'fine-tune-event',\n",
       "   'created_at': '2023-11-29T17:02:15.56Z',\n",
       "   'level': 'info',\n",
       "   'message': 'Training data downloaded for togethercomputer/llama-2-7b-chat at Wed Nov 29 09:02:14 PST 2023',\n",
       "   'type': 'TRAINING_DATA_DOWNLOAD_COMPLETE',\n",
       "   'param_count': 0,\n",
       "   'token_count': 0,\n",
       "   'wandb_url': '',\n",
       "   'checkpoint_path': '',\n",
       "   'model_path': '',\n",
       "   'training_offset': 0,\n",
       "   'hash': '4324118787525346890'},\n",
       "  {'object': 'fine-tune-event',\n",
       "   'created_at': '2023-11-29T17:02:50.141Z',\n",
       "   'level': 'info',\n",
       "   'message': 'Training started for model /work/job-ft-1c17315c-eebb-47a8-bdd9-f76272bb05ce/model',\n",
       "   'type': 'TRAINING_START',\n",
       "   'param_count': 6738415616,\n",
       "   'token_count': 688510,\n",
       "   'wandb_url': '',\n",
       "   'checkpoint_path': '',\n",
       "   'model_path': '',\n",
       "   'training_offset': 0,\n",
       "   'hash': '-5968746771653984898'},\n",
       "  {'object': 'fine-tune-event',\n",
       "   'created_at': '2023-11-29T17:04:28.68Z',\n",
       "   'level': 'info',\n",
       "   'message': 'Epoch completed, at step 43',\n",
       "   'type': 'EPOCH_COMPLETE',\n",
       "   'param_count': 0,\n",
       "   'token_count': 0,\n",
       "   'wandb_url': '',\n",
       "   'checkpoint_path': '',\n",
       "   'model_path': '',\n",
       "   'training_offset': 0,\n",
       "   'hash': '5679148464011540741'},\n",
       "  {'object': 'fine-tune-event',\n",
       "   'created_at': '2023-11-29T17:05:56.613Z',\n",
       "   'level': 'info',\n",
       "   'message': 'Epoch completed, at step 86',\n",
       "   'type': 'EPOCH_COMPLETE',\n",
       "   'param_count': 0,\n",
       "   'token_count': 0,\n",
       "   'wandb_url': '',\n",
       "   'checkpoint_path': '',\n",
       "   'model_path': '',\n",
       "   'training_offset': 0,\n",
       "   'hash': '-2207390798290669768'},\n",
       "  {'object': 'fine-tune-event',\n",
       "   'created_at': '2023-11-29T17:07:24.541Z',\n",
       "   'level': 'info',\n",
       "   'message': 'Epoch completed, at step 129',\n",
       "   'type': 'EPOCH_COMPLETE',\n",
       "   'param_count': 0,\n",
       "   'token_count': 0,\n",
       "   'wandb_url': '',\n",
       "   'checkpoint_path': '',\n",
       "   'model_path': '',\n",
       "   'training_offset': 0,\n",
       "   'hash': '-6984951409631680009'},\n",
       "  {'object': 'fine-tune-event',\n",
       "   'created_at': '2023-11-29T17:08:52.168Z',\n",
       "   'level': 'info',\n",
       "   'message': 'Epoch completed, at step 172',\n",
       "   'type': 'EPOCH_COMPLETE',\n",
       "   'param_count': 0,\n",
       "   'token_count': 0,\n",
       "   'wandb_url': '',\n",
       "   'checkpoint_path': '',\n",
       "   'model_path': '',\n",
       "   'training_offset': 0,\n",
       "   'hash': '3879409174283895094'},\n",
       "  {'object': 'fine-tune-event',\n",
       "   'created_at': '2023-11-29T17:10:20.11Z',\n",
       "   'level': 'info',\n",
       "   'message': 'Epoch completed, at step 215',\n",
       "   'type': 'EPOCH_COMPLETE',\n",
       "   'param_count': 0,\n",
       "   'token_count': 0,\n",
       "   'wandb_url': '',\n",
       "   'checkpoint_path': '',\n",
       "   'model_path': '',\n",
       "   'training_offset': 0,\n",
       "   'hash': '634904574388157497'},\n",
       "  {'object': 'fine-tune-event',\n",
       "   'created_at': '2023-11-29T17:11:47.603Z',\n",
       "   'level': 'info',\n",
       "   'message': 'Epoch completed, at step 258',\n",
       "   'type': 'EPOCH_COMPLETE',\n",
       "   'param_count': 0,\n",
       "   'token_count': 0,\n",
       "   'wandb_url': '',\n",
       "   'checkpoint_path': '',\n",
       "   'model_path': '',\n",
       "   'training_offset': 0,\n",
       "   'hash': '-6813106032989739045'},\n",
       "  {'object': 'fine-tune-event',\n",
       "   'created_at': '2023-11-29T17:13:15.526Z',\n",
       "   'level': 'info',\n",
       "   'message': 'Epoch completed, at step 301',\n",
       "   'type': 'EPOCH_COMPLETE',\n",
       "   'param_count': 0,\n",
       "   'token_count': 0,\n",
       "   'wandb_url': '',\n",
       "   'checkpoint_path': '',\n",
       "   'model_path': '',\n",
       "   'training_offset': 0,\n",
       "   'hash': '-1028324577062069189'},\n",
       "  {'object': 'fine-tune-event',\n",
       "   'created_at': '2023-11-29T17:14:43.1Z',\n",
       "   'level': 'info',\n",
       "   'message': 'Epoch completed, at step 344',\n",
       "   'type': 'EPOCH_COMPLETE',\n",
       "   'param_count': 0,\n",
       "   'token_count': 0,\n",
       "   'wandb_url': '',\n",
       "   'checkpoint_path': '',\n",
       "   'model_path': '',\n",
       "   'training_offset': 0,\n",
       "   'hash': '1332303618885735484'},\n",
       "  {'object': 'fine-tune-event',\n",
       "   'created_at': '2023-11-29T17:16:10.629Z',\n",
       "   'level': 'info',\n",
       "   'message': 'Epoch completed, at step 387',\n",
       "   'type': 'EPOCH_COMPLETE',\n",
       "   'param_count': 0,\n",
       "   'token_count': 0,\n",
       "   'wandb_url': '',\n",
       "   'checkpoint_path': '',\n",
       "   'model_path': '',\n",
       "   'training_offset': 0,\n",
       "   'hash': '-5699581631650221294'},\n",
       "  {'object': 'fine-tune-event',\n",
       "   'created_at': '2023-11-29T17:17:37.969Z',\n",
       "   'level': 'info',\n",
       "   'message': 'Epoch completed, at step 430',\n",
       "   'type': 'EPOCH_COMPLETE',\n",
       "   'param_count': 0,\n",
       "   'token_count': 0,\n",
       "   'wandb_url': '',\n",
       "   'checkpoint_path': '',\n",
       "   'model_path': '',\n",
       "   'training_offset': 0,\n",
       "   'hash': '-2702287032144578512'},\n",
       "  {'object': 'fine-tune-event',\n",
       "   'created_at': '2023-11-29T17:17:58.203Z',\n",
       "   'level': 'info',\n",
       "   'message': 'Training completed for togethercomputer/llama-2-7b-chat at Wed Nov 29 09:17:57 PST 2023',\n",
       "   'type': 'TRAINING_COMPLETE',\n",
       "   'param_count': 0,\n",
       "   'token_count': 0,\n",
       "   'wandb_url': '',\n",
       "   'checkpoint_path': '',\n",
       "   'model_path': '',\n",
       "   'training_offset': 0,\n",
       "   'hash': '-3602026626559728903'},\n",
       "  {'object': 'fine-tune-event',\n",
       "   'created_at': '2023-11-29T17:18:40.037Z',\n",
       "   'level': 'info',\n",
       "   'message': 'Compressing output model',\n",
       "   'type': 'COMPRESSING_MODEL',\n",
       "   'param_count': 0,\n",
       "   'token_count': 0,\n",
       "   'wandb_url': '',\n",
       "   'checkpoint_path': '',\n",
       "   'model_path': '',\n",
       "   'training_offset': 0,\n",
       "   'hash': '8749100413630211268'},\n",
       "  {'object': 'fine-tune-event',\n",
       "   'created_at': '2023-11-29T17:18:56.175Z',\n",
       "   'level': 'info',\n",
       "   'message': 'Model compression complete',\n",
       "   'type': 'MODEL_COMPRESSION_COMPLETE',\n",
       "   'param_count': 0,\n",
       "   'token_count': 0,\n",
       "   'wandb_url': '',\n",
       "   'checkpoint_path': '',\n",
       "   'model_path': '',\n",
       "   'training_offset': 0,\n",
       "   'hash': '-8489537390716392921'},\n",
       "  {'object': 'fine-tune-event',\n",
       "   'created_at': '2023-11-29T17:18:57.759Z',\n",
       "   'level': 'info',\n",
       "   'message': 'Uploading output model',\n",
       "   'type': 'MODEL_UPLOADING',\n",
       "   'param_count': 0,\n",
       "   'token_count': 0,\n",
       "   'wandb_url': '',\n",
       "   'checkpoint_path': '',\n",
       "   'model_path': '',\n",
       "   'training_offset': 0,\n",
       "   'hash': '445466684731091030'},\n",
       "  {'object': 'fine-tune-event',\n",
       "   'created_at': '2023-11-29T17:22:57.243Z',\n",
       "   'level': 'info',\n",
       "   'message': 'Model upload complete',\n",
       "   'type': 'MODEL_UPLOAD_COMPLETE',\n",
       "   'param_count': 0,\n",
       "   'token_count': 0,\n",
       "   'wandb_url': '',\n",
       "   'checkpoint_path': '',\n",
       "   'model_path': '',\n",
       "   'training_offset': 0,\n",
       "   'hash': '890781417987216056'},\n",
       "  {'object': 'fine-tune-event',\n",
       "   'created_at': '2023-11-29T17:22:57.957Z',\n",
       "   'level': 'info',\n",
       "   'message': 'Job finished at Wed Nov 29 09:22:57 PST 2023',\n",
       "   'type': 'JOB_COMPLETE',\n",
       "   'param_count': 0,\n",
       "   'token_count': 0,\n",
       "   'wandb_url': '',\n",
       "   'checkpoint_path': '',\n",
       "   'model_path': 's3://together-dev/finetune/6552b4a556bb2d3952ed7a14/mifu67@stanford.edu/llama-2-7b-chat-middle-han-second-10--1e-05-2023-11-29-06-01-02/ft-1c17315c-eebb-47a8-bdd9-f76272bb05ce-2023-11-29-09-18-55',\n",
       "   'training_offset': 0,\n",
       "   'hash': '9127685939625564436'}],\n",
       " 'queue_depth': 0,\n",
       " 'wandb_key': '',\n",
       " 'wandb_project_name': '',\n",
       " 'wandb_url': '',\n",
       " 'enable_checkpoints': False,\n",
       " 'internal_flags': ''}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp = together.Finetune.list()\n",
    "resp['data'][-1]#['status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'success': True,\n",
       " 'value': '6db8a40646607efa35a0b83d7a98a01ec35dad85e3486d0d77a444bf446d295f-54b07198e280046e0c36ba65da4fef6276f6f71376aed6009c1b6b0bd1dcf953'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "together.Models.start('mifu67@stanford.edu/llama-2-7b-chat-middle-han-second-10--1e-05-2023-11-29-06-01-02')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "YOUNG = 'mifu67@stanford.edu/llama-2-7b-chat-young-han-new-data-6--1e-05-2023-11-22-21-56-35'\n",
    "MIDDLE = 'mifu67@stanford.edu/llama-2-7b-chat-middle-han-second-10--1e-05-2023-11-29-06-01-02'\n",
    "OLD = 'mifu67@stanford.edu/llama-2-7b-chat-old-han-third-20--1e-05-2023-11-27-03-46-19'\n",
    "\n",
    "YOUNG_QUESTIONS_PATH = './young-interview.txt'\n",
    "MIDDLE_QUESTIONS_PATH = './middleage-interview.txt'\n",
    "OLD_QUESTIONS_PATH = './old-interview.txt'\n",
    "\n",
    "OUT_YOUNG_PATH = './interviews/young-interview-answers.json'\n",
    "OUT_MIDDLE_PATH = './interviews/middleage-interview-answers.json'\n",
    "OUT_OLD_PATH = './interviews/old-interview-answers.json'\n",
    "\n",
    "with open(YOUNG_QUESTIONS_PATH, 'r') as f:\n",
    "    young_questions = [line.strip() for line in f.readlines()]\n",
    "\n",
    "with open(MIDDLE_QUESTIONS_PATH, 'r') as f:\n",
    "    middle_questions = [line.strip() for line in f.readlines()]\n",
    "\n",
    "with open(OLD_QUESTIONS_PATH, 'r') as f:\n",
    "    old_questions = [line.strip() for line in f.readlines()]\n",
    "\n",
    "system_prompt = 'I want you to act like Han Solo. I want you to respond and answer like Han Solo, using the tone, manner, and vocabulary Han Solo would use. You must have all the knowledge of Han Solo. \\n\\n Your status is as follows: \\nThe scene is set in a bustling, low-key cantina on the outskirts of Mos Eisley on Tatooine. It\\'s midday, and the heat outside is oppressive, driving a diverse crowd of aliens, smugglers, and travelers into the dimly lit establishment seeking refreshment and shady deals. In one corner, Han Solo sits with a smug look, nursing a drink as he surveys the room.\\n\\n The interactions are as follows:'\n",
    "\n",
    "SYSTEM = f\"<s>[INST] <<SYS>>{system_prompt}<</SYS>>\\n\\n\"\n",
    "\n",
    "def fetch_api_response(question, age):\n",
    "    output = together.Complete.create(\n",
    "        prompt = SYSTEM + \"<interviewer>: \" + question + \"\\n<bot>:\", \n",
    "        model = age, \n",
    "        max_tokens = 2048,\n",
    "        temperature = 0.2,\n",
    "        top_k = 60,\n",
    "        top_p = 1,\n",
    "        repetition_penalty = 1.1,\n",
    "        stop = ['[/INST]', '</s>', '<|eot|>', '[', '<']\n",
    "    )['output']['choices'][0]['text']\n",
    "\n",
    "    #remove stop caracters from the end of ther response\n",
    "    for stop in ['[/INST]', '</s>', '<|eot|>', '[', '<']:\n",
    "        output = output.replace(stop, '')\n",
    "    return {\n",
    "        'question': question, \n",
    "        'answer': output\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Can you explain the reasoning behind your decision to go alone for the coaxium exchange, despite Qi'ra's suggestion otherwise? How did this decision ultimately impact the outcome of the deal?\" generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "\"When faced with Lady Proxima's anger and Rebolt's aggression, you stood up for yourself and even attempted to bluff with a thermal detonator. What drove you to take such risks in that moment? How did this defiance shape your relationship with Lady Proxima and the other criminals?\" generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "'What motivated you to intervene and help the child being attacked by bullies, despite the risks involved?' generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "\"How did your partnership with Qi'ra evolve from being rivals in the White Worms to becoming romantically involved?\" generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "'Can you tell us about your relationship with your father and how it influenced your decision to become a pilot instead of a shipbuilder?' generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "\"As you and Qi'ra raced through the streets of Coronet, pursued by Moloch and his hounds, you displayed impressive driving skills and quick thinking. How did this experience solidify your determination to become a pilot and explore the galaxy? How did it affect your aspirations for independence and freedom?\" generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "'Can you describe the experience of witnessing the arrest of the family and other individuals by stormtroopers at the Coronet spaceport? How did it impact your decision to join the Imperial Navy?' generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "\"How did it feel to leave Qi'ra behind and vow to return for her? What motivated you to join the Imperial Navy as a pilot, and how did you think this decision would help you fulfill your promise to Qi'ra?\" generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "'Can you describe your experience at the Imperial Academy on Carida, particularly the moment when you were stripped of your clothing and given your cadet suit?' generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "'How did it feel to be referred to by your cadet name instead of your real name? Did it affect your sense of identity or individuality?' generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "\"What made you decide to use the coaxium vial to bribe the Imperial Emigration Officer Falthina Sharest? How did this act reflect your determination to protect Qi'ra?\" generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "\"In the midst of all the chaos and danger, you made the difficult decision to fake Nico's death in order to save her. Can you explain your thought process behind that decision and how it felt to leave her behind?\" generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "'What motivated you to sneak into the TIE fighter hangar and steal a fighter? Were you aware of the potential consequences of your actions?' generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "'How did you feel when you discovered that Yurib had ordered a bombing run that almost killed you and your team during the rescue mission? Did it affect your trust in him as a leader?' generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "'Can you describe the significance of the battle on Mimban for the Empire and how it affected your experience as a soldier?' generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "'How did your experience at the Carida Flight Academy shape your perspective on the Empire and your role as a Mudtrooper Corporal?' generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "'Han, can you tell us about your decision to disobey orders and go back to rescue Valance? What motivated you to take such a risk?' generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "'Han, during the intense exchange of fire with the Imperial range troopers, how did you and Chewbacca manage to narrowly avoid being crushed against the rocks while the conveyex train maneuvered along the narrow cliff face?' generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "\"It's clear that Chewbacca has played a crucial role in your survival and your partnership. How would you describe your relationship with Chewbacca, and how has it evolved since your escape from Mimban?\" generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "'Beckett promised you and Chewbacca that if you followed his instructions, you would have enough to buy your own ship. Can you share with us your aspirations and dreams for owning your own ship, and what it would mean to you to have that level of freedom and independence?' generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "\"Han, you mentioned that your plan is to become a pilot and find Qi'ra. Can you tell us more about your motivations behind these goals and why they are so important to you?\" generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "'Can you describe the moment when Val sacrificed herself and destroyed the bridge to prevent the crew from stealing the coaxium wagon? How did you and the others react to her selfless act?' generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "'The decision to let go of the coaxium wagon was undoubtedly a difficult one. Can you walk us through your thought process and the factors that led you to make that choice, ultimately saving the lives of Beckett and Chewbacca?' generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "\"Han, what made you decide to go along with Beckett's plan to make amends with Dryden Vos and repay his debt?\" generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "'How did you plan to navigate the dangerous situation with Vos and the enforcers he might send after you? What strategies or skills did you believe would be crucial in successfully resolving this predicament?' generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "\"Han, how did it feel to unexpectedly reunite with Qi'ra after all this time? Did it bring back any memories or emotions from your past together?\" generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "'Can you tell us more about your motivation to make things right and ensure that you and Chewbacca are paid for your services? How important is it for you to receive compensation for your efforts?' generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "'Can you tell us more about your proposal to steal unrefined coaxium from Kessel? How confident are you in the success of this plan, considering the risks involved?' generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "'Han, what was going through your mind when you decided to challenge Lando to a game of sabacc, knowing that his ship was reputed to be the fastest in the galaxy?' generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "\"Han, how did you feel about Qi'ra being assigned to accompany you on this mission? Did you trust her completely, or did you have any reservations about her loyalty to Vos and Crimson Dawn?\" generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "\"Can you share your thoughts on Lando's ship, the Millennium Falcon, after seeing it for the first time? Did it live up to its reputation as the fastest ship in the galaxy?\" generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "'Han, you mentioned that your father worked at a CEC plant before getting laid off. How did his experience influence your knowledge and understanding of the YT-1300 light freighter? Did it inspire your own aspirations to become a pilot?' generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "\"How did you feel when Lando used a sleight of hand to win the game and ultimately humiliate you in front of Qi'ra? Did it affect your confidence in any way?\" generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "'Han, during the mission on Kessel, you and Chewbacca posed as slaves. How did you manage to maintain your cover and avoid suspicion from the Pyke guards?' generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "'Lando questioned the closeness of your relationship with your father, and you mentioned that you were never really close. Can you elaborate on why that was the case? How did this lack of connection with your father shape your outlook on relationships and trust?' generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "\"Beckett expressed his concerns about trusting Qi'ra, advising you to trust nobody and assume that everyone would betray you. How do you feel about this perspective? Do you think it's possible to find genuine trust and loyalty in the galaxy, or do you agree with Beckett's belief that it's a lonely way to live?\" generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "'Han, you devised a plan to give fake coaxium to Vos and the real coaxium to the Cloud-Riders. How did you come up with this plan and what were your motivations behind it?' generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "\"Can you tell us about the moment when Qi'ra punched you in the gut but discreetly passed you your lucky charm? How did that small act of trust and support affect your mindset during the mission?\" generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "'The escape from Kessel required you to plot a dangerous course through the maelstrom and near a gravity well called the Maw. Can you describe the challenges you faced while piloting the Falcon through such treacherous conditions?' generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "'Can you tell us more about your double-crossing of Beckett and Vos? How did you manage to outsmart them and what were the risks involved in executing this plan?' generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "'Han, can you tell us about the time you and Chewie were riding a 74-Z speeder bike under fire? How did you manage to escape and what was going through your mind during that intense situation?' generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "\"It must have been difficult for you to watch Qi'ra betray and kill Vos. How did you feel in that moment and how did it impact your relationship with Qi'ra moving forward?\" generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "\"It's fascinating to hear about your rematch of sabacc with Lando on Numidian Prime. How did you come up with the idea to swipe the spare cards Lando held up his sleeve? And how did you feel when you won the rematch and gained possession of the Millennium Falcon?\" generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "\"Han, you've had quite a few close calls and encounters with dangerous individuals throughout your adventures. Can you tell us about a particularly harrowing experience where you had to rely on your quick thinking and piloting skills to escape?\" generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "'The Millennium Falcon has become your most prized possession, but it seems like your criminal operations became more dangerous after acquiring the ship. Can you share some of the risky situations you and Chewbacca encountered during your time as smugglers? And how did you manage to navigate through those challenges?' generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "\"Han, you've been known to make some questionable choices in the past, such as leaving Sana Starros in a dire situation after a fraudulent marriage scheme. Can you shed some light on your mindset during that time and how you've grown since then?\" generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "\"It seems like you've had your fair share of run-ins with the Empire. Can you share a memorable encounter where you outsmarted Imperial forces and managed to evade capture?\" generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "\"When faced with the Imperial blockade, you and Chewbacca made the difficult decision to drop Jabba's cargo and escape. Can you describe the thought process behind that decision and the consequences it had for you and your relationship with Jabba?\" generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "'Han, can you tell us about your encounter with the bounty hunters 4-LOM and Zuckuss at the space port on Valtos? How did you end up being captured by them?' generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "\"Han, you and Chewbacca spent many years smuggling for Jabba the Hutt. Can you tell us about some of the challenges you faced during that time and how you became Jabba's top smuggler?\" generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "\"It seems like you were hired by Beris Ford's family to rescue him from the bounty hunters. Can you share with us how you managed to free both yourself and Ford from their clutches?\" generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "'The escape from the planet inhabited by droids sounds like quite the adventure. Can you walk us through how you and Chewbacca tricked the bounty hunters into thinking the Millennium Falcon had lost power, ultimately leaving them behind?' generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "'After escaping to the planet below, you encountered the crime lord Rekias Nodo and posed as Jabba to convince him to repair the Falcon. Can you share the details of that encounter and how it led to the shootout between Nodo and the crime boss Lallani?' generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "'Han, can you tell us about your initial encounter with Alinka Aloo and what made you decide to accept her job offer?' generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "\"How did you feel when you realized that Alinka had deceived you and imprisoned Chewbacca? Can you walk us through the events that led to Chewbacca's rescue?\" generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "\"Han, what made you decide to take on the mission to free planet Rendel despite Chewbacca's concerns about the curse?\" generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "\"Can you describe the encounter with the Cranan star-hopper and how it led to the discovery of Karamu's droid Ess-Vee-Three?\" generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "'The escape from Coruscant and the encounter with the TIE fighters must have been intense. Can you share any details about how you managed to outmaneuver them and ensure the safety of your crew?' generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "'How did you feel when Chewie was too frightened to accompany you during the delivery of the statuette, and what was going through your mind when you realized you should have stayed with him?' generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "'Han, can you tell us about your experience working with Khel Tanna and her crew on the heist on Galator III? How did you and Chewbacca manage to rescue the crew from local security?' generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "\"Jabba tasked you, Chewbacca, and Greedo with stealing the verillix urn containing the ashes of Krestrel D'Naran. Can you walk us through the process of infiltrating Augustus Graves' penthouse and attempting to open the safe? What challenges did you face along the way?\" generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "'Han, can you tell us about your encounter with Makkeer and Gwarm on Kelada? How did you end up getting involved in their search for the lost treasure of Rane Mahal?' generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "'What was your plan when you and Chewie went to the Starfarer Restaurant on Kelada to retrieve the first jewel-encrusted droid? How did Makkeer end up getting captured by Gwarm and his gang?' generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "\"Han, can you explain your plan to retrieve the urn from Madelin Sun's shop on Antillion? How did you intend to get her away from her collection?\" generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "\"When you found the urn amidst the pile of artifacts in Sun's shop, what were your immediate thoughts? Did you anticipate any obstacles or challenges in retrieving it?\" generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "'Han, can you describe the events that unfolded when you and Chewie went to Nubia to find the second droid? How did you come across R5-P8 and what happened when you discovered the droid was a booby trap?' generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "'During the heist, you encountered a man claiming to be your father, \"Ovan.\" Can you share your thoughts and emotions during that encounter? How did it affect your decision-making and the overall outcome of the mission?' generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "'Han, you and Chewbacca went through quite the ordeal to retrieve the urn on Coruscant. Can you tell us about the challenges you faced and how you managed to overcome them?' generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "'It seems like the contents of the urn were not what you expected. How did you and your team react when you discovered it was a neural core instead? And why did you decide not to give it to Jabba?' generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "\"Towards the end of your mission, you were confronted by Tanna's crew and later Tyra, who demanded the core. Can you walk us through the decision-making process that led you and Chewbacca to ultimately bury the core?\" generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "'Can you tell us more about your encounter with the Wookiee bounty hunter Krrsantan? How did you end up being captured by him and taken to Mollo Tanka?' generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "\"Han, can you tell us about your encounter with Jenny at Chalmun's Cantina? How did it feel to have her throw a drink in your face?\" generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "'When negotiating with Obi-Wan Kenobi, you mentioned that the Millennium Falcon had made the Kessel Run in less than twelve parsecs. Can you elaborate on the significance of this feat and how it helped you secure the job?' generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "\"After accepting the job from Kenobi, you mentioned that Imperial sandtroopers were looking for Evazan and Baba's attacker. How did this information affect your decision to quickly depart from the cantina?\" generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "'As you were escaping Tatooine, you faced multiple Star Destroyers pursuing your ship. How did you handle the pressure of evading Imperial fire while also dealing with the backseat badgering from Luke about navigation? Can you describe the challenges you faced during that intense moment?' generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "'After the incident with Greedo, you encountered Jabba and negotiated a deal to pay off your debt. How did you manage to convince Jabba to lower the interest rate from twenty to fifteen percent? Can you share any insights into your negotiation tactics?' generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "'Han, you mentioned being skeptical of the Force and considering it as \"simple tricks and nonsense.\" After witnessing Luke\\'s ability to deflect the sting bolts while blindfolded, do you still hold the same belief? How has this experience affected your perspective on the Force?' generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "'Han, in the encounter with Greedo at the cantina, you shot him in self-defense. Can you tell us more about your decision to use your blaster pistol and how you felt in that moment?' generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "\"It's clear that you initially hesitated to join Skywalker in rescuing Princess Leia, but eventually decided it was worth the risk. Can you explain what ultimately convinced you to take on this dangerous mission?\" generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "\"Han, you've shown great resourcefulness and quick thinking throughout your mission to rescue Princess Leia. Can you tell us about the moment when you decided to impersonate the Imperial scanning crew and how you managed to successfully fool the stormtroopers outside?\" generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "\"When you discovered that Alderaan had been destroyed by the Empire, you expressed disbelief that they had enough firepower to do so. How has this revelation changed your perception of the Empire's capabilities? How does it impact your plans moving forward?\" generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "\"In the face of danger, you initially prepared to fight your way out once the Falcon was pulled into the Death Star. However, Kenobi convinced you to hide instead. Can you explain your thought process during that moment? What made you trust Kenobi's advice and choose hiding over fighting?\" generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "'Han, during the intense firefight in the corridor, you and Chewbacca were retreating while trading fire with the Imperials. Can you describe the level of danger you felt in that moment and how you managed to keep your cool under pressure?' generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "'When Princess Leia took matters into her own hands and shot open the chute, it seemed like you had mixed feelings about her actions. Can you elaborate on your thoughts and emotions during that moment, and how it may have affected your perception of her?' generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "'In the garbage compactor, you and the others faced a life-threatening situation with the dianoga. Despite the danger, you never gave up on finding Skywalker. Can you explain what drove you to keep searching for him, and how you felt when you finally managed to save him?' generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "'During the rescue operation, you had to maintain a charade and keep up the appearance of being an Imperial officer. However, there was a moment when you had to shoot the panel in frustration. Can you share your thoughts and emotions during that moment, and how you managed to stay focused on the mission despite the setbacks?' generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "'Han, in the midst of the chaos and danger, you seemed to clash with Princess Leia Organa quite a bit. Can you tell us more about your initial impressions of her and why you found her demeanor appalling?' generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "\"It's clear that you have a strong bond with Chewbacca, your loyal first mate. However, when he ran away from the strange noises in the compactor, you fired a laser blast to prove his cowardice. Can you explain your reasoning behind that action and how it reflects your relationship with Chewbacca?\" generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "'Han, initially you were skeptical about the Rebel plan to attack the Death Star. Can you tell us more about what made you doubt its success and why you ultimately decided to join the battle?' generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "\"Throughout your journey, you displayed incredible bravery and resourcefulness, especially when you charged the stormtroopers to protect Luke and Leia. Can you share with us what drives you to take such risks and put yourself in harm's way?\" generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "'Han, can you tell us about your experience at the award ceremony and how it felt to be recognized as a hero alongside Luke Skywalker and Chewbacca?' generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "'Throughout the events leading up to the battle, we see a shift in your character from being self-centered to showing bravery and loyalty. How do you think this experience has changed you as a person, and do you see yourself continuing to fight for the Rebellion in the future?' generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "'After receiving your medal from Princess Leia Organa, what was going through your mind as you winked at her? Did you have any particular thoughts or emotions in that moment?' generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "'When you turned around to help Luke during the battle, it seemed like your motivation was to save your friend rather than fight for the Rebellion. Can you explain your thought process in that moment and what drove you to risk your life for Luke?' generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "'Can you tell us about the encounter with the gang of bounty hunters in Motok? How did you manage to escape their clutches and continue your mission?' generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "'We know that you accepted a commission in the Alliance Military as a captain after the battle of Yavin. Can you share with us what led to this decision and how it has impacted your life since then?' generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "'It seems that the bounty hunters you encountered earlier have now teamed up with the Imperials to hunt you down. How do you plan to outmaneuver them and safely reach the Falcon to rescue Ematt?' generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "'Han, in the midst of the intense battle in the hangar, you made a split-second decision to help Delia and her ship instead of running away. Can you explain what motivated you to make that choice, especially considering your usual tendency to prioritize your own survival?' generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "'Han, initially you refused to aid the Rebellion in rescuing Lieutenant Caluan Ematt. What ultimately persuaded you to change your mind and come to their aid?' generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "'Returning to Corellia for parts for the Millennium Falcon led you and Chewbacca into a dangerous situation with the White Worms and Proxima. Can you share your thoughts on the risks you took to escape and the importance of loyalty and trust in such dire circumstances?' generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "\"The Empire's willingness to destroy its own TIE fighters in an attempt to capture you and the Falcon was a shocking revelation. How did witnessing this atrocity impact your perception of the Empire and its methods? Did it strengthen your resolve to fight against them?\" generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "'Han, you initially turned down a smuggling job offered by Katrull because you believed the sector was under Imperial observation. Can you tell us more about your decision-making process and why you were getting nervous about taking on more jobs at that time?' generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "'You were stopped at gunpoint by the partner of the female you had seen previously on another planet. Can you describe the emotions and thoughts that were going through your mind during that encounter? How did you handle the situation?' generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "'Princess Leia and the Rebel Alliance approached you to borrow the Millennium Falcon for a special mission. Can you explain your initial reaction and why you ultimately decided to confront Princess Leia about her decision to use your ship without your permission or participation?' generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "\"Han, throughout the race, you've encountered various obstacles and dangers. What motivates you to continue despite the risks involved?\" generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "'The presence of a traitor among the Rebel spies has put everyone in danger. How do you plan to uncover the identity of the traitor and ensure the safety of the remaining operatives?' generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "'Lee Re Anno sees something more in you than just a skilled pilot. How do you feel about her belief in your potential, and do you think it will have any impact on your actions moving forward in the race?' generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "\"Han, what motivated you to stick with the Alliance and lead a mission to destroy the Empire's largest weapons factory?\" generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "\"Can you tell us more about your plan to bluff your way into the factory by pretending to be the Hutt's envoy? How did you come up with this idea?\" generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "\"During the mission, you held the Overseer at gunpoint to find out the direction to the facility's main power core. How did you feel in that moment, and what was going through your mind?\" generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "'Han, when Luke disappeared to free the slaves instead of standing guard, you expressed worry. Can you tell us more about your concerns and what you were thinking during that time?' generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "'Leia questioned your motives for helping her and the Rebellion, wanting to know your true intentions. Can you shed some light on why you decided to defy your selfish nature and assist them?' generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "'Han, during the escape from the facility, you used the leg of the AT-AT to separate Luke Skywalker and Darth Vader. Can you tell us more about your decision to intervene in their lightsaber combat and how you managed to control the walker in such a chaotic situation?' generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "\"We saw that you were initially skeptical about the power of the Force that Luke and Vader wielded. However, you eventually opened fire on Vader with the walker's laser cannons. What changed your mind and made you take action against Vader?\" generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "'After the walker crashed and you were injured, Princess Leia and the slaves carried you to safety while Luke covered them. Can you describe the emotions and thoughts running through your mind during that moment of vulnerability, and how it affected your perception of the Rebel cause and your relationship with Luke?' generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "'It seems like there might be more to your relationship with Leia than just friendship. Can you elaborate on your feelings towards her and whether there is a romantic interest involved?' generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "'Han, can you explain your initial motivation for seeking out Princess Leia and asking for the parts to repair the Millennium Falcon? How did you plan to settle your debt with Jabba and why was it so urgent for you to leave the Alliance before the bounty hunters arrived?' generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "'It seems like Princess Leia had a condition for providing you with the parts you needed  that you work for the Rebellion. Can you tell us more about your decision to agree to her terms and become her pilot on the scouting mission? What were your thoughts and feelings about joining the Rebellion temporarily?' generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "'Han, in this sequence, we see that Sana Starros claims to be your wife and has a personal vendetta against you. Can you explain the backstory behind your relationship with Sana and why she is seeking revenge?' generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "\"During the mission, you encountered unexpected Imperial TIE fighters and made a decision to put the shuttle through evasive maneuvers, which ultimately led to the Imperials opening fire. Can you explain your reasoning behind this decision and why you chose to go against Princess Leia's instructions? How did you feel about the consequences of your actions and the princess' reaction towards you afterwards?\" generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "'Throughout this encounter, we see moments where you seem to lose your nerve, particularly when the Volt Cobra appears. Can you elaborate on what caused these moments of vulnerability and how they affect your actions?' generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "'How do you feel about the revelation that your marriage to Starros was illegitimate and part of a robbery? How has this revelation impacted your relationship with her?' generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "\"Towards the end of the sequence, Princess Leia takes charge and holds both you and Sana at gunpoint. How do you feel about Leia's decision to take control of the situation, and how does it impact your relationship with her moving forward?\" generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "'Han, can you tell us about your encounter with the bounty hunter Dengar on Nar Shaddaa? How did you manage to save Chewbacca from his clutches?' generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "'Han, can you tell us more about your decision to join the Rebel Alliance and how it has affected your life so far?' generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "'It seems like there is some tension between you and Organa. Can you share your thoughts on this and how it has influenced your actions and decisions during your journey?' generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "'After rescuing Luke Skywalker, you decided to stay with the Rebellion a bit longer. Can you share with us what influenced your decision to continue fighting alongside the Rebel fleet?' generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "\"Han, when you found out that Darth Vader had been shot down on Vrogas Vas, why did you prioritize ensuring Luke's safety over going after Vader with Princess Leia?\" generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "\"How did you feel about Princess Leia's decision to focus on taking down Vader instead of rescuing Luke? Did it surprise you, and how did it affect your relationship with her?\" generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "'It seems like you had to rely on lightsabers during the gladiator fight at the Palace of Grakkus the Hutt. As someone who usually prefers blasters, how did you feel about using a Jedi weapon?' generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "'Han, in this intense rescue mission, you encountered Aphra, a notorious gun thief. How did you recognize her and what was your initial reaction to her presence?' generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "\"Can you describe the strategy you and Chewbacca employed to neutralize Triple-Zero and protect Skywalker? How did you manage to rip off Triple-Zero's arms before he could harm Skywalker?\" generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "'Can you describe your initial reaction when you saw Luke unconscious and being carried by the assassin droid 0-0-0 on Vrogas Vas?' generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "\"Towards the end of the chaos, you and Aphra resorted to shooting nests of wasp-worms above each other's heads. Can you share your thoughts on this unconventional tactic and how it ultimately affected the outcome of the situation?\" generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "'We see that Threepio, of all beings, confronted Krrsantan and urged him to release you. Can you share your thoughts on this unexpected turn of events and how it impacted the outcome of the situation?' generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "'Han, you mentioned feeling guilty about Luke getting captured. Can you tell us more about what was going through your mind at that moment and how you plan to make it up to him?' generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "'It seems like you had a close call with Aphra and her micro-mines. How did you manage to keep your cool and drop your blaster in that intense situation?' generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "'Han, can you tell us about the moment when you received the live message from Organa, ordering the Y-wing bombers to converge on her position? How did you react and what was going through your mind at that moment?' generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "'It seems like you had a tense encounter with Krrsantan, who was working alongside Doctor Aphra. Can you describe the events leading up to the duel between you and the Wookiees? How did you handle the situation and what were your thoughts during the fight?' generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "\"When the Dowutin and his cronies discovered your dishonesty, you and Luke had to flee the planet. How did you feel about potentially losing the Alliance's money and risking your position in the Rebellion? Did you have any regrets about your actions?\" generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "'The unexpected arrival of General Karbin saved the day for you and the rebels. How did it feel to have someone unexpected come to your aid, and how do you think this will impact your future plans?' generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "\"After finding out about Luke's Imperial bounty, you decided to make back the rebels' credits and more by smuggling contraband. Can you explain your thought process behind this decision and why you believed smuggling was the best way to achieve your goal?\" generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "\"Han, can you tell us about your decision to cheat in the game of sabacc in order to double the Rebellion's credits? How did you justify this action to yourself and to Luke?\" generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "'Han, can you tell us about your experience with the nerfs shedding fur and causing messes on your ship? How did you handle the situation and what impact did it have on your relationship with Skywalker?' generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "'It seems like you and Skywalker had a disagreement about allowing the Imperial TIE fighters to board your ship. Can you elaborate on your decision to refuse and how you managed to navigate through that situation without the hyperdrive?' generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "'We read about your reluctance to let Skywalker pilot the Falcon and your comment about him being a poor smuggler. Can you share more about your reasoning behind this decision and how it ultimately led to him flying the ship?' generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "'Han, during the mission to steal the Imperial Star Destroyer Harbinger, you raced Leia Organa to decide who would be the captain of the stolen ship. Can you tell us about the intensity of that race and what it meant to you to come out on top?' generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "'You piloted the Harbinger while Task Force 99 infiltrated the ship. Can you describe the challenges you faced in maneuvering the ship and ensuring the success of the incursion?' generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "'After the Harbinger crashed, you rescued Leia from Skorii-Lei and provided her with medical attention. What drove you to prioritize her safety and well-being in that moment, and how did it strengthen your bond with her?' generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "\"Han, can you tell us about your experience being hypnotized by the Queen on Ktath'atn? How did it feel to be under her control and forced to serve her?\" generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "\"When you were named King by the guards after defeating Varroa, you mentioned that you didn't want to tell people what to do. Can you explain your reasoning behind this decision and how it impacted your actions moving forward?\" generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "\"After disbanding the hive and freeing the people of Ktath'atn, how did you feel about the overall outcome of your mission? Did you have any regrets or were you satisfied with the resolution?\" generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "'Han, during your encounter with Grakkus, he tried to convince you to free him and return to your life as a smuggler. Can you tell us what made you ultimately decide to reject his offer and continue on your mission to Akiva?' generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "'It seems like Grakkus had disabled the hyperdrive of the Falcon, leaving you vulnerable to the TIE attack. How did you manage to outsmart the TIE patrol and ultimately defeat them?' generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "'When Grakkus demanded that Chewie take him to his safe house on Teth, you shocked him and sent the information to General Draven. Can you explain the reasoning behind this decision and how it played a role in capturing Grakkus and ensuring the safety of the Alliance?' generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "'Han, can you describe the challenges you faced while exploring the caves on Odona? How did you and Leia manage to survive for three days and what was the most dangerous encounter you had with the creature?' generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "\"Frax seemed to hold a grudge against you for a past incident involving the Empire. Can you elaborate on what happened and why he sought revenge? How did you handle the confrontation with Frax and the bounty hunters, and how did Leia's intervention help you escape?\" generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "'At the end of your mission, you awarded Des the Medal of Bravery, even though it was a copy. Can you share why you felt it was important to recognize her actions, despite the circumstances?' generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "'It seems like you had some reservations about Des leading the mission. Can you explain what made you hesitant and how you ultimately decided to take charge?' generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "'It seems like Frax and Selt were tracking you and Leia during your time in the caves. How did you discover their presence, and what actions did you take to protect Leia and yourself from their pursuit?' generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "'Han, throughout your mission with the Partisans, you showed great leadership and bravery. Can you tell us about a specific moment where you had to make a difficult decision and how it impacted the outcome of the mission?' generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "\"Han, can you describe the intense battle you led from the captain's seat of the Millennium Falcon to defend the Rebel fleet from the Imperial forces? How did you manage to buy enough time for the fleet to jump to Baraan-Fa?\" generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "'It must have been quite a mission to Crait with Wedge, Leia, Luke, and Chewbacca. Can you share any details about the purpose of this mission and why the Alliance was considering Crait as a potential hidden base of operations?' generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "'The encounter with Trusk Berinato took an unexpected turn when he turned out to be a traitor. Can you tell us more about how you attempted to evacuate Leia while Luke and Wedge engaged SCAR Squadron? How did you manage to regroup and escape aboard the Millennium Falcon?' generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "\"Han, you've encountered numerous challenges and obstacles throughout your mission to Mon Cala. Can you tell us about a specific moment where your quick thinking and resourcefulness helped you overcome a difficult situation?\" generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "'It seems like you and Luke had a disagreement about the next course of action during your mission. Can you share with us how you resolved your differences and ultimately made a decision together?' generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "\"The final moments of your mission involved a confrontation with Grand Admiral Urtya. Can you walk us through your thought process when you made the decision to allow him to take Lee-Char's recording?\" generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "'Han, can you tell us about your experience at the Ring of Kafrene and the deal with the Alaphani? How did you manage to handle the situation with the bounty hunters?' generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "'It seems like you had to make a quick decision to help the Rebel fleet at the Space Docks. Can you walk us through your thought process and what led you to take the Falcon into the bay door despite the risks?' generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "'Han, you mentioned that you had a contact who would pay you for the set of codes. Can you share more about this contact and how you plan to ensure a successful transaction?' generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "'How did the encounter with the native droids and Akar Duel impact your mission? Did it pose any unexpected challenges or obstacles?' generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "'As a seasoned member of the Alliance to Restore the Republic, what lessons did you personally take away from the investigation on Lotho Minor? How do you think this experience will shape future decisions regarding potential rebel bases?' generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "'Han, you and Skywalker were tasked with scouting the land around Echo Base on regular recon missions. Can you tell us about any particularly challenging or dangerous encounters you had during these missions?' generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "'During your time on Hoth, you had a heated conversation with Leia where you claimed she had romantic feelings towards you. Can you elaborate on the dynamics of your relationship with Leia during this time and how it may have influenced your actions?' generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "'Han, can you tell us about your experience on the planet Lotho Minor and what led you and the rest of the team to conclude that it was not suitable for a new rebel base?' generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "'Can you tell us more about your decision to go to Cloud City and seek help from Lando Calrissian? What made you trust him as an old friend?' generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "'Han, flying into the asteroid field was a risky move. What made you confident that the Imperials would not follow you?' generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "'The encounter with the exogorth slug, Sy-O, was quite unexpected. Looking back, how do you feel about the fact that Sy-O had developed a fondness for you and your companions, despite your short stay inside its ecosystem?' generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "'The evacuation from Hoth was a chaotic and intense battle. Can you share any specific moments or challenges you faced while rescuing Leia and escaping on the Falcon?' generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "\"It seemed like you were relatively at ease in Cloud City, even though Leia felt suspicious about C-3PO's disappearance and reappearance in pieces. Can you share why you were able to put your trust in Lando and feel comfortable in that environment?\" generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "'When Lando invited you, Leia, and Chewbacca for refreshments and then unexpectedly led you into a room with Darth Vader, you reacted quickly by drawing your blaster and firing shots at him. Can you describe what was going through your mind in that intense moment and why you chose to take such a bold action?' generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "\"Han, when you first arrived on Cloud City and reunited with Lando Calrissian, you mentioned that you didn't trust him. Can you explain why you had reservations about Lando, despite your history as friends?\" generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "\"Han, after being released from carbonite, you were temporarily blind due to hibernation sickness. How did you manage to recognize Jabba's laugh when he revealed himself to be watching the rescue?\" generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "\"During the battle at the Great Pit of Carkoon, you unintentionally swung an axe into Boba Fett's jetpack, sending him flying into Jabba's sail barge and then rolling into the sarlacc. Can you describe what was going through your mind in that moment?\" generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "'Han, as a General in the Alliance, you played a crucial role in the attack on the second Death Star. Can you tell us about your experience commandeering the Tydirium and leading the Rebel strike team to disable the shields on the forest moon of Endor?' generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "'In the midst of the struggle, you claimed that your vision had \"gotten a lot better\" and were able to shoot the tentacle that had caught Lando. Can you explain how you were able to overcome your temporary blindness and make that shot?' generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "'After Luke and Leia pursued the escaping scout troopers on a speeder, you were left behind with the rest of the strike team. Can you share with us the challenges you faced and the decisions you made to keep the strike team focused and motivated in completing their mission to disable the shields protecting the Death Star?' generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "'During the mission on Endor, you encountered a group of scout troopers and attempted to sneak up on them. However, your attempt failed, alerting them and allowing two to escape. How did you handle this setback, and what actions did you take to ensure the success of the mission?' generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "\"Han, during your time at General Syndulla's camp, you were forced to admit that her ship, the Ghost, was superior to the Falcon in order to obtain food rations for the Ewoks. How did you feel about having to make that admission, considering your pride in the Millennium Falcon?\" generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "'Two days after the battle, you proposed to Leia Organa and the two of you were married in a small ceremony attended only by trusted individuals. Can you share with us the significance of this moment for you and how it felt to finally marry the woman you love amidst the chaos of war?' generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n",
      "'After the Battle of Endor, you led the Pathfinders on an assault on an Imperial outpost and discovered data that led you to believe the war was not over. Can you tell us more about what you found and how it affected your perspective on the ongoing conflict?' generated an exception: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference\n"
     ]
    }
   ],
   "source": [
    "with ThreadPoolExecutor(max_workers=5) as executor:\n",
    "        future_to_question = {executor.submit(fetch_api_response, question, MIDDLE): question for question in middle_questions}\n",
    "        \n",
    "        answers = []\n",
    "        for future in as_completed(future_to_question):\n",
    "            question = future_to_question[future]\n",
    "            try:\n",
    "                answer = future.result()\n",
    "            except Exception as exc:\n",
    "                print('%r generated an exception: %s' % (question, exc))\n",
    "            else:\n",
    "                answers.append(answer)\n",
    "together.Models.stop(model=MIDDLE)\n",
    "with open(OUT_MIDDLE_PATH, 'w') as f:\n",
    "    json.dump(answers, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'success': True, 'wasAlreadyDisabled': True}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "together.Models.stop('mifu67@stanford.edu/llama-2-7b-chat-middle-han-second-10--1e-05-2023-11-29-06-01-02')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "404 Client Error: Not Found for url: https://api.together.xyz/api/inference",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/adamzhao/Desktop/characterbot/finetune.ipynb Cell 10\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/adamzhao/Desktop/characterbot/finetune.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m output \u001b[39m=\u001b[39m together\u001b[39m.\u001b[39;49mComplete\u001b[39m.\u001b[39;49mcreate(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/adamzhao/Desktop/characterbot/finetune.ipynb#X12sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m   prompt \u001b[39m=\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mWhat are your thoughts on Count Dooku?\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m\\n\u001b[39;49;00m\u001b[39m1. \u001b[39;49m\u001b[39m\"\u001b[39;49m, \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/adamzhao/Desktop/characterbot/finetune.ipynb#X12sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m   model \u001b[39m=\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39mmifu67@stanford.edu/llama-2-7b-chat-middle-han-second-10--1e-05-2023-11-29-06-01-02\u001b[39;49m\u001b[39m'\u001b[39;49m, \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/adamzhao/Desktop/characterbot/finetune.ipynb#X12sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/together/complete.py:41\u001b[0m, in \u001b[0;36mComplete.create\u001b[0;34m(self, prompt, model, max_tokens, stop, temperature, top_p, top_k, repetition_penalty, logprobs)\u001b[0m\n\u001b[1;32m     28\u001b[0m parameter_payload \u001b[39m=\u001b[39m {\n\u001b[1;32m     29\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m\"\u001b[39m: model,\n\u001b[1;32m     30\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mprompt\u001b[39m\u001b[39m\"\u001b[39m: prompt,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mlogprobs\u001b[39m\u001b[39m\"\u001b[39m: logprobs,\n\u001b[1;32m     38\u001b[0m }\n\u001b[1;32m     40\u001b[0m \u001b[39m# send request\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m response \u001b[39m=\u001b[39m create_post_request(\n\u001b[1;32m     42\u001b[0m     url\u001b[39m=\u001b[39;49mtogether\u001b[39m.\u001b[39;49mapi_base_complete, json\u001b[39m=\u001b[39;49mparameter_payload\n\u001b[1;32m     43\u001b[0m )\n\u001b[1;32m     45\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     46\u001b[0m     response_json \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(response\u001b[39m.\u001b[39mjson())\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/together/utils.py:109\u001b[0m, in \u001b[0;36mcreate_post_request\u001b[0;34m(url, headers, json, stream, check_auth)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[39melif\u001b[39;00m response\u001b[39m.\u001b[39mstatus_code \u001b[39m==\u001b[39m \u001b[39m401\u001b[39m:\n\u001b[1;32m    108\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mAPI Key not supplied\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 109\u001b[0m response\u001b[39m.\u001b[39;49mraise_for_status()\n\u001b[1;32m    111\u001b[0m \u001b[39mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/requests/models.py:1021\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1016\u001b[0m     http_error_msg \u001b[39m=\u001b[39m (\n\u001b[1;32m   1017\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstatus_code\u001b[39m}\u001b[39;00m\u001b[39m Server Error: \u001b[39m\u001b[39m{\u001b[39;00mreason\u001b[39m}\u001b[39;00m\u001b[39m for url: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39murl\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1018\u001b[0m     )\n\u001b[1;32m   1020\u001b[0m \u001b[39mif\u001b[39;00m http_error_msg:\n\u001b[0;32m-> 1021\u001b[0m     \u001b[39mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m)\n",
      "\u001b[0;31mHTTPError\u001b[0m: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference"
     ]
    }
   ],
   "source": [
    "output = together.Complete.create(\n",
    "  prompt = \"What are your thoughts on Count Dooku?\\n\\n1. \", \n",
    "  model = 'mifu67@stanford.edu/llama-2-7b-chat-middle-han-second-10--1e-05-2023-11-29-06-01-02', \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'training_file': 'file-5350fa6b-2ad1-4a4d-8717-fcb1522be037',\n",
       " 'validation_file': '',\n",
       " 'model_output_name': 'mifu67@stanford.edu/llama-2-7b-chat-middle-han-10--1e-05-2023-11-29-03-08-42',\n",
       " 'model_output_path': 's3://together-dev/finetune/6552b4a556bb2d3952ed7a14/mifu67@stanford.edu/llama-2-7b-chat-middle-han-10--1e-05-2023-11-29-03-08-42/ft-33d67b6b-7bb0-4840-8bce-27ebd5169593',\n",
       " 'Suffix': 'middle-han-10--1e-05',\n",
       " 'model': 'togethercomputer/llama-2-7b-chat',\n",
       " 'n_epochs': 10,\n",
       " 'n_checkpoints': 1,\n",
       " 'batch_size': 4,\n",
       " 'learning_rate': 1e-05,\n",
       " 'user_id': '6552b4a556bb2d3952ed7a14',\n",
       " 'lora': False,\n",
       " 'lora_r': 8,\n",
       " 'lora_alpha': 8,\n",
       " 'lora_dropout': 0,\n",
       " 'staring_epoch': 0,\n",
       " 'training_offset': 0,\n",
       " 'checkspoint_path': '',\n",
       " 'random_seed': '',\n",
       " 'created_at': '2023-11-29T03:08:42.709Z',\n",
       " 'updated_at': '2023-11-29T05:57:55.914Z',\n",
       " 'status': 'cancel_requested',\n",
       " 'owner_address': '0xebd597774b313d8e8d22af4629b75ec7d567f678',\n",
       " 'id': 'ft-33d67b6b-7bb0-4840-8bce-27ebd5169593',\n",
       " 'job_id': '',\n",
       " 'token_count': 0,\n",
       " 'param_count': 0,\n",
       " 'total_price': 0,\n",
       " 'epochs_completed': 0,\n",
       " 'events': [{'object': 'fine-tune-event',\n",
       "   'created_at': '2023-11-29T03:08:42.709Z',\n",
       "   'level': '',\n",
       "   'message': 'Fine tune request created',\n",
       "   'type': 'JOB_PENDING',\n",
       "   'param_count': 0,\n",
       "   'token_count': 0,\n",
       "   'wandb_url': '',\n",
       "   'checkpoint_path': '',\n",
       "   'model_path': '',\n",
       "   'training_offset': 0,\n",
       "   'hash': ''}],\n",
       " 'queue_depth': 0,\n",
       " 'wandb_key': '',\n",
       " 'wandb_project_name': '',\n",
       " 'wandb_url': '',\n",
       " 'enable_checkpoints': False,\n",
       " 'internal_flags': ''}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "together.Finetune.cancel('ft-33d67b6b-7bb0-4840-8bce-27ebd5169593')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
