{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1102\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "EXPERIENCE_PATH = './trainingdata/hansolo/young-han.json'\n",
    "EXPERIENCE_OLD_PATH = './trainingdata/hansolo/han.json'\n",
    "PROTECTED_PATH = './trainingdata/hansolo/han-protective.json'\n",
    "\n",
    "han_exps = ['./trainingdata/hansolo/young-han.json', './trainingdata/hansolo/han.json', './trainingdata/hansolo/old-han.json']\n",
    "han_protected = ['./trainingdata/hansolo/old-han-protective.json']\n",
    "\n",
    "new_data = []\n",
    "\n",
    "# loop thru the original jsons\n",
    "# for each object present, do the following:\n",
    "# 1. create an empty dict\n",
    "# 2. add the key \"text\"\n",
    "\n",
    "for path in (han_exps + han_protected):\n",
    "    with open(path, 'r') as f:\n",
    "        exp = json.load(f)\n",
    "        for obj in exp:\n",
    "            #print(obj)\n",
    "            temp = {'text': []}\n",
    "            temp['text'].append('<instruction>')\n",
    "            temp['text'].append(obj['instruction'])\n",
    "            temp['text'].append('<input>')\n",
    "            temp['text'].append(obj['input'])\n",
    "            temp['text'].append('<output>')\n",
    "            temp['text'].append(obj['output'])\n",
    "            temp['text'] = ' '.join(temp['text'])\n",
    "            new_data.append(temp)\n",
    "        f.close()\n",
    "\n",
    "print(len(new_data))\n",
    "# filthy\n",
    "# with open(EXPERIENCE_PATH, 'r') as f:\n",
    "#     exp = json.load(f)\n",
    "#     for obj in exp:\n",
    "#         #print(obj)\n",
    "#         temp = {'text': []}\n",
    "#         temp['text'].append('<instruction>')\n",
    "#         temp['text'].append(obj['instruction'])\n",
    "#         temp['text'].append('<input>')\n",
    "#         temp['text'].append(obj['input'])\n",
    "#         temp['text'].append('<output>')\n",
    "#         temp['text'].append(obj['output'])\n",
    "#         temp['text'] = ' '.join(temp['text'])\n",
    "#         new_data.append(temp)\n",
    "#     f.close()\n",
    "# print(len(new_data))\n",
    "\n",
    "# with open(EXPERIENCE_OLD_PATH, 'r') as f:\n",
    "#     exp = json.load(f)\n",
    "#     for obj in exp:\n",
    "#         #print(obj)\n",
    "#         temp = {'text': []}\n",
    "#         temp['text'].append('<instruction>')\n",
    "#         temp['text'].append(obj['instruction'])\n",
    "#         temp['text'].append('<input>')\n",
    "#         temp['text'].append(obj['input'])\n",
    "#         temp['text'].append('<output>')\n",
    "#         temp['text'].append(obj['output'])\n",
    "#         temp['text'] = ' '.join(temp['text'])\n",
    "#         new_data.append(temp)\n",
    "#     f.close()\n",
    "# print(len(new_data))\n",
    "# with open(PROTECTED_PATH, 'r') as f:\n",
    "#     exp = json.load(f)\n",
    "#     for obj in exp:\n",
    "#         #print(obj)\n",
    "#         temp = {'text': []}\n",
    "#         temp['text'].append('<instruction>')\n",
    "#         temp['text'].append(obj['instruction'])\n",
    "#         temp['text'].append('<input>')\n",
    "#         temp['text'].append(obj['input'])\n",
    "#         temp['text'].append('<output>')\n",
    "#         temp['text'].append(obj['output'])\n",
    "#         temp['text'] = ' '.join(temp['text'])\n",
    "#         new_data.append(temp)\n",
    "#     f.close()\n",
    "# print(len(new_data))\n",
    "with open('./trainingdata/hansolo/old-han-data.jsonl', 'w') as f:\n",
    "    for entry in new_data:\n",
    "        json.dump(entry, f)\n",
    "        f.write('\\n')\n",
    "    # json.dump(new_experience, f)\n",
    "    f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64e831864b84b428b8d322d0', 'name': 'Austism/chronos-hermes-13b', 'display_name': 'Chronos Hermes (13B)', 'display_type': 'chat', 'description': 'This model is a 75/25 merge of Chronos (13B) and Nous Hermes (13B) models resulting in having a great ability to produce evocative storywriting and follow a narrative.', 'license': 'other', 'creator_organization': 'Austism', 'hardware_label': '2x A100 80GB', 'num_parameters': 13000000000, 'show_in_playground': True, 'isFeaturedModel': True, 'context_length': 2048, 'config': {'stop': ['</s>'], 'prompt_format': '### Instruction:\\n{prompt}\\n### Response:\\n', 'chat_template': \"{% for message in messages %}{% if message['role'] == 'user' %}{{ '### Instruction:\\n' + message['content'] + '\\n' }}{% else %}{{ '### Response:\\n' + message['content'] + '\\n' }}{% endif %}{% endfor %}{{ '### Response:\\n' }}\"}, 'pricing': {'input': 75, 'output': 75, 'hourly': 0}, 'created_at': '2023-08-24T17:08:25.379Z', 'update_at': '2023-08-24T17:08:25.379Z', 'access': '', 'link': '', 'descriptionLink': '', 'depth': {'num_asks': 3, 'num_bids': 1, 'num_running': 1, 'asks': {'0xFA5C96b20a10cAC5d21E095e6F4f8c3CBC2f3527': 2, '0xa96806eD1168d759DC233DfB636522b72bBbE159': 1}, 'asks_updated': '2023-11-30T07:51:08.111742969Z', 'gpus': {'': 0}, 'qps': 0.08135092, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'throughput_in': 55.872772, 'throughput_out': 25.311153}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '6532f0faf94bacfc629b4cf7', 'name': 'EleutherAI/llemma_7b', 'display_name': 'Llemma (7B)', 'display_type': 'language', 'description': 'Llemma 7B is a language model for mathematics. It was initialized with Code Llama 7B weights, and trained on the Proof-Pile-2 for 200B tokens.', 'license': 'LLaMA license Agreement (Meta)', 'link': 'https://huggingface.co/EleutherAI/llemma_7b', 'creator_organization': 'EleutherAI', 'hardware_label': 'A100 80GB', 'pricing_tier': 'Featured', 'access': 'open', 'num_parameters': 6738546688, 'show_in_playground': True, 'isFeaturedModel': True, 'context_length': 4096, 'config': {'chat_template_name': 'llama'}, 'pricing': {'input': 50, 'output': 50, 'hourly': 0}, 'created_at': '2023-10-20T21:28:26.403Z', 'update_at': '2023-10-24T17:42:38.630Z', 'descriptionLink': '', 'depth': {'num_asks': 1, 'num_bids': 0, 'num_running': 0, 'asks': {'0x1de9B2f4CFe3fc2905B5C38302E77dd823536c73': 1}, 'asks_updated': '2023-11-30T07:01:10.039238364Z', 'gpus': {'': 0}, 'qps': 0.033957344, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'throughput_in': 0.74571127, 'throughput_out': 3.238589}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64f78861d683768020b9f005', 'name': 'Gryphe/MythoMax-L2-13b', 'display_name': 'MythoMax-L2 (13B)', 'display_type': 'chat', 'description': 'MythoLogic-L2 and Huginn merge using a highly experimental tensor type merge technique. The main difference with MythoMix is that I allowed more of Huginn to intermingle with the single tensors located at the front and end of a model', 'license': 'other', 'creator_organization': 'Gryphe', 'hardware_label': '1x A40 48GB', 'num_parameters': 13000000000, 'release_date': '2023-08-01T00:00:00.000Z', 'show_in_playground': True, 'isFeaturedModel': True, 'context_length': 4096, 'config': {'stop': ['</s>'], 'prompt_format': '### Instruction:\\n{prompt}\\n### Response:', 'chat_template': \"{% for message in messages %}{% if message['role'] == 'user' %}{{ '### Instruction:\\n' + message['content'] + '\\n' }}{% else %}{{ '### Response:\\n' + message['content'] + '\\n' }}{% endif %}{% endfor %}{{ '### Response:' }}\"}, 'pricing': {'input': 75, 'output': 75, 'hourly': 0}, 'created_at': '2023-09-05T19:58:25.683Z', 'update_at': '2023-09-05T19:58:25.683Z', 'instances': [{'avzone': 'us-east-1a', 'cluster': 'happypiglet'}, {'avzone': 'us-east-2a', 'cluster': 'jumpyjackal'}, {'avzone': 'us-central-1a', 'cluster': 'sassyseal'}], 'access': '', 'link': '', 'descriptionLink': '', 'depth': {'num_asks': 209, 'num_bids': 190, 'num_running': 190, 'asks': {'0x01637e64a1CFbE292e6EBe2E00f69185DF89d611': 4, '0x07b4653B4C867C9CfB4f2A3ceaC68F1F20671Da6': 1, '0x09D59bBE7Fb86f94F0BCDbD3De7Ff9f13938aB59': 6, '0x0E86A9D366259A7Ff146BfC6BE69e580B0BeBf3A': 1, '0x102C7758b7cc0E44C4C8876E002C077d8bd41603': 1, '0x13DB1E0FeFBE7Ef3bfAd5CaD76573296597C38ce': 14, '0x3350c3F44a3225dbC962D62DD82E24B7f6cB8471': 1, '0x37b28e4e7035188D9DCA0d6C93Ed257cd083E1Cc': 1, '0x39AE75E4b81E17fFfE474A036B2fb185d5E29AEF': 2, '0x430Ea7278F74D5765C54588F3D17606779EE416a': 5, '0x46bFcb828de8009c9d1B891f237f483F8E26C05f': 22, '0x483D134ba8724F74FeD95debEa1502DC289B69B7': 3, '0x49Fe4B6E624909d504E4739d31060dC5e00a578e': 4, '0x548E463F92d47d93f01940fd9aeb5ba9A3B5bE0F': 1, '0x5537dc4f0Ac123CD49aAC3A444Ed10693Ba91c6D': 5, '0x579aa338aFcA98afDF99f1c14Da7EA487AC00916': 1, '0x57a5582b5E1508d4Fe138bfa26B882aacEE1F848': 16, '0x59f5E0E38120A95080bf6a002a1f773ad5720eF2': 7, '0x5AB90E240656bc93E8c58C730617A82aF1bC6c98': 1, '0x608c3251Dc8Ad23a591ec41c8F2f15c4fA76B9A6': 3, '0x62c9E9C7C30bD36414D4BfE4b73A397C1236A095': 9, '0x690ec156D12e636a5d45eb0b0184B2f89C838aa6': 1, '0x750C7EA5C4fa95c21905E8B78297C61A78A64C1B': 4, '0x7614a53722658FF897489e838Ac07c703ff3815f': 3, '0x77dDc55dcbeafD7E3DDA5a5C3C1dD0145122A036': 1, '0x7A116c8523E3170107Cd07A2A788615f2A144763': 4, '0x7FefcF6C6C6025830a5DbF1e718b097809b3dB37': 1, '0x86A0cCDbAee9920c670BF7Cc02f73DE96571549B': 16, '0x8ffe255E8555af1387C0524Dcb1b673EC398aB1d': 1, '0x9002a77969C00aB958C9936AD8e74dEb89624e8D': 8, '0xA177b90C3543efaf1406160fa63cD362D58CF329': 1, '0xD0fE5946509AebcE50860F876BA141003D4fEDE9': 3, '0xE4751A8234fa116c9e4e40ca9c9Da6F86404E994': 1, '0xEABB223116c6A75652BDA6CE66Ca6126e1b9C514': 1, '0xFC90529829456BD5cd4107D1434fbedD1315BFf0': 1, '0xFee3E2695fd342e4983b83a2A5931294a74f17f6': 1, '0xa1a40f62A876Be7cbFfD0C7478cB895b927b4E87': 1, '0xa9d2607c36dE09A26A4F20cAa0661B81FE003736': 1, '0xb154a9f4CA2151F61e21519db68Ae339BAAdf405': 3, '0xb266B151084BBA499bF771408DBd8fBe161B5ee2': 1, '0xb66062C56F7438Aa0F1163eEAdfEaF5728C45910': 13, '0xc57431697C9B5f30AD37c8DD57afc67f54ad68C5': 1, '0xcB207FAd1454190a6E27B9396d1AF45dA59B7A1A': 1, '0xd46b944Dc99663df289b03F5bD2e96D2778fd48b': 21, '0xe80ee3A567cC32182D47Ca06af77F4e053439700': 1, '0xea08245042E8Aa315837B85d6e9353C574019550': 1, '0xee2d317445a8d257513dD4B26b5198d2730b26D8': 1, '0xf4446f8A31551775ae515447C5140B9B40c6d489': 8}, 'asks_updated': '2023-11-30T09:01:13.789470174Z', 'gpus': {'': 0}, 'qps': 14.4, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'stats': [{'avzone': 'us-east-1a', 'cluster': 'happypiglet', 'capacity': 0.03565543071161034, 'qps': 4.133333333333334}, {'avzone': 'us-east-2a', 'cluster': 'jumpyjackal', 'capacity': 0.3015873015873014, 'qps': 5.666666666666667}, {'avzone': 'us-central-1a', 'cluster': 'sassyseal', 'capacity': 0.32519332519332583, 'qps': 4.6}]}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '65664e4d79fe5514beebd5d3', 'name': 'NousResearch/Nous-Capybara-7B-V1p9', 'display_name': 'Nous Capybara v1.9 (7B)', 'display_type': 'chat', 'description': 'first Nous collection of dataset and models made by fine-tuning mostly on data created by Nous in-house', 'license': 'MIT', 'creator_organization': 'NousResearch', 'hardware_label': 'A100', 'pricing_tier': 'Featured', 'num_parameters': 7241732096, 'release_date': '2023-11-15T00:00:00.000Z', 'show_in_playground': True, 'isFeaturedModel': True, 'config': {'stop': ['USER:', 'ASSISTANT:'], 'prompt_format': 'USER:\\n{prompt}\\nASSISTANT:', 'pre_prompt': ''}, 'pricing': {'input': 50, 'output': 50}, 'created_at': '2023-11-28T20:32:13.026Z', 'update_at': '2023-11-28T20:33:03.163Z', 'access': '', 'link': '', 'descriptionLink': '', 'depth': {'num_asks': 3, 'num_bids': 0, 'num_running': 0, 'asks': {'0x4B981bb934b6F2351c0947c6c4d5c9B7236FAa77': 1, '0x73e916B574621cE804ecd154c3f6eC91369a6c6f': 1, '0xBaD24C21f75FebD4A955cf1a8Ca9DCD3d3dFb222': 1}, 'asks_updated': '2023-11-30T08:56:51.742036298Z', 'gpus': {'': 0}, 'qps': 0.012105399, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'throughput_in': 0.1349719, 'throughput_out': 0.5145034}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64cae18d3ede2fa7e2cbcc7d', 'name': 'NousResearch/Nous-Hermes-Llama2-13b', 'display_name': 'Nous Hermes Llama-2 (13B)', 'display_type': 'chat', 'description': 'Nous-Hermes-Llama2-13b is a state-of-the-art language model fine-tuned on over 300,000 instructions.', 'license': 'mit', 'creator_organization': 'NousResearch', 'hardware_label': '2x A100 80GB', 'pricing_tier': 'featured', 'access': 'open', 'num_parameters': 13000000000, 'show_in_playground': True, 'isFeaturedModel': True, 'context_length': 4096, 'config': {'prompt_format': '### Instruction:\\n{prompt}\\n### Response:\\n', 'stop': ['###', '</s>'], 'chat_template_name': 'llama', 'chat_template': \"{% for message in messages %}{% if message['role'] == 'user' %}{{ '### Instruction:\\n' + message['content'] + '\\n' }}{% else %}{{ '### Response:\\n' + message['content'] + '\\n' }}{% endif %}{% endfor %}{{ '### Response:\\n' }}\"}, 'pricing': {'input': 75, 'output': 75, 'hourly': 0}, 'created_at': '2023-08-02T23:06:53.926Z', 'update_at': '2023-10-07T00:19:33.779Z', 'instances': [{'avzone': 'us-central-1a', 'cluster': 'sassyseal'}, {'avzone': 'us-east-1a', 'cluster': 'happypiglet'}], 'link': '', 'descriptionLink': '', 'depth': {'num_asks': 9, 'num_bids': 0, 'num_running': 0, 'asks': {'0x43Ea90eC8d1c332c02E1ebaE8A47A3e20A0672dB': 1, '0x547067ece967698fde1caEe1Ac01372eC650a2FF': 1, '0x925B2f41d483CF07907D4020A0e68b6E361EB8bb': 1, '0x99eA480870A0cEf766a90a4CE939cf7c916afae1': 1, '0xA6C2C3EB28d45DC8431251dF878cdCCdC3Bcf18C': 1, '0xCC1c1256C5736708c2dad7DDAD286AcB08BecA72': 1, '0xE76b1D2F7AE035c136e94EAc26A7E6bd5344ab8A': 1, '0xe149e0e7C96c5Db20216346a2F96DFF2c7bb52aD': 1}, 'asks_updated': '2023-11-30T08:42:24.492221379Z', 'gpus': {'': 0}, 'qps': 3.2, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'stats': [{'avzone': 'us-central-1a', 'cluster': 'sassyseal', 'capacity': 0.1603773584905658, 'qps': 1.8666666666666667}, {'avzone': 'us-east-1a', 'cluster': 'happypiglet', 'capacity': 0.02098765432098767, 'qps': 1.3333333333333333}]}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '6532f0faf94bacfc629b4cf8', 'name': 'NousResearch/Nous-Hermes-Llama2-70b', 'display_name': 'Nous Hermes LLaMA-2 (70B)', 'display_type': 'chat', 'description': 'Nous-Hermes-Llama2-70b is a state-of-the-art language model fine-tuned on over 300,000 instructions.', 'license': 'LLaMA license Agreement (Meta)', 'link': 'https://huggingface.co/NousResearch/Nous-Hermes-Llama2-70b', 'creator_organization': 'NousResearch', 'hardware_label': '2X A100 80GB', 'pricing_tier': 'Featured', 'access': 'open', 'num_parameters': 70000000000, 'show_in_playground': True, 'isFeaturedModel': False, 'context_length': 4096, 'config': {'stop': ['###', '</s>'], 'prompt_format': '### Instruction:\\n{prompt}\\n\\n### Response:\\n', 'chat_template_name': 'llama', 'chat_template': \"{% for message in messages %}{% if message['role'] == 'user' %}{{ '### Instruction:\\n' + message['content'] + '\\n' }}{% else %}{{ '### Response:\\n' + message['content'] + '\\n' }}{% endif %}{% endfor %}{{ '### Response:\\n' }}\"}, 'pricing': {'input': 225, 'output': 225, 'hourly': 0}, 'created_at': '2023-10-20T21:28:26.404Z', 'update_at': '2023-10-24T17:43:39.278Z', 'descriptionLink': '', 'depth': {'num_asks': 9, 'num_bids': 7, 'num_running': 7, 'asks': {'0x15Dfce70c27a9867794e1912A54F1F7949452DaB': 5, '0x9c12E6313B59799fe3c9da9d6D6a2bBc88bC6580': 4}, 'asks_updated': '2023-11-30T08:44:33.692605096Z', 'gpus': {'': 0}, 'qps': 0.043180153, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'throughput_in': 62.66865, 'throughput_out': 5.179817}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '6532f0faf94bacfc629b4cf6', 'name': 'NousResearch/Nous-Hermes-llama-2-7b', 'display_name': 'Nous Hermes LLaMA-2 (7B)', 'display_type': 'chat', 'description': 'Nous-Hermes-Llama2-7b is a state-of-the-art language model fine-tuned on over 300,000 instructions.', 'license': 'LLaMA license Agreement (Meta)', 'link': 'https://huggingface.co/NousResearch/Nous-Hermes-llama-2-7b', 'creator_organization': 'NousResearch', 'hardware_label': 'A100 80GB', 'pricing_tier': 'Featured', 'access': 'open', 'num_parameters': 6738415616, 'show_in_playground': True, 'isFeaturedModel': True, 'context_length': 4096, 'config': {'prompt_format': '### Instruction:\\n{prompt}\\n### Response:\\n', 'stop': ['###', '</s>'], 'chat_template_name': 'llama', 'chat_template': \"{% for message in messages %}{% if message['role'] == 'user' %}{{ '### Instruction:\\n' + message['content'] + '\\n' }}{% else %}{{ '### Response:\\n' + message['content'] + '\\n' }}{% endif %}{% endfor %}{{ '### Response:\\n' }}\"}, 'pricing': {'input': 50, 'output': 50, 'hourly': 0}, 'created_at': '2023-10-20T21:28:26.403Z', 'update_at': '2023-10-24T17:41:52.365Z', 'descriptionLink': '', 'depth': {'num_asks': 3, 'num_bids': 1, 'num_running': 1, 'asks': {'0xA4845663a0c61e906cB0A2A53DcFE488dF651d33': 1, '0xDE5095f4D8a85dAA8360521bA1b1b30CB7027776': 1, '0xa4563A7EF1db4afb51ceD6467ad92956E3E58949': 1}, 'asks_updated': '2023-11-30T08:37:34.810890867Z', 'gpus': {'': 0}, 'qps': 0.024048684, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'throughput_in': 0.48132718, 'throughput_out': 1.8405}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64f677bdbc372ce719b97f05', 'name': 'NumbersStation/nsql-llama-2-7B', 'display_name': 'NSQL LLaMA-2 (7B)', 'display_type': 'code', 'description': 'NSQL is a family of autoregressive open-source large foundation models (FMs) designed specifically for SQL generation tasks.', 'license': 'llama2', 'creator_organization': 'Numbers Station', 'hardware_label': 'A40 48GB', 'pricing_tier': 'supported', 'num_parameters': 7000000000, 'show_in_playground': True, 'isFeaturedModel': True, 'context_length': 4096, 'config': {'chat_template_name': 'llama'}, 'pricing': {'input': 50, 'output': 50, 'hourly': 0}, 'created_at': '2023-09-05T00:35:09.649Z', 'update_at': '2023-09-05T00:35:09.649Z', 'access': '', 'link': '', 'descriptionLink': '', 'depth': {'num_asks': 1, 'num_bids': 0, 'num_running': 0, 'asks': {'0xBb702A9526c057836fe845DF91dEAa3B5a48cc84': 1}, 'asks_updated': '2023-11-30T07:38:19.375477274Z', 'gpus': {'': 0}, 'qps': 0.028237915, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'throughput_in': 0.7291023, 'throughput_out': 0.6138619}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '6532f0faf94bacfc629b4cf5', 'name': 'Open-Orca/Mistral-7B-OpenOrca', 'display_name': 'OpenOrca Mistral (7B) 8K', 'display_type': 'chat', 'description': 'An OpenOrca dataset fine-tune on top of Mistral 7B by the OpenOrca team.', 'license': 'apache-2.0', 'link': 'https://huggingface.co/Open-Orca/Mistral-7B-OpenOrca', 'creator_organization': 'OpenOrca', 'hardware_label': 'A100 80GB', 'pricing_tier': 'Featured', 'access': 'open', 'num_parameters': 7241748480, 'show_in_playground': True, 'isFeaturedModel': True, 'context_length': 8192, 'config': {'stop': ['<|im_end|>'], 'prompt_format': '<|im_start|>user\\n{prompt}<|im_end|>\\n<|im_start|>assistant\\n', 'add_generation_prompt': True, 'chat_template_name': 'default'}, 'pricing': {'input': 50, 'output': 50, 'hourly': 0}, 'created_at': '2023-10-20T21:28:26.403Z', 'update_at': '2023-10-24T00:01:52.541Z', 'descriptionLink': '', 'depth': {'num_asks': 21, 'num_bids': 20, 'num_running': 20, 'asks': {'0x0A221f2E0D6Ffd49F33d6BB70ac64EA1a19F331d': 5, '0x2975c4dc20653d24F44998124C06Ce68948a3Ef3': 1, '0x3c47377fd6053D37a6Fd1A10E5d1a955489A22C9': 1, '0x736dC7C200c2FDc3757E90C6FF3cdc6b4aD16D04': 8, '0x9e0b102D8c12d36526279C93Ec1A11033fD3b251': 2, '0xF1B0684e7606c7207AEa19B1190E1c9804bf055C': 1, '0xc24D4c84a0B50274837Fc2dfACA9809a4771c7f4': 1, '0xcfeC9A83690c2c2e12FA1214B51Cf14545ef7B16': 1, '0xf5d239a69960B8a18e3D3c895D55A6221A0f66bc': 1}, 'asks_updated': '2023-11-30T08:46:31.5146332Z', 'gpus': {'': 0}, 'qps': 0.414868, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'throughput_in': 2826.4075, 'throughput_out': 583.08673}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64fbbc5adfdb1e4b06b5d5cc', 'name': 'Phind/Phind-CodeLlama-34B-Python-v1', 'display_name': 'Phind Code LLaMA Python v1 (34B)', 'display_type': 'code', 'description': 'This model is fine-tuned from CodeLlama-34B-Python and achieves 69.5% pass@1 on HumanEval.', 'license': 'llama2', 'creator_organization': 'Phind', 'hardware_label': 'A100 80GB', 'pricing_tier': 'supported', 'access': 'open', 'num_parameters': 33743970304, 'show_in_playground': True, 'isFeaturedModel': True, 'context_length': 16384, 'config': {'prompt_format': '### Instruction:\\n{prompt}\\n### Response:\\n', 'stop': ['</s>', '###'], 'chat_template': \"{% for message in messages %}{% if message['role'] == 'user' %}{{ '### Instruction:\\n' + message['content'] + '\\n' }}{% else %}{{ '### Response:\\n' + message['content'] + '\\n' }}{% endif %}{% endfor %}{{ '### Response:\\n' }}\"}, 'pricing': {'input': 200, 'output': 200, 'hourly': 0}, 'created_at': '2023-09-09T00:29:14.496Z', 'update_at': '2023-09-09T00:29:14.496Z', 'link': '', 'descriptionLink': '', 'depth': {'num_asks': 7, 'num_bids': 6, 'num_running': 6, 'asks': {'0x23b26564e6Cc01cDeE6C933fE14C55892225A08C': 7}, 'asks_updated': '2023-11-30T07:50:07.24541836Z', 'gpus': {'': 0}, 'qps': 0.031949587, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'throughput_in': 0.8171969, 'throughput_out': 14.958518}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64fbbc5adfdb1e4b06b5d5cb', 'name': 'Phind/Phind-CodeLlama-34B-v2', 'display_name': 'Phind Code LLaMA v2 (34B)', 'display_type': 'code', 'description': 'Phind-CodeLlama-34B-v1 trained on additional 1.5B tokens high-quality programming-related data proficient in Python, C/C++, TypeScript, Java, and more.', 'license': 'llama2', 'creator_organization': 'Phind', 'hardware_label': 'A100 80GB', 'pricing_tier': 'supported', 'access': 'open', 'num_parameters': 33743970304, 'show_in_playground': True, 'isFeaturedModel': True, 'context_length': 16384, 'config': {'prompt_format': '### System Prompt\\nYou are an intelligent programming assistant.\\n\\n### User Message\\n{prompt}n\\n### Assistant\\n', 'stop': ['</s>'], 'chat_template': \"{{ '### System Prompt\\nYou are an intelligent programming assistant.\\n\\n' }}{% for message in messages %}{% if message['role'] == 'user' %}{{ '### User Message\\n' + message['content'] + '\\n' }}{% else %}{{ '### Assistant\\n' + message['content'] + '\\n' }}{% endif %}{% endfor %}{{ '### Assistant\\n' }}\"}, 'pricing': {'input': 200, 'output': 200, 'hourly': 0}, 'created_at': '2023-09-09T00:29:14.496Z', 'update_at': '2023-09-09T00:29:14.496Z', 'link': '', 'descriptionLink': '', 'depth': {'num_asks': 11, 'num_bids': 9, 'num_running': 9, 'asks': {'0x4dadba425016Ca6154712e14a68F83b7147F3157': 4, '0x92C124672726325e798A1D55E1Fef1D060657f1b': 2, '0x9D8047723e185c555B9899134ff976f6b6217Ed4': 5}, 'asks_updated': '2023-11-30T08:02:10.834713043Z', 'gpus': {'': 0}, 'qps': 0.037455723, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'throughput_in': 1.141918, 'throughput_out': 2.0291636}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64acee11227f790586239d36', 'name': 'SG161222/Realistic_Vision_V3.0_VAE', 'display_name': 'Realistic Vision 3.0', 'display_type': 'image', 'description': 'Fine-tune version of Stable Diffusion focused on photorealism.', 'license': 'creativeml-openrail-m', 'link': 'https://huggingface.co/SG161222/Realistic_Vision_V1.4', 'creator_organization': 'SG161222', 'hardware_label': 'A40 48GB', 'pricing_tier': 'supported', 'access': 'open', 'show_in_playground': True, 'isFeaturedModel': True, 'external_pricing_url': 'https://www.together.xyz/apis#pricing', 'config': {'height': 1024, 'width': 1024, 'steps': 20, 'number_of_images': 2, 'seed': 42}, 'created_at': '2023-07-11T05:52:17.219Z', 'update_at': '2023-07-11T05:52:17.219Z', 'descriptionLink': '', 'pricing': {'hourly': 0, 'input': 0, 'output': 0, 'base': 0, 'finetune': 0}, 'depth': {'num_asks': 1, 'num_bids': 0, 'num_running': 0, 'asks': {'0x1E128f472069E38aEF6B8f25147B42EF81f0F3C0': 1}, 'asks_updated': '2023-11-30T08:40:54.301373178Z', 'gpus': {'NVIDIA A40': 1}, 'options': {'input=text,image': 1}, 'qps': 0.026349546, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'throughput_in': 0.57462096}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '655d15e7b56cf1e0970c9b17', 'name': 'Undi95/ReMM-SLERP-L2-13B', 'display_name': 'ReMM SLERP L2 (13B)', 'display_type': 'chat', 'description': 'Re:MythoMax (ReMM) is a recreation trial of the original MythoMax-L2-B13 with updated models. This merge use SLERP [TESTING] to merge ReML and Huginn v1.2.', 'license': 'LLaMA license Agreement (Meta)', 'link': 'https://huggingface.co/Undi95/ReMM-SLERP-L2-13B', 'creator_organization': 'Undi95', 'hardware_label': 'A100 80GB', 'pricing_tier': 'Featured', 'access': 'open', 'num_parameters': 13000000000, 'show_in_playground': True, 'isFeaturedModel': False, 'context_length': 4096, 'config': {'stop': ['###'], 'prompt_format': '### Instruction:\\n{prompt}\\n\\n### Response:', 'chat_template': \"{% for message in messages %}{% if message['role'] == 'user' %}{{ '### Instruction:\\n' + message['content'] + '\\n\\n' }}{% else %}{{ '### Response:\\n' + message['content'] + '\\n\\n' }}{% endif %}{% endfor %}{{ '### Response:' }}\"}, 'pricing': {'input': 75, 'output': 75, 'hourly': 0}, 'created_at': '2023-11-21T20:41:11.759Z', 'update_at': '2023-11-21T20:41:11.759Z', 'descriptionLink': '', 'depth': {'num_asks': 15, 'num_bids': 14, 'num_running': 14, 'asks': {'0x008A982F855FcED4AF721C15bF7B8D864AE50682': 1, '0x313570338f45B8A65ff340f4a3c78eeB484754be': 2, '0x346Fd8efcc13051868443157Fd3A5514F5195234': 4, '0x37Cb70365e291fd13D0E5B9F51307f1dEf2e6Bf5': 1, '0x4563C666F9807bF2302d81C940d3BBA5dE4B6Ed5': 1, '0x90e7533D373Ee7B0130d26044BF74AE2B788077b': 1, '0xA228ae3c0CaD0eBe37A125d99A38Dd3000dc80f1': 1, '0xF92c3656D2ae1Adf42ac7a3141E8eB8452CcA17E': 1, '0xa01129c319063A4dfd5a9CF1DA07dfAc84Ea229b': 1, '0xcdcB3170C76978983C890d75a47Dc68c5b86E287': 1, '0xfA8697423283F2A115679356B6EafbB248F87F9B': 1}, 'asks_updated': '2023-11-30T07:57:32.870092912Z', 'gpus': {'': 0}, 'qps': 0.03832178, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'throughput_in': 251.32867, 'throughput_out': 13.758019}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '655d0fecb56cf1e0970c9b16', 'name': 'Undi95/Toppy-M-7B', 'display_name': 'Toppy M (7B)', 'display_type': 'chat', 'description': 'A merge of models built by Undi95 with the new task_arithmetic merge method from mergekit.', 'license': 'LLaMA license Agreement (Meta)', 'link': 'https://huggingface.co/Undi95/Toppy-M-7B', 'creator_organization': 'Undi95', 'hardware_label': 'A100 80GB', 'pricing_tier': 'Featured', 'access': 'open', 'num_parameters': 7241748480, 'show_in_playground': True, 'isFeaturedModel': False, 'context_length': 4096, 'config': {'stop': ['###'], 'prompt_format': '### Instruction:\\n{prompt}\\n\\n### Response:', 'chat_template': \"{% for message in messages %}{% if message['role'] == 'user' %}{{ '### Instruction:\\n' + message['content'] + '\\n\\n' }}{% else %}{{ '### Response:\\n' + message['content'] + '\\n\\n' }}{% endif %}{% endfor %}{{ '### Response:' }}\"}, 'pricing': {'input': 50, 'output': 50, 'hourly': 0}, 'created_at': '2023-11-21T20:15:40.468Z', 'update_at': '2023-11-21T20:15:40.468Z', 'descriptionLink': '', 'depth': {'num_asks': 32, 'num_bids': 31, 'num_running': 31, 'asks': {'0x0066d2f91029375f3FdD8f672912d48B41421dF5': 1, '0x08D10b5e76d3938A11ACd8fc56973Fcf77A3ED6d': 1, '0x1725835784a7174d77894C6f13C15D05D3d642Eb': 1, '0x23b07b1a525C162EF84D691f74EE61B76466b40b': 1, '0x251aB24eE9c3DE3E47Ab75EF98c42Ef534788E53': 1, '0x2AD0168B87ba77cc50dAfDc05057cA00CC3bA63E': 1, '0x2e58c20b3e8090632DdE22091EC734E2F15207AA': 1, '0x2fB3753aac57597d4a969E1187340B1C9FBC90b9': 1, '0x39A7EEA56C2875E13A4C5B24dA11E8072C5efAE7': 1, '0x3b0a6a8036F290B0A49C31FeCb02feF3355a349C': 1, '0x470f61eab30942a685137dD71DD2a3cc707b4943': 1, '0x50e97ad179677f97E0b04a05d4406ea0d5F869fa': 1, '0x51557c377Fd3709DCBE1169D29D509a5dBa2eE5D': 1, '0x6160E35FE5b2A931dACaBa0E316483B75Dd940F9': 1, '0x62e654727daB2238529979443156A938f7E79A13': 1, '0x67E72b30a228c3dE7ceD39f3182B74996F70f80F': 1, '0x698dd4A106A28f157875bcE1726aD3F9cbb2335C': 1, '0x751B1F79F7d1D06C7C691079A7BE6Afe117eb06b': 1, '0x77de5180A82160a8E861E4B1E61b8534282Bdc34': 1, '0x893edda2792978d798feb74d1d3770DF07D26ca7': 1, '0x8A021270A692559fD7bE9aDC8F6DF3cFfDb56821': 1, '0x8E99D691ef451333CE25553451c625a414dd418E': 1, '0x941c5DbBe43AC8Ef157D4b807f846A6eAce0E9d2': 1, '0x97Dc9Fd767990a358288d38aEaDdb33235f9391C': 1, '0x98d33a085B6051401F23cae00bE94376b49790B7': 1, '0xA1776AFb86f4f5616016488Af2059B6D85c8aC95': 1, '0xA27AC1a6187331de3277a4Ff240528461Ab6cec7': 1, '0xB4137A309320cFD19490Edbc24bc326D3C483316': 1, '0xD7445AAEb4b7445002Dd67121362Bb0e34b900Ea': 1, '0xc20820625589b9A924B96ED914d34b501Ee0f2b6': 1, '0xec3294A37611926E36766aE0fAECd1c4a6A1d852': 1, '0xefa20f57179ffdc04c2fCbdc77B0E0848356A242': 1}, 'asks_updated': '2023-11-30T08:23:35.009783004Z', 'gpus': {'': 0}, 'qps': 0.0016657896, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'throughput_in': 3.261253e-07, 'throughput_out': 5.7661254e-07}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64fbbc5adfdb1e4b06b5d5cd', 'name': 'WizardLM/WizardCoder-15B-V1.0', 'display_name': 'WizardCoder v1.0 (15B)', 'display_type': 'code', 'description': 'This model empowers Code LLMs with complex instruction fine-tuning, by adapting the Evol-Instruct method to the domain of code.', 'license': 'llama2', 'creator_organization': 'WizardLM', 'hardware_label': 'A100 80GB', 'pricing_tier': 'supported', 'access': 'open', 'num_parameters': 15517462528, 'show_in_playground': True, 'context_length': 8192, 'config': {'prompt_format': '### Instruction:\\n{prompt}\\n\\n### Response:\\n', 'stop': ['###', '<|endoftext|>'], 'chat_template': \"{% for message in messages %}{% if message['role'] == 'user' %}{{ '### Instruction:\\n' + message['content'] + '\\n\\n' }}{% else %}{{ '### Response:\\n' + message['content'] + '\\n\\n' }}{% endif %}{% endfor %}{{ '### Response:\\n' }}\"}, 'pricing': {'input': 75, 'output': 75, 'hourly': 0}, 'created_at': '2023-09-09T00:29:14.496Z', 'update_at': '2023-09-09T00:29:14.496Z', 'link': '', 'descriptionLink': '', 'depth': {'num_asks': 7, 'num_bids': 6, 'num_running': 6, 'asks': {'0x63199A7778a823BbfffebA3432C7c87831595648': 7}, 'asks_updated': '2023-11-30T08:25:10.386445064Z', 'gpus': {'': 0}, 'qps': 0.026346121, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'throughput_in': 0.67388237, 'throughput_out': 3.9675195}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '6567d4e5d1c5e59967640530', 'name': 'WizardLM/WizardLM-13B-V1.2', 'display_name': 'WizardLM v1.2 (13B)', 'display_type': 'chat', 'description': 'This model achieves a substantial and comprehensive improvement on coding, mathematical reasoning and open-domain conversation capacities', 'license': 'llama2', 'creator_organization': 'WizardLM', 'hardware_label': 'A100', 'pricing_tier': 'Featured', 'num_parameters': 13000000000, 'release_date': '2023-11-01T00:00:00.000Z', 'show_in_playground': True, 'isFeaturedModel': True, 'config': {'stop': ['</s>', 'USER:', 'ASSISTANT:'], 'prompt_format': 'USER: {prompt} ASSISTANT:', 'pre_prompt': \"A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions. \"}, 'pricing': {'input': 50, 'output': 50}, 'created_at': '2023-11-30T00:18:45.791Z', 'update_at': '2023-11-30T01:20:01.779Z', 'access': '', 'link': '', 'descriptionLink': '', 'depth': {'num_asks': 1, 'num_bids': 0, 'num_running': 0, 'asks': {'0x47403098D12c575B632Ad32a5666317D2A5d10C4': 1}, 'asks_updated': '2023-11-30T07:57:36.051952288Z', 'gpus': {'': 0}, 'qps': 0, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64f67555bc372ce719b97f03', 'name': 'WizardLM/WizardLM-70B-V1.0', 'display_name': 'WizardLM v1.0 (70B)', 'display_type': 'language', 'description': 'This model achieves a substantial and comprehensive improvement on coding, mathematical reasoning and open-domain conversation capacities.', 'license': 'llama2', 'creator_organization': 'WizardLM', 'hardware_label': '2x A100 80GB', 'pricing_tier': 'supported', 'num_parameters': 70000000000, 'show_in_playground': True, 'isFeaturedModel': True, 'context_length': 4096, 'config': {'stop': ['</s>'], 'prompt_format': 'USER: {prompt} ASSISTANT:', 'chat_template': \"{% for message in messages %}{% if message['role'] == 'user' %}{{ 'USER: ' + message['content'] + ' ' }}{% else %}{{ 'ASSISTANT:' + message['content'] + '\\n' }}{% endif %}{% endfor %}{{ 'ASSISTANT:' }}\"}, 'pricing': {'input': 225, 'output': 225, 'hourly': 0}, 'created_at': '2023-09-05T00:24:53.327Z', 'update_at': '2023-09-05T00:24:53.327Z', 'access': '', 'link': '', 'descriptionLink': '', 'depth': {'num_asks': 1, 'num_bids': 1, 'num_running': 1, 'asks': {'0x9bFb1a1D28Bd50dE78bcb8A79663dA916ade6f3e': 1}, 'asks_updated': '2023-11-30T07:57:24.047157246Z', 'gpus': {'': 0}, 'qps': 0.054244023, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'throughput_in': 151.09865, 'throughput_out': 6.288682}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64f676f7bc372ce719b97f04', 'name': 'garage-bAInd/Platypus2-70B-instruct', 'display_name': 'Platypus2 Instruct (70B)', 'display_type': 'chat', 'description': 'An instruction fine-tuned LLaMA-2 (70B) model by merging Platypus2 (70B) by garage-bAInd and LLaMA-2 Instruct v2 (70B) by upstage.', 'license': 'CC BY-NC-4.0', 'creator_organization': 'garage-bAInd', 'hardware_label': '2x A100 80GB', 'pricing_tier': 'featured', 'num_parameters': 70000000000, 'show_in_playground': True, 'isFeaturedModel': True, 'context_length': 4096, 'config': {'stop': ['</s>', '###'], 'prompt_format': '### Instruction:\\n{prompt}\\n### Response:\\n'}, 'pricing': {'input': 225, 'output': 225, 'hourly': 0}, 'created_at': '2023-09-05T00:31:51.264Z', 'update_at': '2023-09-07T01:46:29.338Z', 'access': '', 'link': '', 'descriptionLink': '', 'depth': {'num_asks': 1, 'num_bids': 0, 'num_running': 0, 'asks': {'0x763611653e222b6a0a8b7E060FB819A1FfcDF025': 1}, 'asks_updated': '2023-11-30T08:09:01.117588399Z', 'gpus': {'': 0}, 'qps': 0.022857781, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'throughput_in': 0.45094335, 'throughput_out': 1.3351386}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64acea57227f790586239d0d', 'name': 'huggyllama/llama-65b', 'display_name': 'LLaMA (65B)', 'display_type': 'language', 'description': 'An auto-regressive language model, based on the transformer architecture. The model comes in different sizes: 7B, 13B, 33B and 65B parameters.', 'license': 'LLaMA license Agreement (Meta)', 'link': 'https://huggingface.co/decapoda-research/llama-30b-hf-int4/commit/95d097b272bd0a84a164aa8116e8c09661487581#d2h-740129', 'creator_organization': 'Meta', 'hardware_label': '2x A100 80GB', 'pricing_tier': 'supported', 'access': 'open', 'num_parameters': 65000000000, 'show_in_playground': True, 'isFeaturedModel': True, 'context_length': 2048, 'config': {'chat_template_name': 'llama'}, 'pricing': {'input': 225, 'output': 225, 'hourly': 0}, 'created_at': '2023-07-11T05:36:23.656Z', 'update_at': '2023-07-11T05:36:23.656Z', 'descriptionLink': '', 'depth': {'num_asks': 1, 'num_bids': 0, 'num_running': 0, 'asks': {'0x78B092625C02856925454cACa099990A7F543eE7': 1}, 'asks_updated': '2023-11-30T06:57:37.148783242Z', 'gpus': {'': 0}, 'qps': 0.012420984, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'throughput_in': 0.11917307, 'throughput_out': 0.8426892}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64fbbc5adfdb1e4b06b5d5ce', 'name': 'lmsys/vicuna-13b-v1.5-16k', 'display_name': 'Vicuna v1.5 16K (13B)', 'display_type': 'chat', 'description': 'Vicuna is a chat assistant trained by fine-tuning Llama 2 on user-shared conversations collected from ShareGPT.', 'license': 'llama2', 'creator_organization': 'LM Sys', 'hardware_label': 'A100 80GB', 'pricing_tier': 'supported', 'access': 'open', 'num_parameters': 13015864320, 'show_in_playground': True, 'isFeaturedModel': True, 'context_length': 16384, 'config': {'prompt_format': 'USER: {prompt}\\nASSISTANT:', 'stop': ['</s>'], 'chat_template': \"{% for message in messages %}{{message['role'].toLocaleUpperCase() + ': ' + message['content'] + '\\n'}}{% endfor %}{{ 'ASSISTANT:' }}\"}, 'pricing': {'input': 75, 'output': 75, 'hourly': 0}, 'created_at': '2023-09-09T00:29:14.496Z', 'update_at': '2023-09-09T00:29:14.496Z', 'link': '', 'descriptionLink': '', 'depth': {'num_asks': 10, 'num_bids': 8, 'num_running': 8, 'asks': {'0x6FDb2202dDE8386D67b8D64849Fb593E7cABE01B': 1, '0xAcEb074D6C8d98a788A874F2c40b65815cCf313d': 9}, 'asks_updated': '2023-11-30T08:50:52.701620834Z', 'gpus': {'': 0}, 'qps': 0.02528779, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'throughput_in': 0.5259339, 'throughput_out': 1.4524498}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64f678e7bc372ce719b97f06', 'name': 'lmsys/vicuna-13b-v1.5', 'display_name': 'Vicuna v1.5 (13B)', 'display_type': 'chat', 'description': 'Vicuna is a chat assistant trained by fine-tuning Llama 2 on user-shared conversations collected from ShareGPT.', 'license': 'llama2', 'creator_organization': 'LM Sys', 'hardware_label': 'A40 48GB', 'pricing_tier': 'supported', 'access': 'open', 'num_parameters': 13000000000, 'show_in_playground': True, 'isFeaturedModel': True, 'context_length': 4096, 'config': {'stop': ['</s>'], 'prompt_format': 'USER: {prompt}\\nASSISTANT:', 'chat_template': \"{% for message in messages %}{{message['role'].toLocaleUpperCase() + ': ' + message['content'] + '\\n'}}{% endfor %}{{ 'ASSISTANT:' }}\"}, 'pricing': {'input': 75, 'output': 75, 'hourly': 0}, 'created_at': '2023-09-05T00:40:07.763Z', 'update_at': '2023-09-05T00:40:07.763Z', 'link': '', 'descriptionLink': '', 'depth': {'num_asks': 5, 'num_bids': 3, 'num_running': 3, 'asks': {'0x4355788cD083a3DFEd4Ab134b49aeC1B9a4820ae': 3, '0x8FFf4DEeFE3C4Aa5F2810d372617B58D262b064B': 2}, 'asks_updated': '2023-11-30T08:25:54.596717379Z', 'gpus': {'': 0}, 'qps': 0.23243612, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'throughput_in': 1297.5328, 'throughput_out': 128.26349}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '652da26579174a6bc507647f', 'name': 'lmsys/vicuna-7b-v1.5', 'display_name': 'Vicuna v1.5 (7B)', 'display_type': 'chat', 'description': 'Vicuna is a chat assistant trained by fine-tuning Llama 2 on user-shared conversations collected from ShareGPT.', 'license': 'LLaMA license Agreement (Meta)', 'link': 'https://huggingface.co/lmsys/vicuna-7b-v1.5', 'creator_organization': 'LM Sys', 'hardware_label': 'A40 48GB', 'pricing_tier': 'Featured', 'access': 'open', 'num_parameters': 6738415616, 'show_in_playground': True, 'isFeaturedModel': False, 'context_length': 4096, 'config': {'stop': ['</s>', 'USER:'], 'prompt_format': 'USER: {prompt}\\nASSISTANT: Hello!', 'chat_template': \"{% for message in messages %}{{message['role'].toLocaleUpperCase() + ': ' + message['content'] + '\\n'}}{% endfor %}{{ 'ASSISTANT:' }}\"}, 'pricing': {'input': 50, 'output': 50, 'hourly': 0}, 'created_at': '2023-10-16T20:51:49.194Z', 'update_at': '2023-10-16T20:51:49.194Z', 'descriptionLink': '', 'depth': {'num_asks': 1, 'num_bids': 0, 'num_running': 0, 'asks': {'0xb73DBA565275A7403Cc93D0b99Ef5D795D0eeC05': 1}, 'asks_updated': '2023-11-30T08:21:51.501138379Z', 'gpus': {'': 0}, 'qps': 0.03308953, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'throughput_in': 0.75217676, 'throughput_out': 1.0372027}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '6514c873829715ded9cd17b1', 'name': 'mistralai/Mistral-7B-Instruct-v0.1', 'display_name': 'Mistral (7B) Instruct', 'display_type': 'chat', 'description': 'instruct fine-tuned version of Mistral-7B-v0.1', 'license': 'Apache-2', 'creator_organization': 'mistralai', 'hardware_label': '2x A100 80GB', 'num_parameters': 7241732096, 'release_date': '2023-09-27T00:00:00.000Z', 'show_in_playground': True, 'isFeaturedModel': True, 'context_length': 4096, 'config': {'stop': ['[/INST]', '</s>'], 'prompt_format': '<s>[INST] {prompt} [/INST]', 'chat_template_name': 'llama'}, 'pricing': {'input': 50, 'output': 50, 'hourly': 0}, 'created_at': '2023-09-28T00:27:31.815Z', 'update_at': '2023-10-12T01:13:51.840Z', 'instances': [{'avzone': 'us-east-1a', 'cluster': 'happypiglet'}], 'access': '', 'link': '', 'descriptionLink': '', 'depth': {'num_asks': 2, 'num_bids': 0, 'num_running': 0, 'asks': {'0xe418D299aAede108588E6fBf99F06C25f2671738': 1}, 'asks_updated': '2023-11-30T07:20:20.174860246Z', 'gpus': {'': 0}, 'qps': 11.133333333333333, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'stats': [{'avzone': 'us-east-1a', 'cluster': 'happypiglet', 'capacity': 0.37225613020666, 'qps': 11.133333333333333}]}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '6514c6ee829715ded9cd17b0', 'name': 'mistralai/Mistral-7B-v0.1', 'display_name': 'Mistral (7B)', 'display_type': 'language', 'description': '7.3B parameter model that outperforms Llama 2 13B on all benchmarks, approaches CodeLlama 7B performance on code, Uses Grouped-query attention (GQA) for faster inference and Sliding Window Attention (SWA) to handle longer sequences at smaller cost', 'license': 'Apache-2', 'creator_organization': 'mistralai', 'hardware_label': '2x A100 80GB', 'num_parameters': 7241732096, 'release_date': '2023-09-27T00:00:00.000Z', 'show_in_playground': True, 'isFeaturedModel': True, 'context_length': 4096, 'config': {'stop': ['</s>'], 'prompt_format': '{prompt}', 'chat_template_name': 'llama'}, 'pricing': {'input': 50, 'output': 50, 'hourly': 0}, 'created_at': '2023-09-28T00:21:02.330Z', 'update_at': '2023-09-28T00:21:02.330Z', 'instances': [{'avzone': 'us-east-1a', 'cluster': 'happypiglet'}], 'access': '', 'link': '', 'descriptionLink': '', 'depth': {'num_asks': 2, 'num_bids': 0, 'num_running': 0, 'asks': {'0xAfFc4830905540bbD64C0a4d8cA10493F75aF0e6': 1}, 'asks_updated': '2023-11-30T07:50:08.540193079Z', 'gpus': {'': 0}, 'qps': 0, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'stats': [{'avzone': 'us-east-1a', 'cluster': 'happypiglet', 'capacity': 0.06818181818181818, 'qps': 0}]}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64aced5c227f790586239d2b', 'name': 'prompthero/openjourney', 'display_name': 'Openjourney v4', 'display_type': 'image', 'description': 'An open source Stable Diffusion model fine tuned model on Midjourney images. ', 'license': 'creativeml-openrail-m', 'link': 'https://huggingface.co/prompthero/openjourney', 'creator_organization': 'Prompt Hero', 'hardware_label': 'A40 48GB', 'pricing_tier': 'featured', 'access': 'open', 'num_parameters': 13000000000, 'show_in_playground': True, 'isFeaturedModel': True, 'external_pricing_url': 'https://www.together.xyz/apis#pricing', 'config': {'height': 512, 'width': 512, 'steps': 20, 'number_of_images': 2, 'seed': 42}, 'pricing': {'input': 75, 'output': 75, 'hourly': 0}, 'created_at': '2023-07-11T05:49:16.586Z', 'update_at': '2023-07-11T05:49:16.586Z', 'descriptionLink': '', 'depth': {'num_asks': 2, 'num_bids': 0, 'num_running': 0, 'asks': {'0x5C5b60Ea2C7046FDdf7F7be3853d046301334a85': 1, '0xB2bFeaa446Cc0376249ed2d7a8f5C32E0705e556': 1}, 'asks_updated': '2023-11-30T08:19:19.005370646Z', 'gpus': {'NVIDIA A40': 2}, 'options': {'input=text,image': 2}, 'qps': 0.019606669, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'throughput_in': 0.4359551}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '6495ff1312907e072b8aece1', 'name': 'runwayml/stable-diffusion-v1-5', 'display_name': 'Stable Diffusion 1.5', 'display_type': 'image', 'description': 'Latent text-to-image diffusion model capable of generating photo-realistic images given any text input.', 'license': 'creativeml-openrail-m', 'link': 'https://huggingface.co/runwayml/stable-diffusion-v1-5', 'creator_organization': 'Runway ML', 'hardware_label': 'A100 80GB', 'pricing_tier': 'featured', 'show_in_playground': True, 'isFeaturedModel': True, 'external_pricing_url': 'https://www.together.xyz/apis#pricing', 'config': {'height': 512, 'width': 512, 'steps': 20, 'number_of_images': 2, 'seed': 42}, 'created_at': '2023-06-23T20:22:43.572Z', 'update_at': '2023-06-23T20:22:43.572Z', 'access': '', 'descriptionLink': '', 'pricing': {'hourly': 0, 'input': 0, 'output': 0, 'base': 0, 'finetune': 0}, 'depth': {'num_asks': 1, 'num_bids': 0, 'num_running': 0, 'asks': {'0x98D41CFC96e488D9810431B65Aa98EBfc87b73c8': 1}, 'asks_updated': '2023-11-30T07:44:28.410485615Z', 'gpus': {'NVIDIA A40': 1}, 'options': {'input=text,image': 1}, 'qps': 0.019918047, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'throughput_in': 0.45013}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64acef00227f790586239d3b', 'name': 'stabilityai/stable-diffusion-2-1', 'display_name': 'Stable Diffusion 2.1', 'display_type': 'image', 'description': 'Latent text-to-image diffusion model capable of generating photo-realistic images given any text input.', 'license': 'openrail++', 'link': 'https://huggingface.co/stabilityai/stable-diffusion-2-1', 'creator_organization': 'Stability AI', 'hardware_label': 'A100 80GB', 'pricing_tier': 'featured', 'show_in_playground': True, 'isFeaturedModel': True, 'external_pricing_url': 'https://www.together.xyz/apis#pricing', 'created_at': '2023-06-23T20:22:43.572Z', 'update_at': '2023-06-23T20:22:43.572Z', 'access': '', 'descriptionLink': '', 'pricing': {'hourly': 0, 'input': 0, 'output': 0, 'base': 0, 'finetune': 0}, 'depth': {'num_asks': 2, 'num_bids': 0, 'num_running': 0, 'asks': {'0x8e6cadaf8bE88b995920A561DE48434b11b05170': 1, '0xC9494f3A014EAC6DD43De5b03E03364F1AcC9ea7': 1}, 'asks_updated': '2023-11-30T08:32:02.448213221Z', 'gpus': {'NVIDIA A100 80GB PCIe': 2}, 'options': {'input=text,image': 2}, 'qps': 0.012969065, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'throughput_in': 0.31114987}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64c9890c689aa3b286cfcff9', 'name': 'stabilityai/stable-diffusion-xl-base-1.0', 'display_name': 'Stable Diffusion XL 1.0', 'display_type': 'image', 'description': 'A text-to-image generative AI model that excels at creating 1024x1024 images.', 'license': 'openrail++', 'link': 'https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0', 'creator_organization': 'Stability AI', 'hardware_label': 'A100 80GB', 'pricing_tier': 'featured', 'access': 'open', 'show_in_playground': True, 'isFeaturedModel': True, 'external_pricing_url': 'https://www.together.xyz/apis#pricing', 'config': {'height': 1024, 'width': 1024, 'steps': 20, 'number_of_images': 2, 'seed': 42}, 'created_at': '2023-08-01T22:37:00.851Z', 'update_at': '2023-08-01T22:37:00.851Z', 'descriptionLink': '', 'pricing': {'hourly': 0, 'input': 0, 'output': 0, 'base': 0, 'finetune': 0}, 'depth': {'num_asks': 1, 'num_bids': 0, 'num_running': 0, 'asks': {'0x2E595c6ee5e62FeFF9f426b239a2fB0970476593': 1}, 'asks_updated': '2023-11-30T08:09:00.678144472Z', 'gpus': {'NVIDIA A100 80GB PCIe': 1}, 'options': {'input=text,image': 1}, 'qps': 0.014992103, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'throughput_in': 0.3561096}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '653c053fd9679a84df55c4e7', 'name': 'teknium/OpenHermes-2-Mistral-7B', 'display_name': 'OpenHermes-2-Mistral (7B)', 'display_type': 'chat', 'description': 'State of the art Mistral Fine-tuned on extensive public datasets', 'license': 'Apache-2', 'creator_organization': 'teknium', 'hardware_label': 'A40', 'pricing_tier': 'Featured', 'num_parameters': 7241732096, 'release_date': '2023-10-27T00:00:00.000Z', 'show_in_playground': True, 'isFeaturedModel': True, 'config': {'stop': ['<|im_end|>', '<|im_start|>'], 'prompt_format': '<|im_start|>user\\n{prompt}<|im_end|>\\n<|im_start|>assistant\\n', 'pre_prompt': '<|im_start|>system\\nYou are thoughtful, helpful, polite, honest, and friendly<|im_end|>\\n', 'add_generation_prompt': True, 'chat_template_name': 'default'}, 'pricing': {'input': 50, 'output': 50, 'hourly': 0}, 'created_at': '2023-10-27T18:45:19.307Z', 'update_at': '2023-10-27T23:53:05.438Z', 'instances': [{'avzone': 'us-east-2a', 'cluster': 'jumpyjackal'}], 'access': '', 'link': '', 'descriptionLink': '', 'depth': {'num_asks': 17, 'num_bids': 2, 'num_running': 2, 'asks': {'0x14b4C60931A0a0994E76d135EBc90939FfC7fDaC': 1, '0x1F56D369a573066890cBaD3443c9f222ef10e1D3': 1, '0x2EEE67EE6495C35b5d4e3FDBB56d8A4FBE99EF7a': 1, '0x35c0a2A5F744a0fb52dde9743B93F135895CCeC5': 1, '0x3e7b96F15cEC21A9405c5cF73A9bfE1c8dB5963d': 1, '0x5C351909412afD37f8A4e49DD7C1Ce6C26D58045': 1, '0x7594203Fb8614e6921a9197038Bb98A029fBaE07': 1, '0x96e984a8EA5eBD07e5ACF5E7761aC66c03A0457C': 1, '0x9778EB18C6694e1934e92bA67340c06B7BD35530': 1, '0x9f850AC6941891f0ce2893F67f97DBc0f3839cDB': 1, '0xA59b2541da93726954C2F250d438b17Dc15E2F7E': 1, '0xACe1778e4601b49e9C86b97Fd42c9C35E871aE44': 1, '0xD8d0A5999D87b21E7Dd619e58b5Db048e5e9dA58': 1, '0xF93afA632a4Ae317212d9be258D35c69af76CaCb': 1, '0xa4BfEAc05f1E055fA8E804dD1A3C104851e1c1B7': 1, '0xfE3dd65473d02C0B21eaa481386004dDaa382Da4': 1}, 'asks_updated': '2023-11-30T08:45:08.293482966Z', 'gpus': {'': 0}, 'qps': 7.6, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'stats': [{'avzone': 'us-east-2a', 'cluster': 'jumpyjackal', 'capacity': 0.6003227541689078, 'qps': 7.6}]}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '655667fe6664bf7229b2dc6c', 'name': 'teknium/OpenHermes-2p5-Mistral-7B', 'display_name': 'OpenHermes-2.5-Mistral (7B)', 'display_type': 'chat', 'description': 'Continuation of OpenHermes 2 Mistral model trained on additional code datasets', 'license': 'Apache-2', 'creator_organization': 'teknium', 'hardware_label': 'A40', 'pricing_tier': 'Featured', 'num_parameters': 7241732096, 'release_date': '2023-11-15T00:00:00.000Z', 'show_in_playground': True, 'isFeaturedModel': True, 'config': {'stop': ['<|im_end|>', '<|im_start|>'], 'prompt_format': '<|im_start|>user\\n{prompt}<|im_end|>\\n<|im_start|>assistant\\n', 'add_generation_prompt': True, 'chat_template_name': 'default'}, 'pricing': {'input': 50, 'output': 50}, 'created_at': '2023-11-16T19:05:34.976Z', 'update_at': '2023-11-16T19:12:24.883Z', 'instances': [{'avzone': 'us-east-2a', 'cluster': 'jumpyjackal'}], 'access': '', 'link': '', 'descriptionLink': '', 'depth': {'num_asks': 2, 'num_bids': 0, 'num_running': 0, 'asks': {'0xfBa03CcfDCA1822BfB65c647a985b9B7D8CE7415': 1}, 'asks_updated': '2023-11-30T09:01:43.546233805Z', 'gpus': {'': 0}, 'qps': 2.4, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'stats': [{'avzone': 'us-east-2a', 'cluster': 'jumpyjackal', 'capacity': 0.3048701298701299, 'qps': 2.4}]}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64e78eba589782acafe17820', 'name': 'togethercomputer/CodeLlama-13b-Instruct', 'display_name': 'Code Llama Instruct (13B)', 'display_type': 'chat', 'description': 'Code Llama is a family of large language models for code based on Llama 2 providing infilling capabilities, support for large input contexts, and zero-shot instruction following ability for programming tasks.', 'license': 'LLAMA 2 Community license Agreement (Meta)', 'creator_organization': 'Meta', 'hardware_label': 'A100 80GB', 'num_parameters': '13016028160', 'show_in_playground': True, 'finetuning_supported': True, 'isFeaturedModel': True, 'context_length': 8192, 'config': {'prompt_format': '[INST] {prompt} [/INST]', 'stop': ['</s>', '[INST]'], 'chat_template_name': 'llama'}, 'pricing': {'input': 56.25, 'output': 56.25, 'hourly': 0}, 'created_at': '2023-08-24T17:09:14.381Z', 'update_at': '2023-08-24T17:09:14.381Z', 'instances': [{'avzone': 'us-east-1a', 'cluster': 'happypiglet'}], 'access': '', 'link': '', 'descriptionLink': '', 'depth': {'num_asks': 3, 'num_bids': 1, 'num_running': 1, 'asks': {'0x9503fB851b50A1395D24F961dbEa14239D7FFb75': 1, '0xD7447A0a89a34EdA080357Bc9ffd71F339a6bAB3': 1}, 'asks_updated': '2023-11-30T08:21:24.536137135Z', 'gpus': {'': 0}, 'qps': 0.06666666666666667, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'stats': [{'avzone': 'us-east-1a', 'cluster': 'happypiglet', 'capacity': 0.19047619047619044, 'qps': 0.06666666666666667}]}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64e78eba589782acafe1781f', 'name': 'togethercomputer/CodeLlama-13b-Python', 'display_name': 'Code Llama Python (13B)', 'display_type': 'code', 'description': 'Code Llama is a family of large language models for code based on Llama 2 providing infilling capabilities, support for large input contexts, and zero-shot instruction following ability for programming tasks.', 'license': 'LLAMA 2 Community license Agreement (Meta)', 'creator_organization': 'Meta', 'hardware_label': 'A100 80GB', 'num_parameters': '13016028160', 'show_in_playground': True, 'finetuning_supported': True, 'isFeaturedModel': True, 'context_length': 8192, 'config': {'stop': ['</s>'], 'chat_template_name': 'llama'}, 'pricing': {'input': 56.25, 'output': 56.25, 'hourly': 0}, 'created_at': '2023-08-24T17:09:14.381Z', 'update_at': '2023-08-24T17:09:14.381Z', 'instances': [{'avzone': 'us-central-1a', 'cluster': 'sassyseal'}, {'avzone': 'us-east-1a', 'cluster': 'happypiglet'}], 'access': '', 'link': '', 'descriptionLink': '', 'depth': {'num_asks': 3, 'num_bids': 0, 'num_running': 0, 'asks': {'0x0fd44704EBaE5c6E7604bEd3b2FcA3A54e53a6C5': 1, '0x12aDF7E8EbA62640A9f48e8b148e95A84b90A44A': 1}, 'asks_updated': '2023-11-30T08:21:30.731854987Z', 'gpus': {'': 0}, 'qps': 0, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'stats': [{'avzone': 'us-central-1a', 'cluster': 'sassyseal', 'capacity': 0.14285714285714285, 'qps': 0}, {'avzone': 'us-east-1a', 'cluster': 'happypiglet', 'capacity': 0.21428571428571427, 'qps': 0}]}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64e78eba589782acafe1781e', 'name': 'togethercomputer/CodeLlama-13b', 'display_name': 'Code Llama (13B)', 'display_type': 'code', 'description': 'Code Llama is a family of large language models for code based on Llama 2 providing infilling capabilities, support for large input contexts, and zero-shot instruction following ability for programming tasks.', 'license': 'LLAMA 2 Community license Agreement (Meta)', 'creator_organization': 'Meta', 'hardware_label': 'A100 80GB', 'num_parameters': '13016028160', 'show_in_playground': True, 'finetuning_supported': True, 'isFeaturedModel': True, 'context_length': 8192, 'config': {'stop': ['</s>'], 'chat_template_name': 'llama'}, 'pricing': {'input': 56.25, 'output': 56.25, 'hourly': 0}, 'created_at': '2023-08-24T17:09:14.381Z', 'update_at': '2023-08-24T17:09:14.381Z', 'instances': [{'avzone': 'us-east-1a', 'cluster': 'happypiglet'}], 'access': '', 'link': '', 'descriptionLink': '', 'depth': {'num_asks': 2, 'num_bids': 0, 'num_running': 0, 'asks': {'0x8e1F3327B53B044D9c71A84b0506A77aE45511F6': 1}, 'asks_updated': '2023-11-30T08:16:54.348347884Z', 'gpus': {'': 0}, 'qps': 0, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'stats': [{'avzone': 'us-east-1a', 'cluster': 'happypiglet', 'capacity': 0.14285714285714285, 'qps': 0}]}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64e7934a589782acafe17823', 'name': 'togethercomputer/CodeLlama-34b-Instruct', 'display_name': 'Code Llama Instruct (34B)', 'display_type': 'chat', 'description': 'Code Llama is a family of large language models for code based on Llama 2 providing infilling capabilities, support for large input contexts, and zero-shot instruction following ability for programming tasks.', 'license': 'LLAMA 2 Community license Agreement (Meta)', 'creator_organization': 'Meta', 'hardware_label': 'A100 80GB', 'num_parameters': 34000000000, 'show_in_playground': True, 'isFeaturedModel': True, 'context_length': 8192, 'config': {'prompt_format': '[INST] {prompt} [/INST]', 'stop': ['</s>', '[INST]'], 'chat_template_name': 'llama'}, 'pricing': {'input': 200, 'output': 200, 'hourly': 0}, 'created_at': '2023-08-24T17:28:42.172Z', 'update_at': '2023-08-24T17:28:42.172Z', 'instances': [{'avzone': 'us-east-1a', 'cluster': 'happypiglet'}], 'access': '', 'link': '', 'descriptionLink': '', 'depth': {'num_asks': 4, 'num_bids': 1, 'num_running': 1, 'asks': {'0x40296D800102366b9Fe1085598BF6Ff66c9c5022': 1, '0x419C1B2BE24a9052ca50C97d6EB1E636F530b0C5': 1, '0xa4DcBF61a846056CF35fC50871CD5C5183aFA66B': 1}, 'asks_updated': '2023-11-30T08:41:35.145761326Z', 'gpus': {'': 0}, 'qps': 0.8666666666666667, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'stats': [{'avzone': 'us-east-1a', 'cluster': 'happypiglet', 'capacity': 0.17307692307692316, 'qps': 0.8666666666666667}]}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64e7934a589782acafe17822', 'name': 'togethercomputer/CodeLlama-34b-Python', 'display_name': 'Code Llama Python (34B)', 'display_type': 'code', 'description': 'Code Llama is a family of large language models for code based on Llama 2 providing infilling capabilities, support for large input contexts, and zero-shot instruction following ability for programming tasks.', 'license': 'LLAMA 2 Community license Agreement (Meta)', 'creator_organization': 'Meta', 'hardware_label': 'A100 80GB', 'num_parameters': 34000000000, 'show_in_playground': True, 'isFeaturedModel': True, 'context_length': 8192, 'config': {'stop': ['</s>'], 'chat_template_name': 'llama'}, 'pricing': {'input': 200, 'output': 200, 'hourly': 0}, 'created_at': '2023-08-24T17:28:42.172Z', 'update_at': '2023-08-24T17:28:42.172Z', 'instances': [{'avzone': 'us-east-1a', 'cluster': 'happypiglet'}], 'access': '', 'link': '', 'descriptionLink': '', 'depth': {'num_asks': 2, 'num_bids': 0, 'num_running': 0, 'asks': {'0xaD8115f5949C5729Ca840D12CCd000986EAE1d98': 1}, 'asks_updated': '2023-11-30T08:34:42.379146326Z', 'gpus': {'': 0}, 'qps': 1.5333333333333334, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'stats': [{'avzone': 'us-east-1a', 'cluster': 'happypiglet', 'capacity': 0.05372340425531905, 'qps': 1.5333333333333334}]}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64e7934a589782acafe17821', 'name': 'togethercomputer/CodeLlama-34b', 'display_name': 'Code Llama (34B)', 'display_type': 'code', 'description': 'Code Llama is a family of large language models for code based on Llama 2 providing infilling capabilities, support for large input contexts, and zero-shot instruction following ability for programming tasks.', 'license': 'LLAMA 2 Community license Agreement (Meta)', 'creator_organization': 'Meta', 'hardware_label': 'A100 80GB', 'num_parameters': 34000000000, 'show_in_playground': True, 'isFeaturedModel': True, 'context_length': 8192, 'config': {'stop': ['</s>'], 'chat_template_name': 'llama'}, 'pricing': {'input': 200, 'output': 200, 'hourly': 0}, 'created_at': '2023-08-24T17:28:42.172Z', 'update_at': '2023-08-24T17:28:42.172Z', 'instances': [{'avzone': 'us-east-1a', 'cluster': 'happypiglet'}], 'access': '', 'link': '', 'descriptionLink': '', 'depth': {'num_asks': 2, 'num_bids': 0, 'num_running': 0, 'asks': {'0xb9904738F08BdFA268cdD6C22029C924075c32f5': 1}, 'asks_updated': '2023-11-30T09:00:40.878302143Z', 'gpus': {'': 0}, 'qps': 0, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'stats': [{'avzone': 'us-east-1a', 'cluster': 'happypiglet', 'capacity': 0.06666666666666667, 'qps': 0}]}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64e78e89589782acafe1781d', 'name': 'togethercomputer/CodeLlama-7b-Instruct', 'display_name': 'Code Llama Instruct (7B)', 'display_type': 'chat', 'description': 'Code Llama is a family of large language models for code based on Llama 2 providing infilling capabilities, support for large input contexts, and zero-shot instruction following ability for programming tasks.', 'license': 'LLAMA 2 Community license Agreement (Meta)', 'creator_organization': 'Meta', 'hardware_label': 'A100 80GB', 'num_parameters': '6738546688', 'show_in_playground': True, 'finetuning_supported': True, 'isFeaturedModel': True, 'context_length': 8192, 'config': {'prompt_format': '[INST] {prompt} [/INST]', 'stop': ['</s>', '[INST]'], 'chat_template_name': 'llama'}, 'pricing': {'input': 50, 'output': 50, 'hourly': 0}, 'created_at': '2023-08-24T17:08:25.379Z', 'update_at': '2023-08-24T17:08:25.379Z', 'access': '', 'link': '', 'descriptionLink': '', 'depth': {'num_asks': 2, 'num_bids': 0, 'num_running': 0, 'asks': {'0x4394c63F1239626B62dCd57055B1cC6C8838A873': 1, '0x5216d6CA97cACeD33b1090433fEb1e83886406C2': 1}, 'asks_updated': '2023-11-30T08:57:31.40692972Z', 'gpus': {'': 0}, 'qps': 0.070727505, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'throughput_in': 23.757494, 'throughput_out': 11.982411}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64e78e89589782acafe1781c', 'name': 'togethercomputer/CodeLlama-7b-Python', 'display_name': 'Code Llama Python (7B)', 'display_type': 'code', 'description': 'Code Llama is a family of large language models for code based on Llama 2 providing infilling capabilities, support for large input contexts, and zero-shot instruction following ability for programming tasks.', 'license': 'LLAMA 2 Community license Agreement (Meta)', 'creator_organization': 'Meta', 'hardware_label': 'A100 80GB', 'num_parameters': '6738546688', 'show_in_playground': True, 'finetuning_supported': True, 'isFeaturedModel': True, 'context_length': 8192, 'config': {'stop': ['</s>'], 'chat_template_name': 'llama'}, 'pricing': {'input': 50, 'output': 50, 'hourly': 0}, 'created_at': '2023-08-24T17:08:25.379Z', 'update_at': '2023-08-24T17:08:25.379Z', 'access': '', 'link': '', 'descriptionLink': '', 'depth': {'num_asks': 2, 'num_bids': 0, 'num_running': 0, 'asks': {'0x3e1FDd24eAdC6dA6F24b672E995bB58B2Ba9ACc7': 1, '0x8ff44C68db56E66E200C6a7a51740d09D18Cd93b': 1}, 'asks_updated': '2023-11-30T08:39:43.204042706Z', 'gpus': {'': 0}, 'qps': 0.039676283, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'throughput_in': 0.89590085, 'throughput_out': 5.0833836}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64e78e89589782acafe1781b', 'name': 'togethercomputer/CodeLlama-7b', 'display_name': 'Code Llama (7B)', 'display_type': 'code', 'description': 'Code Llama is a family of large language models for code based on Llama 2 providing infilling capabilities, support for large input contexts, and zero-shot instruction following ability for programming tasks.', 'license': 'LLAMA 2 Community license Agreement (Meta)', 'creator_organization': 'Meta', 'hardware_label': 'A100 80GB', 'num_parameters': '6738546688', 'show_in_playground': True, 'finetuning_supported': True, 'isFeaturedModel': True, 'context_length': 8192, 'config': {'stop': ['</s>'], 'chat_template_name': 'llama'}, 'pricing': {'input': 50, 'output': 50, 'hourly': 0}, 'created_at': '2023-08-24T17:08:25.379Z', 'update_at': '2023-08-24T17:08:25.379Z', 'access': '', 'link': '', 'descriptionLink': '', 'depth': {'num_asks': 9, 'num_bids': 7, 'num_running': 7, 'asks': {'0x06F3a0760639A6514e65080b526108DD5FdA491E': 1, '0x2529004E1F328c64aefE70d0a78BC636f9a10C67': 8}, 'asks_updated': '2023-11-30T08:23:06.29734546Z', 'gpus': {'': 0}, 'qps': 0.04925829, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'throughput_in': 61.005207, 'throughput_out': 21.818993}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '6495ff1312907e072b8aece2', 'name': 'togethercomputer/GPT-JT-6B-v1', 'display_name': 'GPT-JT (6B)', 'display_type': 'language', 'description': 'Fork of GPT-J instruction tuned to excel at few-shot prompts (blog post).', 'descriptionLink': 'https://www.together.xyz/blog/releasing-v1-of-gpt-jt-powered-by-open-source-ai', 'license': 'apache-2.0', 'link': 'https://huggingface.co/togethercomputer/GPT-JT-6B-v1', 'creator_organization': 'Together', 'hardware_label': 'A40 48GB', 'pricing_tier': 'featured', 'access': 'open', 'num_parameters': 6700000000, 'release_date': '2022-11-29T00:00:00.000Z', 'show_in_playground': True, 'isFeaturedModel': True, 'context_length': 2048, 'config': {'chat_template_name': 'gpt'}, 'pricing': {'input': 50, 'output': 50, 'hourly': 0}, 'created_at': '2023-06-23T20:22:43.617Z', 'update_at': '2023-06-23T20:22:43.617Z', 'depth': {'num_asks': 2, 'num_bids': 0, 'num_running': 0, 'asks': {'0x347ed480e16d8df64575Af1b19A9bb84fA787149': 1, '0x825c2eEAf8e191c9c65D333F6e97C91b3459F06C': 1}, 'asks_updated': '2023-11-30T08:02:00.123059399Z', 'gpus': {'': 0}, 'qps': 0.021982463, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'throughput_in': 0.39000276, 'throughput_out': 2.473073}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '6495ff1312907e072b8aece3', 'name': 'togethercomputer/GPT-JT-Moderation-6B', 'display_name': 'GPT-JT-Moderation (6B)', 'display_type': 'language', 'description': \"This model can be used to moderate other chatbot models. Built using GPT-JT model fine-tuned on Ontocord.ai's OIG-moderation dataset v0.1.\", 'license': 'apache-2.0', 'link': 'https://huggingface.co/togethercomputer/GPT-JT-Moderation-6B', 'creator_organization': 'Together', 'hardware_label': 'A40 48GB', 'pricing_tier': 'featured', 'access': 'open', 'num_parameters': 6700000000, 'show_in_playground': True, 'isFeaturedModel': True, 'context_length': 2048, 'config': {'chat_template_name': 'gpt'}, 'pricing': {'input': 50, 'output': 50, 'hourly': 0}, 'created_at': '2023-06-23T20:22:43.657Z', 'update_at': '2023-06-23T20:22:43.657Z', 'descriptionLink': '', 'depth': {'num_asks': 2, 'num_bids': 0, 'num_running': 0, 'asks': {'0x6ab061898c6c0b6E7595BFa12c7d3F410a79D480': 1, '0xfDb481fb1949C07e4096111E92C426821516AC67': 1}, 'asks_updated': '2023-11-30T08:53:15.208786546Z', 'gpus': {'NVIDIA A100 80GB PCIe': 2}, 'qps': 0.030003404, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'throughput_in': 0.61706156, 'throughput_out': 3.7189405}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '6495ff1312907e072b8aece4', 'name': 'togethercomputer/GPT-NeoXT-Chat-Base-20B', 'display_name': 'GPT-NeoXT-Chat-Base (20B)', 'display_type': 'chat', 'description': 'Chat model fine-tuned from EleutherAIs GPT-NeoX with over 40 million instructions on carbon reduced compute.', 'license': 'apache-2.0', 'link': 'https://huggingface.co/togethercomputer/GPT-NeoXT-Chat-Base-20B', 'creator_organization': 'Together', 'hardware_label': 'A40 48GB', 'pricing_tier': 'featured', 'access': 'open', 'num_parameters': 20000000000, 'show_in_playground': True, 'isFeaturedModel': True, 'context_length': 2048, 'config': {'prompt_format': '<human>: {prompt}\\n<bot>:', 'stop': ['<human>'], 'chat_template_name': 'gpt'}, 'max_tokens': 995, 'pricing': {'input': 75, 'output': 75, 'hourly': 0}, 'created_at': '2023-06-23T20:22:43.702Z', 'update_at': '2023-06-23T20:22:43.702Z', 'descriptionLink': '', 'depth': {'num_asks': 2, 'num_bids': 0, 'num_running': 0, 'asks': {'0x0648b3363589FE937639A018781Ea6A1367AeDA3': 1, '0xF336AF86FBFf5dc323F0964f2DF9C8fE9ce804DB': 1}, 'asks_updated': '2023-11-30T08:42:37.440664174Z', 'gpus': {'': 0}, 'qps': 0.022899456, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'throughput_in': 0.4515941, 'throughput_out': 1.3601706}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64c28e8742fa06a9511509d1', 'name': 'togethercomputer/LLaMA-2-7B-32K', 'display_name': 'LLaMA-2-32K (7B)', 'display_type': 'language', 'description': \"Extending LLaMA-2 to 32K context, built with Meta's Position Interpolation and Together AI's data recipe and system optimizations.\", 'license': 'Meta license', 'link': 'https://huggingface.co/togethercomputer/LLaMA-2-7B-32K', 'creator_organization': 'Together', 'hardware_label': '2x A100 80GB', 'pricing_tier': 'supported', 'access': 'open', 'num_parameters': '6738415616', 'show_in_playground': True, 'finetuning_supported': True, 'isFeaturedModel': True, 'context_length': 32768, 'config': {'stop': ['\\n\\n\\n\\n', '<|endoftext|>'], 'chat_template_name': 'llama'}, 'pricing': {'input': 50, 'output': 50, 'hourly': 0}, 'created_at': '2023-07-27T15:34:31.581Z', 'update_at': '2023-08-17T17:07:36.346Z', 'descriptionLink': '', 'depth': {'num_asks': 2, 'num_bids': 0, 'num_running': 0, 'asks': {'0x5e4d8140190F6b1A6098e20Faf53CE2912f86e24': 1, '0x9DA91a58b69ECa0080221784A1B037648d03c73F': 1}, 'asks_updated': '2023-11-30T09:00:26.518608294Z', 'gpus': {'': 0}, 'qps': 0.03783752, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'throughput_in': 0.8582364, 'throughput_out': 1.7934135}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64de96090d052d10425df3c9', 'name': 'togethercomputer/Llama-2-7B-32K-Instruct', 'display_name': 'LLaMA-2-7B-32K-Instruct (7B)', 'display_type': 'chat', 'description': \"Extending LLaMA-2 to 32K context, built with Meta's Position Interpolation and Together AI's data recipe and system optimizations, instruction tuned by Together\", 'license': 'Meta license', 'creator_organization': 'Together', 'hardware_label': '2X A100 80GB', 'pricing_tier': 'supported', 'num_parameters': 7000000000, 'show_in_playground': True, 'finetuning_supported': True, 'isFeaturedModel': True, 'context_length': 32768, 'config': {'prompt_format': '[INST]\\n {prompt} \\n[/INST]\\n\\n', 'stop': ['[INST]', '\\n\\n'], 'chat_template_name': 'llama'}, 'pricing': {'input': 50, 'output': 50, 'hourly': 0}, 'access': '', 'link': '', 'descriptionLink': '', 'depth': {'num_asks': 7, 'num_bids': 4, 'num_running': 4, 'asks': {'0x3D6eD2De2148B00b96C37C646E4Aaa5a51de6768': 3, '0x3c82375Cbb63c659Ae960Aaa7b92434b34C3F455': 3, '0x6a3aB552e8841502c2f1Db37287503Cb9d6ADf05': 1}, 'asks_updated': '2023-11-30T08:14:54.890523432Z', 'gpus': {'': 0}, 'qps': 0.032026317, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'throughput_in': 0.7054863, 'throughput_out': 1.8144706}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '6495ff1412907e072b8aecee', 'name': 'togethercomputer/Pythia-Chat-Base-7B-v0.16', 'display_name': 'Pythia-Chat-Base (7B)', 'display_type': 'chat', 'description': 'Chat model based on EleutherAIs Pythia-7B model, and is fine-tuned with data focusing on dialog-style interactions.', 'license': 'apache-2.0', 'creator_organization': 'Together', 'hardware_label': 'A40 48GB', 'pricing_tier': 'featured', 'access': 'open', 'num_parameters': 7000000000, 'show_in_playground': True, 'finetuning_supported': True, 'isFeaturedModel': True, 'context_length': 2048, 'config': {'prompt_format': '<human>: {prompt}\\n<bot>:', 'stop': ['<human>'], 'chat_template_name': 'gpt'}, 'pricing': {'input': 50, 'output': 50, 'hourly': 0}, 'created_at': '2023-06-23T20:22:44.251Z', 'update_at': '2023-06-23T20:22:44.251Z', 'link': '', 'descriptionLink': '', 'depth': {'num_asks': 1, 'num_bids': 0, 'num_running': 0, 'asks': {'0x42899d444e0669B867ECa64983143469F097D9c5': 1}, 'asks_updated': '2023-11-30T08:28:30.832257746Z', 'gpus': {'': 0}, 'qps': 0.030301858, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'throughput_in': 0.6668213, 'throughput_out': 4.7835846}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64efd5511b76196fc5a54872', 'name': 'togethercomputer/Qwen-7B-Chat', 'display_name': 'Qwen-Chat (7B)', 'display_type': 'chat', 'description': '7B-parameter version of the large language model series, Qwen (abbr. Tongyi Qianwen), proposed by Aibaba Cloud. Qwen-7B-Chat is a large-model-based AI assistant, which is trained with alignment techniques.\\xa0 \\xa0', 'license': 'Tongyi Qianwen LICENSE AGREEMENT', 'creator_organization': 'Qwen', 'hardware_label': '1x A100 80GB', 'num_parameters': 7000000000, 'release_date': '2023-08-01T00:00:00.000Z', 'show_in_playground': True, 'isFeaturedModel': True, 'context_length': 8192, 'config': {'stop': ['<|im_end|>', '<|im_start|>'], 'prompt_format': '\\n<|im_start|>user\\n{prompt}<|im_end|>\\n<|im_start|>assistant\\n', 'add_generation_prompt': True, 'chat_template_name': 'default'}, 'pricing': {'input': 50, 'output': 50, 'hourly': 0}, 'created_at': '2023-08-30T23:48:33.852Z', 'update_at': '2023-09-07T01:49:42.840Z', 'access': '', 'link': '', 'descriptionLink': '', 'depth': {'num_asks': 6, 'num_bids': 5, 'num_running': 5, 'asks': {'0x3A30F87675923F5dE4d7468Ef492015CC6a862c7': 6}, 'asks_updated': '2023-11-30T07:42:08.741761087Z', 'gpus': {'': 0}, 'qps': 0.030975824, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'throughput_in': 0.66682243, 'throughput_out': 5.7531824}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64efcc2a1b76196fc5a54870', 'name': 'togethercomputer/Qwen-7B', 'display_name': 'Qwen (7B)', 'display_type': 'language', 'description': '7B-parameter version of the large language model series, Qwen (abbr. Tongyi Qianwen), proposed by Aibaba Cloud. Qwen-7B is a Transformer-based large language model, which is pretrained on a large volume of data, including web texts, books, codes, etc.\\xa0', 'license': 'Tongyi Qianwen LICENSE AGREEMENT', 'creator_organization': 'Qwen', 'hardware_label': '1x A100 80GB', 'num_parameters': 7000000000, 'release_date': '2023-08-01T00:00:00.000Z', 'show_in_playground': True, 'isFeaturedModel': True, 'context_length': 8192, 'config': {'stop': ['<|im_end|>', '<|endoftext|>'], 'add_generation_prompt': True, 'chat_template_name': 'default'}, 'pricing': {'input': 50, 'output': 50, 'hourly': 0}, 'created_at': '2023-08-30T23:09:30.570Z', 'update_at': '2023-09-07T01:49:24.716Z', 'access': '', 'link': '', 'descriptionLink': '', 'depth': {'num_asks': 8, 'num_bids': 7, 'num_running': 7, 'asks': {'0x3b8A3B15fBa1c9528653acBA88C329baE2a5a43D': 8}, 'asks_updated': '2023-11-30T07:57:07.814564396Z', 'gpus': {'': 0}, 'qps': 0.023537071, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'throughput_in': 0.44352335, 'throughput_out': 5.972012}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '6495ff1412907e072b8aeceb', 'name': 'togethercomputer/RedPajama-INCITE-7B-Base', 'display_name': 'RedPajama-INCITE (7B)', 'display_type': 'language', 'description': 'Base model that aims to replicate the LLaMA recipe as closely as possible (blog post).', 'descriptionLink': 'https://www.together.xyz/blog/redpajama-models-v1', 'license': 'apache-2.0', 'link': 'https://huggingface.co/togethercomputer/RedPajama-INCITE-7B-Base', 'creator_organization': 'Together', 'hardware_label': 'A40 48GB', 'pricing_tier': 'featured', 'access': 'open', 'num_parameters': '6857302016', 'show_in_playground': True, 'finetuning_supported': True, 'isFeaturedModel': True, 'context_length': 2048, 'config': {'chat_template_name': 'gpt'}, 'pricing': {'input': 50, 'output': 50, 'hourly': 0}, 'created_at': '2023-06-23T20:22:44.033Z', 'update_at': '2023-06-23T20:22:44.033Z', 'depth': {'num_asks': 2, 'num_bids': 0, 'num_running': 0, 'asks': {'0x7c7007A3ffF953bA357CF3eeF853DD8613B07209': 1, '0xa5c71572Cfa868Ef8616Bb33FccB05B49dA88d8B': 1}, 'asks_updated': '2023-11-30T08:21:18.177107071Z', 'gpus': {'': 0}, 'qps': 0.02515027, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'throughput_in': 0.49030614, 'throughput_out': 1.9426649}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '6495ff1412907e072b8aeced', 'name': 'togethercomputer/RedPajama-INCITE-7B-Chat', 'display_name': 'RedPajama-INCITE Chat (7B)', 'display_type': 'chat', 'description': 'Chat model fine-tuned using data from Dolly 2.0 and Open Assistant over the RedPajama-INCITE-Base-7B-v1 base model.', 'license': 'apache-2.0', 'link': 'https://huggingface.co/togethercomputer/RedPajama-INCITE-7B-Chat', 'creator_organization': 'Together', 'hardware_label': 'A100 80GB', 'pricing_tier': 'featured', 'access': 'open', 'num_parameters': '6857302016', 'show_in_playground': True, 'finetuning_supported': True, 'isFeaturedModel': True, 'context_length': 2048, 'config': {'prompt_format': '<human>: {prompt}\\n<bot>:', 'stop': ['<human>'], 'chat_template_name': 'gpt'}, 'pricing': {'input': 50, 'output': 50, 'hourly': 0}, 'created_at': '2023-06-23T20:22:44.190Z', 'update_at': '2023-06-23T20:22:44.190Z', 'descriptionLink': '', 'depth': {'num_asks': 2, 'num_bids': 0, 'num_running': 0, 'asks': {'0xcC9323401A6f39efd3C5fc8bFAc74D7b512abd69': 1, '0xd21D8158D6065D9D38d68DEAcd5946F228499b16': 1}, 'asks_updated': '2023-11-30T08:51:14.252552392Z', 'gpus': {'': 0}, 'qps': 0.02897506, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'throughput_in': 0.63285714, 'throughput_out': 1.0530012}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '6495ff1412907e072b8aecec', 'name': 'togethercomputer/RedPajama-INCITE-7B-Instruct', 'display_name': 'RedPajama-INCITE Instruct (7B)', 'display_type': 'language', 'description': 'Designed for few-shot prompts, fine-tuned over the RedPajama-INCITE-Base-7B-v1 base model.', 'license': 'apache-2.0', 'link': 'https://huggingface.co/togethercomputer/RedPajama-INCITE-7B-Instruct', 'creator_organization': 'Together', 'hardware_label': 'A100 80GB', 'pricing_tier': 'featured', 'access': 'open', 'num_parameters': '6857302016', 'show_in_playground': True, 'finetuning_supported': True, 'isFeaturedModel': True, 'context_length': 2048, 'config': {'chat_template_name': 'gpt'}, 'pricing': {'input': 50, 'output': 50, 'hourly': 0}, 'created_at': '2023-06-23T20:22:44.083Z', 'update_at': '2023-06-23T20:22:44.083Z', 'descriptionLink': '', 'depth': {'num_asks': 2, 'num_bids': 0, 'num_running': 0, 'asks': {'0x30D9d6EaFcA72F8913A8661450722E512bD06a9F': 1, '0xF68F3AfE6f0e6a29A16CB73cFB3BEb86E88Df043': 1}, 'asks_updated': '2023-11-30T08:31:19.985062693Z', 'gpus': {'': 0}, 'qps': 0.02665426, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'throughput_in': 0.5339221, 'throughput_out': 1.5884362}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '6495ff1312907e072b8aece5', 'name': 'togethercomputer/RedPajama-INCITE-Base-3B-v1', 'display_name': 'RedPajama-INCITE (3B)', 'display_type': 'language', 'description': 'Base model that aims to replicate the LLaMA recipe as closely as possible (blog post).', 'descriptionLink': 'https://www.together.xyz/blog/redpajama-models-v1', 'license': 'apache-2.0', 'link': 'https://huggingface.co/togethercomputer/RedPajama-INCITE-Base-3B-v1', 'creator_organization': 'Together', 'hardware_label': 'A40 48GB', 'pricing_tier': 'featured', 'access': 'open', 'num_parameters': '2775864320', 'show_in_playground': True, 'finetuning_supported': True, 'isFeaturedModel': True, 'context_length': 2048, 'config': {'chat_template_name': 'gpt'}, 'pricing': {'input': 25, 'output': 25, 'hourly': 0}, 'created_at': '2023-06-23T20:22:43.751Z', 'update_at': '2023-06-23T20:22:43.751Z', 'depth': {'num_asks': 2, 'num_bids': 0, 'num_running': 0, 'asks': {'0x0aBe21E3ca185164261ef34A239C247300ac8443': 1, '0x930312eb45cEDC07Ca1cFFf399e46693e1f6b0B9': 1}, 'asks_updated': '2023-11-30T08:35:56.179503561Z', 'gpus': {'': 0}, 'qps': 0.026605694, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'throughput_in': 0.5325134, 'throughput_out': 0.8833926}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '6495ff1312907e072b8aece7', 'name': 'togethercomputer/RedPajama-INCITE-Chat-3B-v1', 'display_name': 'RedPajama-INCITE Chat (3B)', 'display_type': 'chat', 'description': 'Chat model fine-tuned using data from Dolly 2.0 and Open Assistant over the RedPajama-INCITE-Base-3B-v1 base model.', 'license': 'apache-2.0', 'link': 'https://huggingface.co/togethercomputer/RedPajama-INCITE-Chat-3B-v1', 'creator_organization': 'Together', 'hardware_label': 'A40 48GB', 'pricing_tier': 'featured', 'access': 'open', 'num_parameters': '2775864320', 'show_in_playground': True, 'finetuning_supported': True, 'isFeaturedModel': True, 'context_length': 2048, 'config': {'prompt_format': '<human>: {prompt}\\n<bot>:', 'stop': ['<human>'], 'chat_template_name': 'gpt'}, 'pricing': {'input': 25, 'output': 25, 'hourly': 0}, 'created_at': '2023-06-23T20:22:43.839Z', 'update_at': '2023-06-23T20:22:43.839Z', 'descriptionLink': '', 'depth': {'num_asks': 2, 'num_bids': 0, 'num_running': 0, 'asks': {'0x314e601Ca3c385ade582C39Ea568fc5F93024899': 1, '0xE5CdaceFC11371aF54F4CEa9B825E299605fC0DB': 1}, 'asks_updated': '2023-11-30T08:28:25.853987545Z', 'gpus': {'': 0}, 'qps': 0.022276906, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'throughput_in': 0.43409777, 'throughput_out': 1.0446243}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '6495ff1312907e072b8aece6', 'name': 'togethercomputer/RedPajama-INCITE-Instruct-3B-v1', 'display_name': 'RedPajama-INCITE Instruct (3B)', 'display_type': 'language', 'description': 'Designed for few-shot prompts, fine-tuned over the RedPajama-INCITE-Base-3B-v1 base model.', 'license': 'apache-2.0', 'link': 'https://huggingface.co/togethercomputer/RedPajama-INCITE-Instruct-3B-v1', 'creator_organization': 'Together', 'hardware_label': 'A40 48GB', 'pricing_tier': 'featured', 'access': 'open', 'num_parameters': '2775864320', 'show_in_playground': True, 'finetuning_supported': True, 'isFeaturedModel': True, 'context_length': 2048, 'config': {'chat_template_name': 'gpt'}, 'pricing': {'input': 25, 'output': 25, 'hourly': 0}, 'created_at': '2023-06-23T20:22:43.796Z', 'update_at': '2023-06-23T20:22:43.796Z', 'descriptionLink': '', 'depth': {'num_asks': 5, 'num_bids': 3, 'num_running': 3, 'asks': {'0x9212cc97439F70f4a4611c5D93F37087d5DF111b': 4, '0xc627592f6023D78F544e7D643e5aF32c055EEA9D': 1}, 'asks_updated': '2023-11-30T08:38:03.095138629Z', 'gpus': {'': 0}, 'qps': 0.03067099, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'throughput_in': 0.65040696, 'throughput_out': 1.5413531}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64ace317227f790586239ce2', 'name': 'togethercomputer/alpaca-7b', 'display_name': 'Alpaca (7B)', 'display_type': 'chat', 'description': 'Fine-tuned from the LLaMA 7B model on 52K instruction-following demonstrations. ', 'license': 'cc-by-nc-4.0', 'link': 'https://huggingface.co/tatsu-lab/alpaca-7b-wdiff', 'creator_organization': 'Stanford', 'hardware_label': 'A40 48GB', 'pricing_tier': 'supported', 'access': 'open', 'num_parameters': 7000000000, 'show_in_playground': True, 'isFeaturedModel': True, 'context_length': 2048, 'config': {'stop': ['</s>', '###'], 'prompt_format': '### Instruction:\\n{prompt}\\n### Response:\\n', 'chat_template': \"{% for message in messages %}{% if message['role'] == 'user' %}{{ '### Instruction:\\n' + message['content'] + '\\n' }}{% else %}{{ '### Response:\\n' + message['content'] + '\\n' }}{% endif %}{% endfor %}{{ '### Response:\\n' }}\"}, 'pricing': {'input': 50, 'output': 50, 'hourly': 0}, 'created_at': '2023-07-11T05:05:27.713Z', 'update_at': '2023-07-11T05:05:27.713Z', 'descriptionLink': '', 'depth': {'num_asks': 1, 'num_bids': 0, 'num_running': 0, 'asks': {'0x4174A3c81710BCd6C43b1F8e8f8a91B1137Baf55': 1}, 'asks_updated': '2023-11-30T08:47:47.258164154Z', 'gpus': {'': 0}, 'qps': 0.021750662, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'throughput_in': 0.40734977, 'throughput_out': 1.1825417}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64ace614227f790586239cf7', 'name': 'togethercomputer/falcon-40b-instruct', 'display_name': 'Falcon Instruct (40B)', 'display_type': 'chat', 'description': 'Falcon-40B-Instruct is a causal decoder-only model built by TII based on Falcon-40B and finetuned on a mixture of Baize. ', 'license': 'apache-2.0', 'link': 'https://huggingface.co/tiiuae/falcon-40b-instruct', 'creator_organization': 'TII UAE', 'hardware_label': '2X A40 48GB', 'pricing_tier': 'supported', 'access': 'open', 'num_parameters': 40000000000, 'show_in_playground': True, 'isFeaturedModel': True, 'context_length': 2048, 'config': {'prompt_format': 'User: {prompt}\\nAssistant:', 'stop': ['User:', '</s>'], 'chat_template_name': 'default'}, 'pricing': {'input': 200, 'output': 200, 'hourly': 0}, 'created_at': '2023-07-11T05:18:12.323Z', 'update_at': '2023-07-11T05:18:12.323Z', 'descriptionLink': '', 'depth': {'num_asks': 1, 'num_bids': 0, 'num_running': 0, 'asks': {'0x0b5481F80C5DEe44b73CC49BA6091F6245545716': 1}, 'asks_updated': '2023-11-30T08:16:12.005913968Z', 'gpus': {'': 0}, 'qps': 0.022961343, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'throughput_in': 0.44597414, 'throughput_out': 1.2328038}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64ace59f227f790586239cf5', 'name': 'togethercomputer/falcon-40b', 'display_name': 'Falcon (40B)', 'display_type': 'language', 'description': 'Falcon-40B is a causal decoder-only model built by TII and trained on 1,000B tokens of RefinedWeb enhanced with curated corpora.', 'license': 'apache-2.0', 'link': 'https://huggingface.co/tiiuae/falcon-40b', 'creator_organization': 'TII UAE', 'hardware_label': '2X A40 48GB', 'pricing_tier': 'supported', 'access': 'open', 'num_parameters': 40000000000, 'show_in_playground': True, 'isFeaturedModel': True, 'context_length': 2048, 'config': {'stop': ['<|endoftext|>'], 'chat_template_name': 'default'}, 'pricing': {'input': 200, 'output': 200, 'hourly': 0}, 'created_at': '2023-07-11T05:16:15.898Z', 'update_at': '2023-07-11T05:16:15.898Z', 'descriptionLink': '', 'depth': {'num_asks': 3, 'num_bids': 2, 'num_running': 2, 'asks': {'0x42C59dDFA7fEF158a7d11a675317669893CE0EbC': 3}, 'asks_updated': '2023-11-30T07:27:40.19098176Z', 'gpus': {'': 0}, 'qps': 0.06739513, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'throughput_in': 19.852734, 'throughput_out': 108.726364}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64ace63d227f790586239cf8', 'name': 'togethercomputer/falcon-7b-instruct', 'display_name': 'Falcon Instruct (7B)', 'display_type': 'chat', 'description': 'Casual decoder-only model built by TII based on Falcon-7B and finetuned on a mixture of chat/instruct datasets. ', 'license': 'apache-2.0', 'link': 'https://huggingface.co/tiiuae/falcon-7b-instruct', 'creator_organization': 'TII UAE', 'hardware_label': 'A40 48GB', 'pricing_tier': 'featured', 'access': 'open', 'num_parameters': 7000000000, 'show_in_playground': True, 'isFeaturedModel': True, 'context_length': 2048, 'config': {'prompt_format': 'User: {prompt}\\nAssistant:', 'stop': ['User:', '</s>'], 'chat_template_name': 'default'}, 'pricing': {'input': 50, 'output': 50, 'hourly': 0}, 'created_at': '2023-07-11T05:18:53.623Z', 'update_at': '2023-07-11T05:18:53.623Z', 'descriptionLink': '', 'depth': {'num_asks': 1, 'num_bids': 0, 'num_running': 0, 'asks': {'0x2b665036860161c962147A49c5Baf87CFbFC6c4b': 1}, 'asks_updated': '2023-11-30T08:06:01.111608764Z', 'gpus': {'': 0}, 'qps': 0.03334472, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'throughput_in': 0.74709207, 'throughput_out': 1.4275361}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64ace5dd227f790586239cf6', 'name': 'togethercomputer/falcon-7b', 'display_name': 'Falcon (7B)', 'display_type': 'language', 'description': 'Causal decoder-only model built by TII and trained on 1,500B tokens of RefinedWeb enhanced with curated corpora.', 'license': 'apache-2.0', 'link': 'https://huggingface.co/tiiuae/falcon-7b', 'creator_organization': 'TII UAE', 'hardware_label': 'A40 48GB', 'pricing_tier': 'featured', 'access': 'open', 'num_parameters': 7000000000, 'show_in_playground': True, 'isFeaturedModel': True, 'context_length': 2048, 'config': {'stop': ['<|endoftext|>'], 'chat_template_name': 'default'}, 'pricing': {'input': 50, 'output': 50, 'hourly': 0}, 'created_at': '2023-07-11T05:17:17.883Z', 'update_at': '2023-07-11T05:17:17.883Z', 'descriptionLink': '', 'depth': {'num_asks': 1, 'num_bids': 0, 'num_running': 0, 'asks': {'0xeA9aAE19f2f4423f83eBF38571Cc6F4BC990174d': 1}, 'asks_updated': '2023-11-30T07:19:00.440972889Z', 'gpus': {'': 0}, 'qps': 0.025402151, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'throughput_in': 0.49562693, 'throughput_out': 1.1339589}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64b7165fcccc52103e2f07e8', 'name': 'togethercomputer/llama-2-13b-chat', 'display_name': 'LLaMA-2 Chat (13B)', 'display_type': 'chat', 'description': 'Llama 2-chat leverages publicly available instruction datasets and over 1 million human annotations. Available in three sizes: 7B, 13B and 70B parameters', 'license': 'LLaMA license Agreement (Meta)', 'link': 'https://huggingface.co/togethercomputer/llama-2-13b-chat', 'creator_organization': 'Meta', 'hardware_label': '2X A100 80GB', 'pricing_tier': 'Featured', 'access': 'open', 'num_parameters': '13015864320', 'show_in_playground': True, 'finetuning_supported': True, 'isFeaturedModel': True, 'context_length': 4096, 'config': {'prompt_format': '[INST] {prompt} [/INST]', 'stop': ['[/INST]', '</s>'], 'chat_template_name': 'llama'}, 'pricing': {'input': 56.25, 'output': 56.25, 'hourly': 0}, 'created_at': '2023-07-18T22:46:55.042Z', 'update_at': '2023-07-18T22:46:55.042Z', 'instances': [{'avzone': 'us-east-1a', 'cluster': 'happypiglet'}], 'descriptionLink': '', 'depth': {'num_asks': 5, 'num_bids': 0, 'num_running': 0, 'asks': {'0x5Da09CD1EdF3e771B8F781AA61c24d58Ad818C25': 1, '0xB55115d37767D2e3CDe83c29EF363ca0e36912bB': 1, '0xB5Cc7Af02C5aE6eAEF91b98EedFF46e654628720': 1, '0xE4fec5B651a66255Cace2F5Dee048AEC80b32dfe': 1}, 'asks_updated': '2023-11-30T08:37:53.358301448Z', 'gpus': {'': 0}, 'qps': 1.2666666666666666, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'stats': [{'avzone': 'us-east-1a', 'cluster': 'happypiglet', 'capacity': 0.031428571428571445, 'qps': 1.2666666666666666}]}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64b7165fcccc52103e2f07e7', 'name': 'togethercomputer/llama-2-13b', 'display_name': 'LLaMA-2 (13B)', 'display_type': 'language', 'description': 'Language model trained on 2 trillion tokens with double the context length of Llama 1. Available in three sizes: 7B, 13B and 70B parameters', 'license': 'LLaMA license Agreement (Meta)', 'link': 'https://huggingface.co/togethercomputer/llama-2-13b', 'creator_organization': 'Meta', 'hardware_label': '2X A100 80GB', 'pricing_tier': 'Featured', 'access': 'open', 'num_parameters': '13015864320', 'show_in_playground': True, 'finetuning_supported': True, 'isFeaturedModel': True, 'context_length': 4096, 'config': {'chat_template_name': 'llama'}, 'pricing': {'input': 56.25, 'output': 56.25, 'hourly': 0}, 'created_at': '2023-07-18T22:46:55.042Z', 'update_at': '2023-07-18T22:46:55.042Z', 'instances': [{'avzone': 'us-east-1a', 'cluster': 'happypiglet'}, {'avzone': 'us-east-2a', 'cluster': 'jumpyjackal'}], 'descriptionLink': '', 'depth': {'num_asks': 5, 'num_bids': 0, 'num_running': 0, 'asks': {'0x5088dC715714fe3ACeC2C5b93bcd9B5b60B41D1C': 1, '0x60a094F7CBf1db8e0BA62c50c5A2ee25A273B145': 1, '0xE3D4371DFf66bDAC60a35fFfcd8cEd65D145D7a4': 1, '0xFEC24537885b347650f48C6809a9C1fA4Ed880E5': 1}, 'asks_updated': '2023-11-30T07:57:38.022432442Z', 'gpus': {'': 0}, 'qps': 0, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'stats': [{'avzone': 'us-east-1a', 'cluster': 'happypiglet', 'capacity': 0.045454545454545456, 'qps': 0}, {'avzone': 'us-east-2a', 'cluster': 'jumpyjackal', 'capacity': 0.045454545454545456, 'qps': 0}]}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64b7165fcccc52103e2f07ea', 'name': 'togethercomputer/llama-2-70b-chat', 'display_name': 'LLaMA-2 Chat (70B)', 'display_type': 'chat', 'description': 'Llama 2-chat leverages publicly available instruction datasets and over 1 million human annotations. Available in three sizes: 7B, 13B and 70B parameters', 'license': 'LLaMA license Agreement (Meta)', 'link': 'https://huggingface.co/togethercomputer/llama-2-70b-chat', 'creator_organization': 'Meta', 'hardware_label': '2X A100 80GB', 'pricing_tier': 'Featured', 'access': 'open', 'num_parameters': '68976648192', 'show_in_playground': True, 'finetuning_supported': True, 'isFeaturedModel': True, 'context_length': 4096, 'config': {'prompt_format': '[INST] {prompt} [/INST]', 'stop': ['[/INST]', '</s>'], 'chat_template_name': 'llama'}, 'pricing': {'input': 225, 'output': 225, 'hourly': 0}, 'created_at': '2023-07-18T22:46:55.042Z', 'update_at': '2023-07-18T22:46:55.042Z', 'autopilot_pool': 'cr-a100-80-2x', 'instances': [{'avzone': 'us-east-1a', 'cluster': 'happypiglet'}], 'descriptionLink': '', 'depth': {'num_asks': 9, 'num_bids': 0, 'num_running': 0, 'asks': {'0x0897b7173F81f3d323fC287C9049E4541f5bBF32': 1, '0x2e2B7aB32FFB80b8Bbb583A1C17Ff3336700111B': 1, '0x7C581517e418A31046269aee7A2411FEa8CC1BD0': 1, '0x8a20df4af9049D57B4f08875eB4f98E9678D3AcE': 1, '0xB52F81EFaA46D921B2d6Cf86FeDecf1847956AB7': 1, '0xBAd39DBE4eB99E1185aEe028AFAe184f01B38596': 1, '0xF8c041b5687bcBc2702D4037120F677C8dFB5103': 1, '0xfe2259baF27B4a3B8BE704416aa02F235fC8beEA': 1}, 'asks_updated': '2023-11-30T09:02:10.240098915Z', 'gpus': {'': 0}, 'qps': 13.266666666666667, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'stats': [{'avzone': 'us-east-1a', 'cluster': 'happypiglet', 'capacity': 0.18561005625879043, 'qps': 13.266666666666667}]}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64b7165fcccc52103e2f07e9', 'name': 'togethercomputer/llama-2-70b', 'display_name': 'LLaMA-2 (70B)', 'display_type': 'language', 'description': 'Language model trained on 2 trillion tokens with double the context length of Llama 1. Available in three sizes: 7B, 13B and 70B parameters', 'license': 'LLaMA license Agreement (Meta)', 'link': 'https://huggingface.co/togethercomputer/llama-2-70b', 'creator_organization': 'Meta', 'hardware_label': '2X A100 80GB', 'pricing_tier': 'Featured', 'access': 'open', 'num_parameters': '68976648192', 'show_in_playground': True, 'finetuning_supported': True, 'isFeaturedModel': True, 'context_length': 4096, 'config': {'chat_template_name': 'llama'}, 'pricing': {'input': 225, 'output': 225, 'hourly': 0}, 'created_at': '2023-07-18T22:46:55.042Z', 'update_at': '2023-07-18T22:46:55.042Z', 'autopilot_pool': 'cr-a100-80-2x', 'instances': [{'avzone': 'us-east-1a', 'cluster': 'happypiglet'}], 'descriptionLink': '', 'depth': {'num_asks': 3, 'num_bids': 0, 'num_running': 0, 'asks': {'0x6d024295Fe0369978762D09815dE85f2F60A1ecd': 1, '0xD2AEb96bdf3B886A196F68dE9D84B381308AA7EA': 1}, 'asks_updated': '2023-11-30T07:24:53.813957673Z', 'gpus': {'': 0}, 'qps': 0.06666666666666667, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'stats': [{'avzone': 'us-east-1a', 'cluster': 'happypiglet', 'capacity': 0.01694915254237288, 'qps': 0.06666666666666667}]}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64b7165fcccc52103e2f07e6', 'name': 'togethercomputer/llama-2-7b-chat', 'display_name': 'LLaMA-2 Chat (7B)', 'display_type': 'chat', 'description': 'Llama 2-chat leverages publicly available instruction datasets and over 1 million human annotations. Available in three sizes: 7B, 13B and 70B parameters', 'license': 'LLaMA license Agreement (Meta)', 'link': 'https://huggingface.co/togethercomputer/llama-2-7b-chat', 'creator_organization': 'Meta', 'hardware_label': 'A100 80GB', 'pricing_tier': 'Featured', 'access': 'open', 'num_parameters': '6738415616', 'show_in_playground': True, 'finetuning_supported': True, 'isFeaturedModel': True, 'context_length': 4096, 'config': {'prompt_format': '[INST] {prompt} [/INST]', 'stop': ['[/INST]', '</s>'], 'chat_template_name': 'llama'}, 'pricing': {'input': 50, 'output': 50, 'hourly': 0}, 'created_at': '2023-07-18T22:46:55.042Z', 'update_at': '2023-07-18T22:46:55.042Z', 'instances': [{'avzone': 'us-east-1a', 'cluster': 'happypiglet'}], 'descriptionLink': '', 'depth': {'num_asks': 2, 'num_bids': 0, 'num_running': 0, 'asks': {'0x7b26c6138a649F91Eb542906284389e49A2f56F5': 1}, 'asks_updated': '2023-11-30T09:00:42.973737927Z', 'gpus': {'': 0}, 'qps': 0.06666666666666667, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'stats': [{'avzone': 'us-east-1a', 'cluster': 'happypiglet', 'capacity': 0.0625, 'qps': 0.06666666666666667}]}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64b7165fcccc52103e2f07e5', 'name': 'togethercomputer/llama-2-7b', 'display_name': 'LLaMA-2 (7B)', 'display_type': 'language', 'description': 'Language model trained on 2 trillion tokens with double the context length of Llama 1. Available in three sizes: 7B, 13B and 70B parameters', 'license': 'LLaMA license Agreement (Meta)', 'link': 'https://huggingface.co/togethercomputer/llama-2-7b', 'creator_organization': 'Meta', 'hardware_label': 'A100 80GB', 'pricing_tier': 'Featured', 'access': 'open', 'num_parameters': '6738415616', 'show_in_playground': True, 'finetuning_supported': True, 'isFeaturedModel': True, 'context_length': 4096, 'config': {'chat_template_name': 'llama'}, 'pricing': {'input': 50, 'output': 50, 'hourly': 0}, 'created_at': '2023-07-18T22:46:55.042Z', 'update_at': '2023-07-18T22:46:55.042Z', 'instances': [{'avzone': 'us-east-1a', 'cluster': 'happypiglet'}], 'descriptionLink': '', 'depth': {'num_asks': 2, 'num_bids': 0, 'num_running': 0, 'asks': {'0xe80502a69732A5b012E8E5c0837e53099A059174': 1}, 'asks_updated': '2023-11-30T08:57:01.847923378Z', 'gpus': {'': 0}, 'qps': 0.06666666666666667, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'stats': [{'avzone': 'us-east-1a', 'cluster': 'happypiglet', 'capacity': 0.08333333333333333, 'qps': 0.06666666666666667}]}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64ee72a0aa4f1b1b2c66f0a5', 'name': 'upstage/SOLAR-0-70b-16bit', 'display_name': 'SOLAR v0 (70B)', 'display_type': 'chat', 'description': 'Language model instruction fine-tuned by upstage.ai on Orca and Alpaca style datasets that reached the top spot in openLLM rankings', 'license': 'CC BY-NC-4.0', 'creator_organization': 'Upstage', 'hardware_label': '2x A100 80GB', 'num_parameters': 70000000000, 'release_date': '2023-08-01T00:00:00.000Z', 'show_in_playground': True, 'isFeaturedModel': True, 'context_length': 4096, 'config': {'stop': ['###'], 'prompt_format': '### System:\\nYou are a respectful and helpful assistant.\\n### User:\\n{prompt}\\n### Assistant:', 'chat_template': \"{{ '### System:\\nYou are a respectful and helpful assistant.\\n' }}{% for message in messages %}{% if message['role'] == 'user' %}{{ '### User:\\n' + message['content'] + '\\n' }}{% else %}{{ '### Assistant:\\n' + message['content'] + '\\n' }}{% endif %}{% endfor %}{{ '### Assistant:' }}\"}, 'pricing': {'input': 225, 'output': 225, 'hourly': 0}, 'created_at': '2023-08-29T22:35:12.294Z', 'update_at': '2023-08-29T22:35:12.294Z', 'access': '', 'link': '', 'descriptionLink': '', 'depth': {'num_asks': 13, 'num_bids': 8, 'num_running': 8, 'asks': {'0x27aF4Aa79cAF4474BFAE3bdE9D270d5aA66d653e': 5, '0x28c6482fc89503c6b1e31df21af94804e82609D5': 2, '0x4490a9356Bdd49156142e78388ed80114a4Bc1E6': 1, '0x8E3ed25250B5152Ac86935386cdC0F2228EBEC9C': 4, '0xF43B38c82e5b1357Ab601aa4f2855E621Ee303d8': 1}, 'asks_updated': '2023-11-30T08:36:41.381592847Z', 'gpus': {'': 0}, 'qps': 0.17387462, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'throughput_in': 633.2236, 'throughput_out': 104.670944}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64ace3af227f790586239ce6', 'name': 'wavymulder/Analog-Diffusion', 'display_name': 'Analog Diffusion', 'display_type': 'image', 'description': 'Dreambooth model trained on a diverse set of analog photographs to provide an analog film effect. ', 'license': 'creativeml-openrail-m', 'link': 'https://huggingface.co/wavymulder/Analog-Diffusion', 'creator_organization': 'Wavymulder', 'hardware_label': 'A40 48GB', 'pricing_tier': 'supported', 'access': 'open', 'num_parameters': 0, 'show_in_playground': True, 'isFeaturedModel': True, 'external_pricing_url': 'https://www.together.xyz/apis#pricing', 'created_at': '2023-07-11T05:07:59.364Z', 'update_at': '2023-07-11T05:07:59.364Z', 'descriptionLink': '', 'pricing': {'hourly': 0, 'input': 0, 'output': 0, 'base': 0, 'finetune': 0}, 'depth': {'num_asks': 1, 'num_bids': 0, 'num_running': 0, 'asks': {'0xC830b3583bcA51887185318c0184fbdB622A55f5': 1}, 'asks_updated': '2023-11-30T08:43:23.563355674Z', 'gpus': {'NVIDIA A40': 1}, 'options': {'input=text,image': 1}, 'qps': 0.014621044, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}, 'throughput_in': 0.33624262}}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '655e703de94c78d2e9a9bc70', 'name': 'mifu67@stanford.edu/llama-2-7b-chat-young-han-new-data-3--1e-05-2023-11-22-21-08-10', 'display_type': 'chat', 'description': 'Llama 2-chat leverages publicly available instruction datasets and over 1 million human annotations. Available in three sizes: 7B, 13B and 70B parameters', 'creator_organization': 'mifu67@stanford.edu', 'hardware_label': 'L40', 'num_parameters': '6738415616', 'release_date': '2023-11-22T21:18:53.292Z', 'show_in_playground': True, 'owner': 'mifu67@stanford.edu', 'owner_address': '0xebd597774b313d8e8d22af4629b75ec7d567f678', 'owner_userid': '6552b4a556bb2d3952ed7a14', 'parent': 'togethercomputer/llama-2-7b-chat', 'base': 'togethercomputer/llama-2-7b-chat', 'path': 'r2://together-dev/finetune/6552b4a556bb2d3952ed7a14/mifu67@stanford.edu/llama-2-7b-chat-young-han-new-data-3--1e-05-2023-11-22-21-08-10/ft-5ff6785e-ae32-4636-a4ff-ce6bec016053-2023-11-22-13-14-06', 'files': [{'filename': 'added_tokens.json', 'size': 21, 'hash': 'ddfe5408fa8791d2ce96f5aeeb2bb76', 'modified': '2023-11-22T21:14:10.452Z'}, {'filename': 'config.json', 'size': 603, 'hash': 'f238117b38b277bf76354fb70287646', 'modified': '2023-11-22T21:14:09.351Z'}, {'filename': 'generation_config.json', 'size': 132, 'hash': '8cfc95df8bad11477f8efa77123af44', 'modified': '2023-11-22T21:14:10.155Z'}, {'filename': 'pytorch_model-00001-of-00002.bin', 'size': 9976620122, 'hash': 'e48eb921582519988e30b2ff600fd03f-119', 'modified': '2023-11-22T21:16:35.798Z'}, {'filename': 'pytorch_model-00002-of-00002.bin', 'size': 3500310787, 'hash': '71b70ef9908000aa8cbcf4b4c06c9dc5-41', 'modified': '2023-11-22T21:15:09.221Z'}, {'filename': 'pytorch_model.bin.index.json', 'size': 23950, 'hash': '14bb4de8f69434fc50ee5fe1b30adea', 'modified': '2023-11-22T21:14:10.224Z'}, {'filename': 'special_tokens_map.json', 'size': 435, 'hash': '413c7f9a8a6517c52c937eed27f1884', 'modified': '2023-11-22T21:14:10.272Z'}, {'filename': 'tokenizer.model', 'size': 499723, 'hash': 'eeec4125e9c7560836b4873b6f8e302', 'modified': '2023-11-22T21:14:10.462Z'}, {'filename': 'tokenizer_config.json', 'size': 825, 'hash': '0b458d0721f67a36c18821b20b4d65f', 'modified': '2023-11-22T21:14:10.237Z'}], 'config': {'prompt_format': '[INST] {prompt} [/INST]', 'stop': ['[/INST]', '</s>']}, 'worker_config': None, 'worker_template': None, 'pricing': {'hourly': 1400000000, 'input': 0, 'output': 0, 'finetune': 0, 'base': 0}, 'created_at': '2023-11-22T21:18:53.509Z', 'update_at': '2023-11-22T21:18:53.509Z', 'autopilot_pool': None, 'has_wandb_telemetry': False, 'wandb_url': '', 'access': '', 'depth': {'num_asks': 0, 'num_bids': 0, 'num_running': 0, 'asks_updated': '2023-11-22T21:41:56.745587576Z', 'qps': 0, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}}, 'link': '', 'license': '', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '65603ee6297c0d1aa331f724', 'name': 'mifu67@stanford.edu/llama-2-7b-chat-han-first-3--1e-05-2023-11-24-05-56-02', 'display_type': 'chat', 'description': 'Llama 2-chat leverages publicly available instruction datasets and over 1 million human annotations. Available in three sizes: 7B, 13B and 70B parameters', 'creator_organization': 'mifu67@stanford.edu', 'hardware_label': 'L40', 'num_parameters': '6738415616', 'release_date': '2023-11-24T06:12:54.772Z', 'show_in_playground': True, 'owner': 'mifu67@stanford.edu', 'owner_address': '0xebd597774b313d8e8d22af4629b75ec7d567f678', 'owner_userid': '6552b4a556bb2d3952ed7a14', 'parent': 'togethercomputer/llama-2-7b-chat', 'base': 'togethercomputer/llama-2-7b-chat', 'path': 'r2://together-dev/finetune/6552b4a556bb2d3952ed7a14/mifu67@stanford.edu/llama-2-7b-chat-han-first-3--1e-05-2023-11-24-05-56-02/ft-5c5faba8-4c1a-41b1-8f8a-c22c5772128f-2023-11-23-22-08-26', 'files': [{'filename': 'added_tokens.json', 'size': 21, 'hash': 'ddfe5408fa8791d2ce96f5aeeb2bb76', 'modified': '2023-11-24T06:08:29.647Z'}, {'filename': 'config.json', 'size': 603, 'hash': 'f238117b38b277bf76354fb70287646', 'modified': '2023-11-24T06:08:30.181Z'}, {'filename': 'generation_config.json', 'size': 132, 'hash': '8cfc95df8bad11477f8efa77123af44', 'modified': '2023-11-24T06:08:30.202Z'}, {'filename': 'pytorch_model-00001-of-00002.bin', 'size': 9976620122, 'hash': '46325810d92b773e010a4836bbe68a9f-119', 'modified': '2023-11-24T06:10:45.375Z'}, {'filename': 'pytorch_model-00002-of-00002.bin', 'size': 3500310787, 'hash': '10333b6016655f4baf1462b6731902af-41', 'modified': '2023-11-24T06:09:25.802Z'}, {'filename': 'pytorch_model.bin.index.json', 'size': 23950, 'hash': '14bb4de8f69434fc50ee5fe1b30adea', 'modified': '2023-11-24T06:08:30.183Z'}, {'filename': 'special_tokens_map.json', 'size': 435, 'hash': '413c7f9a8a6517c52c937eed27f1884', 'modified': '2023-11-24T06:08:30.158Z'}, {'filename': 'tokenizer.model', 'size': 499723, 'hash': 'eeec4125e9c7560836b4873b6f8e302', 'modified': '2023-11-24T06:08:30.566Z'}, {'filename': 'tokenizer_config.json', 'size': 825, 'hash': '0b458d0721f67a36c18821b20b4d65f', 'modified': '2023-11-24T06:08:30.150Z'}], 'config': {'prompt_format': '[INST] {prompt} [/INST]', 'stop': ['[/INST]', '</s>']}, 'worker_config': None, 'worker_template': None, 'pricing': {'hourly': 1400000000, 'input': 0, 'output': 0, 'finetune': 0, 'base': 0}, 'created_at': '2023-11-24T06:12:54.971Z', 'update_at': '2023-11-24T06:12:54.971Z', 'autopilot_pool': None, 'has_wandb_telemetry': False, 'wandb_url': '', 'access': '', 'depth': {'num_asks': 0, 'num_bids': 0, 'num_running': 0, 'asks_updated': '2023-11-29T02:06:36.507874782Z', 'qps': 0, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}}, 'link': '', 'license': '', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '655e7c91e94c78d2e9a9bc78', 'name': 'mifu67@stanford.edu/llama-2-7b-chat-young-han-new-data-6--1e-05-2023-11-22-21-56-35', 'display_type': 'chat', 'description': 'Llama 2-chat leverages publicly available instruction datasets and over 1 million human annotations. Available in three sizes: 7B, 13B and 70B parameters', 'creator_organization': 'mifu67@stanford.edu', 'hardware_label': 'L40', 'num_parameters': '6738415616', 'release_date': '2023-11-22T22:11:28.854Z', 'show_in_playground': True, 'owner': 'mifu67@stanford.edu', 'owner_address': '0xebd597774b313d8e8d22af4629b75ec7d567f678', 'owner_userid': '6552b4a556bb2d3952ed7a14', 'parent': 'togethercomputer/llama-2-7b-chat', 'base': 'togethercomputer/llama-2-7b-chat', 'path': 'r2://together-dev/finetune/6552b4a556bb2d3952ed7a14/mifu67@stanford.edu/llama-2-7b-chat-young-han-new-data-6--1e-05-2023-11-22-21-56-35/ft-4dd9ec0a-d19e-4bf6-bf44-f360b14cee1c-2023-11-22-14-06-51', 'files': [{'filename': 'added_tokens.json', 'size': 21, 'hash': 'ddfe5408fa8791d2ce96f5aeeb2bb76', 'modified': '2023-11-22T22:06:55.120Z'}, {'filename': 'config.json', 'size': 603, 'hash': 'f238117b38b277bf76354fb70287646', 'modified': '2023-11-22T22:06:55.189Z'}, {'filename': 'generation_config.json', 'size': 132, 'hash': '8cfc95df8bad11477f8efa77123af44', 'modified': '2023-11-22T22:06:55.166Z'}, {'filename': 'pytorch_model-00001-of-00002.bin', 'size': 9976620122, 'hash': '36b2baef72d07f27713e22a0ade0fa09-119', 'modified': '2023-11-22T22:09:11.047Z'}, {'filename': 'pytorch_model-00002-of-00002.bin', 'size': 3500310787, 'hash': 'b64fda8565064857c0bc050507f22072-41', 'modified': '2023-11-22T22:07:56.571Z'}, {'filename': 'pytorch_model.bin.index.json', 'size': 23950, 'hash': '14bb4de8f69434fc50ee5fe1b30adea', 'modified': '2023-11-22T22:06:55.141Z'}, {'filename': 'special_tokens_map.json', 'size': 435, 'hash': '413c7f9a8a6517c52c937eed27f1884', 'modified': '2023-11-22T22:06:55.217Z'}, {'filename': 'tokenizer.model', 'size': 499723, 'hash': 'eeec4125e9c7560836b4873b6f8e302', 'modified': '2023-11-22T22:06:55.510Z'}, {'filename': 'tokenizer_config.json', 'size': 825, 'hash': '0b458d0721f67a36c18821b20b4d65f', 'modified': '2023-11-22T22:06:54.646Z'}], 'config': {'prompt_format': '[INST] {prompt} [/INST]', 'stop': ['[/INST]', '</s>']}, 'worker_config': None, 'worker_template': None, 'pricing': {'hourly': 1400000000, 'input': 0, 'output': 0, 'finetune': 0, 'base': 0}, 'created_at': '2023-11-22T22:11:29.045Z', 'update_at': '2023-11-22T22:11:29.045Z', 'autopilot_pool': None, 'has_wandb_telemetry': False, 'wandb_url': '', 'access': '', 'depth': {'num_asks': 0, 'num_bids': 0, 'num_running': 0, 'asks_updated': '2023-11-29T17:28:39.442017849Z', 'qps': 0, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}}, 'link': '', 'license': '', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '65627212297c0d1aa331f7a1', 'name': 'mifu67@stanford.edu/llama-2-7b-chat-old-han-first-5--1e-05-2023-11-25-21-58-35', 'display_type': 'chat', 'description': 'Llama 2-chat leverages publicly available instruction datasets and over 1 million human annotations. Available in three sizes: 7B, 13B and 70B parameters', 'creator_organization': 'mifu67@stanford.edu', 'hardware_label': 'L40', 'num_parameters': '6738415616', 'release_date': '2023-11-25T22:15:46.522Z', 'show_in_playground': True, 'owner': 'mifu67@stanford.edu', 'owner_address': '0xebd597774b313d8e8d22af4629b75ec7d567f678', 'owner_userid': '6552b4a556bb2d3952ed7a14', 'parent': 'togethercomputer/llama-2-7b-chat', 'base': 'togethercomputer/llama-2-7b-chat', 'path': 'r2://together-dev/finetune/6552b4a556bb2d3952ed7a14/mifu67@stanford.edu/llama-2-7b-chat-old-han-first-5--1e-05-2023-11-25-21-58-35/ft-b28914ad-08ca-42fc-9807-3b61fede621f-2023-11-25-14-11-35', 'files': [{'filename': 'added_tokens.json', 'size': 21, 'hash': 'ddfe5408fa8791d2ce96f5aeeb2bb76', 'modified': '2023-11-25T22:11:39.223Z'}, {'filename': 'config.json', 'size': 603, 'hash': 'f238117b38b277bf76354fb70287646', 'modified': '2023-11-25T22:11:38.608Z'}, {'filename': 'generation_config.json', 'size': 132, 'hash': '8cfc95df8bad11477f8efa77123af44', 'modified': '2023-11-25T22:11:39.409Z'}, {'filename': 'pytorch_model-00001-of-00002.bin', 'size': 9976620122, 'hash': '2b9c408550c1a6a690ac4c083e62d8c5-119', 'modified': '2023-11-25T22:13:56.728Z'}, {'filename': 'pytorch_model-00002-of-00002.bin', 'size': 3500310787, 'hash': 'b9f27acd5a26a1d69dac86c9b7cd587b-41', 'modified': '2023-11-25T22:13:09.411Z'}, {'filename': 'pytorch_model.bin.index.json', 'size': 23950, 'hash': '14bb4de8f69434fc50ee5fe1b30adea', 'modified': '2023-11-25T22:11:39.224Z'}, {'filename': 'special_tokens_map.json', 'size': 435, 'hash': '413c7f9a8a6517c52c937eed27f1884', 'modified': '2023-11-25T22:11:39.152Z'}, {'filename': 'tokenizer.model', 'size': 499723, 'hash': 'eeec4125e9c7560836b4873b6f8e302', 'modified': '2023-11-25T22:11:39.668Z'}, {'filename': 'tokenizer_config.json', 'size': 825, 'hash': '0b458d0721f67a36c18821b20b4d65f', 'modified': '2023-11-25T22:11:39.575Z'}], 'config': {'prompt_format': '[INST] {prompt} [/INST]', 'stop': ['[/INST]', '</s>']}, 'worker_config': None, 'worker_template': None, 'pricing': {'hourly': 1400000000, 'input': 0, 'output': 0, 'finetune': 0, 'base': 0}, 'created_at': '2023-11-25T22:15:46.729Z', 'update_at': '2023-11-25T22:15:46.729Z', 'autopilot_pool': None, 'has_wandb_telemetry': False, 'wandb_url': '', 'access': '', 'depth': {'num_asks': 0, 'num_bids': 0, 'num_running': 0, 'asks_updated': '2023-11-27T06:13:46.19718036Z', 'qps': 0, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}}, 'link': '', 'license': '', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '65627b1c297c0d1aa331f7b0', 'name': 'mifu67@stanford.edu/llama-2-7b-chat-old-han-second-10--1e-05-2023-11-25-22-27-37', 'display_type': 'chat', 'description': 'Llama 2-chat leverages publicly available instruction datasets and over 1 million human annotations. Available in three sizes: 7B, 13B and 70B parameters', 'creator_organization': 'mifu67@stanford.edu', 'hardware_label': 'L40', 'num_parameters': '6738415616', 'release_date': '2023-11-25T22:54:20.361Z', 'show_in_playground': True, 'owner': 'mifu67@stanford.edu', 'owner_address': '0xebd597774b313d8e8d22af4629b75ec7d567f678', 'owner_userid': '6552b4a556bb2d3952ed7a14', 'parent': 'togethercomputer/llama-2-7b-chat', 'base': 'togethercomputer/llama-2-7b-chat', 'path': 'r2://together-dev/finetune/6552b4a556bb2d3952ed7a14/mifu67@stanford.edu/llama-2-7b-chat-old-han-second-10--1e-05-2023-11-25-22-27-37/ft-4bf5839f-2e92-45bc-acf2-a51d8a7d1031-2023-11-25-14-50-31', 'files': [{'filename': 'added_tokens.json', 'size': 21, 'hash': 'ddfe5408fa8791d2ce96f5aeeb2bb76', 'modified': '2023-11-25T22:50:35.465Z'}, {'filename': 'config.json', 'size': 603, 'hash': 'f238117b38b277bf76354fb70287646', 'modified': '2023-11-25T22:50:34.541Z'}, {'filename': 'generation_config.json', 'size': 132, 'hash': '8cfc95df8bad11477f8efa77123af44', 'modified': '2023-11-25T22:50:35.538Z'}, {'filename': 'pytorch_model-00001-of-00002.bin', 'size': 9976620122, 'hash': '56c1a077891cc2393a4c8bc442be0f62-119', 'modified': '2023-11-25T22:52:37.727Z'}, {'filename': 'pytorch_model-00002-of-00002.bin', 'size': 3500310787, 'hash': '51bf7d04a1b065d65cf423b3a149ef5d-41', 'modified': '2023-11-25T22:51:36.709Z'}, {'filename': 'pytorch_model.bin.index.json', 'size': 23950, 'hash': '14bb4de8f69434fc50ee5fe1b30adea', 'modified': '2023-11-25T22:50:35.607Z'}, {'filename': 'special_tokens_map.json', 'size': 435, 'hash': '413c7f9a8a6517c52c937eed27f1884', 'modified': '2023-11-25T22:50:35.553Z'}, {'filename': 'tokenizer.model', 'size': 499723, 'hash': 'eeec4125e9c7560836b4873b6f8e302', 'modified': '2023-11-25T22:50:36.156Z'}, {'filename': 'tokenizer_config.json', 'size': 825, 'hash': '0b458d0721f67a36c18821b20b4d65f', 'modified': '2023-11-25T22:50:36.365Z'}], 'config': {'prompt_format': '[INST] {prompt} [/INST]', 'stop': ['[/INST]', '</s>']}, 'worker_config': None, 'worker_template': None, 'pricing': {'hourly': 1400000000, 'input': 0, 'output': 0, 'finetune': 0, 'base': 0}, 'created_at': '2023-11-25T22:54:20.575Z', 'update_at': '2023-11-25T22:54:20.575Z', 'autopilot_pool': None, 'has_wandb_telemetry': False, 'wandb_url': '', 'access': '', 'depth': {'num_asks': 0, 'num_bids': 0, 'num_running': 0, 'asks_updated': '2023-11-28T07:39:07.794403116Z', 'qps': 0, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}}, 'link': '', 'license': '', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '65641c69297c0d1aa331f7fe', 'name': 'mifu67@stanford.edu/llama-2-7b-chat-old-han-second-20--1e-05-2023-11-27-03-45-03', 'display_type': 'chat', 'description': 'Llama 2-chat leverages publicly available instruction datasets and over 1 million human annotations. Available in three sizes: 7B, 13B and 70B parameters', 'creator_organization': 'mifu67@stanford.edu', 'hardware_label': 'L40', 'num_parameters': '6738415616', 'release_date': '2023-11-27T04:34:48.917Z', 'show_in_playground': True, 'owner': 'mifu67@stanford.edu', 'owner_address': '0xebd597774b313d8e8d22af4629b75ec7d567f678', 'owner_userid': '6552b4a556bb2d3952ed7a14', 'parent': 'togethercomputer/llama-2-7b-chat', 'base': 'togethercomputer/llama-2-7b-chat', 'path': 'r2://together-dev/finetune/6552b4a556bb2d3952ed7a14/mifu67@stanford.edu/llama-2-7b-chat-old-han-second-20--1e-05-2023-11-27-03-45-03/ft-89dab9cf-f09a-40f8-8fe6-74db4202fb3b-2023-11-26-20-30-00', 'files': [{'filename': 'added_tokens.json', 'size': 21, 'hash': 'ddfe5408fa8791d2ce96f5aeeb2bb76', 'modified': '2023-11-27T04:30:04.663Z'}, {'filename': 'config.json', 'size': 603, 'hash': 'f238117b38b277bf76354fb70287646', 'modified': '2023-11-27T04:30:04.028Z'}, {'filename': 'generation_config.json', 'size': 132, 'hash': '8cfc95df8bad11477f8efa77123af44', 'modified': '2023-11-27T04:30:04.559Z'}, {'filename': 'pytorch_model-00001-of-00002.bin', 'size': 9976620122, 'hash': 'f8c72121a0bc888e0c72354b000c96b2-119', 'modified': '2023-11-27T04:32:19.893Z'}, {'filename': 'pytorch_model-00002-of-00002.bin', 'size': 3500310787, 'hash': 'd0f4d6fcccb298a4795285703fa2ecf7-41', 'modified': '2023-11-27T04:31:14.747Z'}, {'filename': 'pytorch_model.bin.index.json', 'size': 23950, 'hash': '14bb4de8f69434fc50ee5fe1b30adea', 'modified': '2023-11-27T04:30:04.495Z'}, {'filename': 'special_tokens_map.json', 'size': 435, 'hash': '413c7f9a8a6517c52c937eed27f1884', 'modified': '2023-11-27T04:30:04.478Z'}, {'filename': 'tokenizer.model', 'size': 499723, 'hash': 'eeec4125e9c7560836b4873b6f8e302', 'modified': '2023-11-27T04:30:04.671Z'}, {'filename': 'tokenizer_config.json', 'size': 825, 'hash': '0b458d0721f67a36c18821b20b4d65f', 'modified': '2023-11-27T04:30:04.787Z'}], 'config': {'prompt_format': '[INST] {prompt} [/INST]', 'stop': ['[/INST]', '</s>']}, 'worker_config': None, 'worker_template': None, 'pricing': {'hourly': 1400000000, 'input': 0, 'output': 0, 'finetune': 0, 'base': 0}, 'created_at': '2023-11-27T04:34:49.103Z', 'update_at': '2023-11-27T04:34:49.103Z', 'autopilot_pool': None, 'has_wandb_telemetry': False, 'wandb_url': '', 'access': '', 'depth': {'num_asks': 0, 'num_bids': 0, 'num_running': 0, 'asks_updated': '0001-01-01T00:00:00Z', 'qps': 0, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}}, 'link': '', 'license': '', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '65641caa297c0d1aa331f800', 'name': 'mifu67@stanford.edu/llama-2-7b-chat-old-han-third-20--1e-05-2023-11-27-03-46-19', 'display_type': 'chat', 'description': 'Llama 2-chat leverages publicly available instruction datasets and over 1 million human annotations. Available in three sizes: 7B, 13B and 70B parameters', 'creator_organization': 'mifu67@stanford.edu', 'hardware_label': 'L40', 'num_parameters': '6738415616', 'release_date': '2023-11-27T04:35:54.335Z', 'show_in_playground': True, 'owner': 'mifu67@stanford.edu', 'owner_address': '0xebd597774b313d8e8d22af4629b75ec7d567f678', 'owner_userid': '6552b4a556bb2d3952ed7a14', 'parent': 'togethercomputer/llama-2-7b-chat', 'base': 'togethercomputer/llama-2-7b-chat', 'path': 'r2://together-dev/finetune/6552b4a556bb2d3952ed7a14/mifu67@stanford.edu/llama-2-7b-chat-old-han-third-20--1e-05-2023-11-27-03-46-19/ft-9a50dddf-094e-4bdd-953b-0eab313d70e7-2023-11-26-20-31-53', 'files': [{'filename': 'added_tokens.json', 'size': 21, 'hash': 'ddfe5408fa8791d2ce96f5aeeb2bb76', 'modified': '2023-11-27T04:31:56.691Z'}, {'filename': 'config.json', 'size': 603, 'hash': 'f238117b38b277bf76354fb70287646', 'modified': '2023-11-27T04:31:55.934Z'}, {'filename': 'generation_config.json', 'size': 132, 'hash': '8cfc95df8bad11477f8efa77123af44', 'modified': '2023-11-27T04:31:56.462Z'}, {'filename': 'pytorch_model-00001-of-00002.bin', 'size': 9976620122, 'hash': '358431f7275bb26f1f86694591eb9569-119', 'modified': '2023-11-27T04:34:01.231Z'}, {'filename': 'pytorch_model-00002-of-00002.bin', 'size': 3500310787, 'hash': '10bbd161cfc669e4de9c692374c66976-41', 'modified': '2023-11-27T04:33:21.721Z'}, {'filename': 'pytorch_model.bin.index.json', 'size': 23950, 'hash': '14bb4de8f69434fc50ee5fe1b30adea', 'modified': '2023-11-27T04:31:56.263Z'}, {'filename': 'special_tokens_map.json', 'size': 435, 'hash': '413c7f9a8a6517c52c937eed27f1884', 'modified': '2023-11-27T04:31:56.430Z'}, {'filename': 'tokenizer.model', 'size': 499723, 'hash': 'eeec4125e9c7560836b4873b6f8e302', 'modified': '2023-11-27T04:31:56.548Z'}, {'filename': 'tokenizer_config.json', 'size': 825, 'hash': '0b458d0721f67a36c18821b20b4d65f', 'modified': '2023-11-27T04:31:56.579Z'}], 'config': {'prompt_format': '[INST] {prompt} [/INST]', 'stop': ['[/INST]', '</s>']}, 'worker_config': None, 'worker_template': None, 'pricing': {'hourly': 1400000000, 'input': 0, 'output': 0, 'finetune': 0, 'base': 0}, 'created_at': '2023-11-27T04:35:54.597Z', 'update_at': '2023-11-27T04:35:54.597Z', 'autopilot_pool': None, 'has_wandb_telemetry': False, 'wandb_url': '', 'access': '', 'depth': {'num_asks': 0, 'num_bids': 0, 'num_running': 0, 'asks_updated': '2023-11-29T17:52:55.645578622Z', 'qps': 0, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}}, 'link': '', 'license': '', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '6557d5a5c8fe37c1d548da4f', 'name': 'mifu67@stanford.edu/llama-2-7b-chat-my-demo-finetune-2023-11-17-20-51-22', 'display_type': 'chat', 'description': 'Llama 2-chat leverages publicly available instruction datasets and over 1 million human annotations. Available in three sizes: 7B, 13B and 70B parameters', 'creator_organization': 'mifu67@stanford.edu', 'hardware_label': 'L40', 'num_parameters': '6738415616', 'release_date': '2023-11-17T21:05:40.815Z', 'show_in_playground': True, 'owner': 'mifu67@stanford.edu', 'owner_address': '0xebd597774b313d8e8d22af4629b75ec7d567f678', 'owner_userid': '6552b4a556bb2d3952ed7a14', 'parent': 'togethercomputer/llama-2-7b-chat', 'base': 'togethercomputer/llama-2-7b-chat', 'path': 'r2://together-dev/finetune/6552b4a556bb2d3952ed7a14/mifu67@stanford.edu/llama-2-7b-chat-my-demo-finetune-2023-11-17-20-51-22/ft-43158f66-36ae-481d-a40b-f396019113ff-2023-11-17-13-01-42', 'files': [{'filename': 'added_tokens.json', 'size': 21, 'hash': 'ddfe5408fa8791d2ce96f5aeeb2bb76', 'modified': '2023-11-17T21:01:45.901Z'}, {'filename': 'config.json', 'size': 603, 'hash': 'f238117b38b277bf76354fb70287646', 'modified': '2023-11-17T21:01:45.749Z'}, {'filename': 'generation_config.json', 'size': 132, 'hash': '8cfc95df8bad11477f8efa77123af44', 'modified': '2023-11-17T21:01:44.954Z'}, {'filename': 'pytorch_model-00001-of-00002.bin', 'size': 9976620122, 'hash': '4763a46138d621b8de4277debd9b20da-119', 'modified': '2023-11-17T21:03:58.715Z'}, {'filename': 'pytorch_model-00002-of-00002.bin', 'size': 3500310787, 'hash': 'd63cb28f9b2c9100ec6094ff39a7197f-41', 'modified': '2023-11-17T21:02:57.012Z'}, {'filename': 'pytorch_model.bin.index.json', 'size': 23950, 'hash': '14bb4de8f69434fc50ee5fe1b30adea', 'modified': '2023-11-17T21:01:45.760Z'}, {'filename': 'special_tokens_map.json', 'size': 435, 'hash': '413c7f9a8a6517c52c937eed27f1884', 'modified': '2023-11-17T21:01:45.806Z'}, {'filename': 'tokenizer.model', 'size': 499723, 'hash': 'eeec4125e9c7560836b4873b6f8e302', 'modified': '2023-11-17T21:01:45.989Z'}, {'filename': 'tokenizer_config.json', 'size': 825, 'hash': '0b458d0721f67a36c18821b20b4d65f', 'modified': '2023-11-17T21:01:45.643Z'}], 'config': {'prompt_format': '[INST] {prompt} [/INST]', 'stop': ['[/INST]', '</s>']}, 'worker_config': None, 'worker_template': None, 'pricing': {'hourly': 1400000000, 'input': 0, 'output': 0, 'finetune': 0, 'base': 0}, 'created_at': '2023-11-17T21:05:41.026Z', 'update_at': '2023-11-17T21:05:41.026Z', 'autopilot_pool': None, 'has_wandb_telemetry': False, 'wandb_url': '', 'access': '', 'depth': {'num_asks': 0, 'num_bids': 0, 'num_running': 0, 'asks_updated': '2023-11-18T02:20:51.068199522Z', 'qps': 0, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}}, 'link': '', 'license': '', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '65582d676865deb9bb51e2fa', 'name': 'mifu67@stanford.edu/llama-2-70b-chat-my-demo-finetune-2023-11-17-20-51-35', 'display_type': 'chat', 'description': 'Llama 2-chat leverages publicly available instruction datasets and over 1 million human annotations. Available in three sizes: 7B, 13B and 70B parameters', 'creator_organization': 'mifu67@stanford.edu', 'hardware_label': '2x A100 80GB', 'num_parameters': '68976648192', 'release_date': '2023-11-18T03:20:07.317Z', 'show_in_playground': True, 'owner': 'mifu67@stanford.edu', 'owner_address': '0xebd597774b313d8e8d22af4629b75ec7d567f678', 'owner_userid': '6552b4a556bb2d3952ed7a14', 'parent': 'togethercomputer/llama-2-70b-chat', 'base': 'togethercomputer/llama-2-70b-chat', 'path': 'r2://together-dev/finetune/6552b4a556bb2d3952ed7a14/mifu67@stanford.edu/llama-2-70b-chat-my-demo-finetune-2023-11-17-20-51-35/ft-3625edb3-0c2d-4cf7-9164-e45532dfea2b-2023-11-17-18-48-43', 'files': [{'filename': 'README.md', 'size': 1469, 'hash': '32bbb3ddde59255848c98ed438d90d2', 'modified': '2023-11-18T02:48:46.718Z'}, {'filename': 'all_results.json', 'size': 434, 'hash': 'b802e58ae4f673867384ac0dc9a439f', 'modified': '2023-11-18T02:48:46.261Z'}, {'filename': 'config.json', 'size': 687, 'hash': '996cb86147e7a25fc1e18b7cceb1f88', 'modified': '2023-11-18T02:48:46.623Z'}, {'filename': 'eval_results.json', 'size': 264, 'hash': 'd1962ed75c1e9ef1144d56def6d9780', 'modified': '2023-11-18T02:48:46.927Z'}, {'filename': 'generation_config.json', 'size': 132, 'hash': '8272d56fb279e1fbfcc6bfc841c968a', 'modified': '2023-11-18T02:48:46.584Z'}, {'filename': 'pytorch_model-00001-of-00015.bin', 'size': 9852601804, 'hash': '753d7aa19e4bab5cfd6b0823857d3cb8-117', 'modified': '2023-11-18T02:57:00.276Z'}, {'filename': 'pytorch_model-00002-of-00015.bin', 'size': 9798109380, 'hash': 'eff59207ae39ef60d5c3ee4f357f285e-116', 'modified': '2023-11-18T02:56:41.546Z'}, {'filename': 'pytorch_model-00003-of-00015.bin', 'size': 9965880502, 'hash': 'c71b064c73a381f3724e6089a870f5cb-118', 'modified': '2023-11-18T02:57:22.698Z'}, {'filename': 'pytorch_model-00004-of-00015.bin', 'size': 9798075916, 'hash': 'ebb94280fc17aef79293a4cbe92f4a04-116', 'modified': '2023-11-18T02:56:50.740Z'}, {'filename': 'pytorch_model-00005-of-00015.bin', 'size': 9798109360, 'hash': '2796d62b1908aea9a267eea1df4592d7-116', 'modified': '2023-11-18T02:56:54.678Z'}, {'filename': 'pytorch_model-00006-of-00015.bin', 'size': 9798109444, 'hash': '6f3ac8cd135b4b6c88a14469f4352396-116', 'modified': '2023-11-18T03:04:25.309Z'}, {'filename': 'pytorch_model-00007-of-00015.bin', 'size': 9965880502, 'hash': 'e26e216a30d8bd74544767d24d4e6b76-118', 'modified': '2023-11-18T03:04:40.535Z'}, {'filename': 'pytorch_model-00008-of-00015.bin', 'size': 9798075916, 'hash': 'a7d73b3e21787b6d8e5e68ce725392d3-116', 'modified': '2023-11-18T03:04:41.318Z'}, {'filename': 'pytorch_model-00009-of-00015.bin', 'size': 9798109360, 'hash': '0d1cd89baf3309f3c9e1c37966ed6183-116', 'modified': '2023-11-18T03:04:45.941Z'}, {'filename': 'pytorch_model-00010-of-00015.bin', 'size': 9798109444, 'hash': '4316ad29b2d4e884fae73b56941e1a62-116', 'modified': '2023-11-18T03:05:03.671Z'}, {'filename': 'pytorch_model-00011-of-00015.bin', 'size': 9965880502, 'hash': 'b8aad3f1112e8cf652082d3cfe17d152-118', 'modified': '2023-11-18T03:10:24.198Z'}, {'filename': 'pytorch_model-00012-of-00015.bin', 'size': 9798075916, 'hash': 'e1ff7d60a523c6f2b140b9cbddbafc2b-116', 'modified': '2023-11-18T03:10:29.455Z'}, {'filename': 'pytorch_model-00013-of-00015.bin', 'size': 9798109360, 'hash': 'a98c8838ad394781353923dc43687f5c-116', 'modified': '2023-11-18T03:10:30.710Z'}, {'filename': 'pytorch_model-00014-of-00015.bin', 'size': 9496134826, 'hash': '5e2cf53c3d273e9287353c1f565998c9-113', 'modified': '2023-11-18T03:10:24.610Z'}, {'filename': 'pytorch_model-00015-of-00015.bin', 'size': 524289413, 'hash': '795220f8f55fd8ee1c0b48f6a726fe1a-6', 'modified': '2023-11-18T03:05:26.444Z'}, {'filename': 'pytorch_model.bin.index.json', 'size': 59615, 'hash': '5bb77a095a762a7d1a6c3448a796f01', 'modified': '2023-11-18T03:05:26.790Z'}, {'filename': 'special_tokens_map.json', 'size': 435, 'hash': '413c7f9a8a6517c52c937eed27f1884', 'modified': '2023-11-18T03:05:27.064Z'}, {'filename': 'tokenizer.json', 'size': 1843030, 'hash': 'e4696245cb7913263030b4880dde3de', 'modified': '2023-11-18T03:05:27.897Z'}, {'filename': 'tokenizer.model', 'size': 499723, 'hash': 'eeec4125e9c7560836b4873b6f8e302', 'modified': '2023-11-18T03:05:28.163Z'}, {'filename': 'tokenizer_config.json', 'size': 812, 'hash': 'a86eaa9d2d5476d7a41d43834c0ad39', 'modified': '2023-11-18T03:05:28.262Z'}, {'filename': 'train_results.json', 'size': 190, 'hash': 'b3cf6ea7221c429a761f5af6e42f1eb', 'modified': '2023-11-18T03:05:28.734Z'}, {'filename': 'trainer_state.json', 'size': 889, 'hash': '69b91298ed1023ff6ca591ebd92f065', 'modified': '2023-11-18T03:05:28.942Z'}, {'filename': 'training_args.bin', 'size': 6392, 'hash': '02372f37a15dfc300e9a2fdd0399448', 'modified': '2023-11-18T03:05:29.188Z'}], 'config': {'prompt_format': '[INST] {prompt} [/INST]', 'stop': ['[/INST]', '</s>']}, 'worker_config': None, 'worker_template': None, 'pricing': {'hourly': 6170000000, 'input': 0, 'output': 0, 'finetune': 0, 'base': 0}, 'created_at': '2023-11-18T03:20:07.562Z', 'update_at': '2023-11-18T03:20:07.562Z', 'autopilot_pool': 'cr-a100-80-2x', 'has_wandb_telemetry': False, 'wandb_url': '', 'access': '', 'depth': {'num_asks': 0, 'num_bids': 0, 'num_running': 0, 'asks_updated': '0001-01-01T00:00:00Z', 'qps': 0, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}}, 'link': '', 'license': '', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '65677372629b5834216f25f0', 'name': 'mifu67@stanford.edu/llama-2-7b-chat-middle-han-second-10--1e-05-2023-11-29-06-01-02', 'display_type': 'chat', 'description': 'Llama 2-chat leverages publicly available instruction datasets and over 1 million human annotations. Available in three sizes: 7B, 13B and 70B parameters', 'creator_organization': 'mifu67@stanford.edu', 'hardware_label': 'L40', 'num_parameters': '6738415616', 'release_date': '2023-11-29T17:22:57.977Z', 'show_in_playground': True, 'owner': 'mifu67@stanford.edu', 'owner_address': '0xebd597774b313d8e8d22af4629b75ec7d567f678', 'owner_userid': '6552b4a556bb2d3952ed7a14', 'parent': 'togethercomputer/llama-2-7b-chat', 'base': 'togethercomputer/llama-2-7b-chat', 'path': 'r2://together-dev/finetune/6552b4a556bb2d3952ed7a14/mifu67@stanford.edu/llama-2-7b-chat-middle-han-second-10--1e-05-2023-11-29-06-01-02/ft-1c17315c-eebb-47a8-bdd9-f76272bb05ce-2023-11-29-09-18-55', 'files': [{'filename': 'added_tokens.json', 'size': 21, 'hash': 'ddfe5408fa8791d2ce96f5aeeb2bb76', 'modified': '2023-11-29T17:19:00.272Z'}, {'filename': 'config.json', 'size': 603, 'hash': 'f238117b38b277bf76354fb70287646', 'modified': '2023-11-29T17:19:00.335Z'}, {'filename': 'generation_config.json', 'size': 132, 'hash': '8cfc95df8bad11477f8efa77123af44', 'modified': '2023-11-29T17:18:59.436Z'}, {'filename': 'pytorch_model-00001-of-00002.bin', 'size': 9976620122, 'hash': '2618cbce9429b6aa8e994553f4f97730-119', 'modified': '2023-11-29T17:21:05.060Z'}, {'filename': 'pytorch_model-00002-of-00002.bin', 'size': 3500310787, 'hash': 'f942dafa770519486e133571101ea0b6-41', 'modified': '2023-11-29T17:20:05.714Z'}, {'filename': 'pytorch_model.bin.index.json', 'size': 23950, 'hash': '14bb4de8f69434fc50ee5fe1b30adea', 'modified': '2023-11-29T17:19:00.193Z'}, {'filename': 'special_tokens_map.json', 'size': 435, 'hash': '413c7f9a8a6517c52c937eed27f1884', 'modified': '2023-11-29T17:19:00.338Z'}, {'filename': 'tokenizer.model', 'size': 499723, 'hash': 'eeec4125e9c7560836b4873b6f8e302', 'modified': '2023-11-29T17:19:00.456Z'}, {'filename': 'tokenizer_config.json', 'size': 825, 'hash': '0b458d0721f67a36c18821b20b4d65f', 'modified': '2023-11-29T17:18:59.748Z'}], 'config': {'prompt_format': '[INST] {prompt} [/INST]', 'stop': ['[/INST]', '</s>'], 'chat_template_name': 'llama'}, 'worker_config': None, 'worker_template': None, 'pricing': {'hourly': 1400000000, 'input': 0, 'output': 0, 'finetune': 0, 'base': 0}, 'created_at': '2023-11-29T17:22:58.194Z', 'update_at': '2023-11-29T17:22:58.194Z', 'autopilot_pool': None, 'has_wandb_telemetry': False, 'wandb_url': '', 'access': '', 'depth': {'num_asks': 0, 'num_bids': 0, 'num_running': 0, 'asks_updated': '0001-01-01T00:00:00Z', 'qps': 0, 'permit_required': False, 'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}}, 'link': '', 'license': '', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '6495ff1112907e072b8aecbe', 'name': 'EleutherAI/pythia-1b-v0', 'display_name': 'Pythia (1B)', 'display_type': 'language', 'description': 'The Pythia Scaling Suite is a collection of models developed to facilitate interpretability research.', 'license': '', 'link': '', 'creator_organization': 'EleutherAI', 'hardware_label': 'A40 48GB', 'pricing_tier': 'supported', 'num_parameters': 1000000000, 'show_in_playground': True, 'isFeaturedModel': False, 'context_length': 2048, 'config': {'chat_template_name': 'gpt'}, 'pricing': {'input': 25, 'output': 25, 'hourly': 0}, 'created_at': '2023-06-23T20:22:41.925Z', 'update_at': '2023-06-23T20:22:41.925Z', 'access': '', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '6495ff1412907e072b8aecf1', 'name': 'togethercomputer/codegen2-16B', 'display_name': 'CodeGen2 (16B)', 'display_type': 'code', 'description': 'An autoregressive language models for program synthesis.', 'license': '', 'link': '', 'creator_organization': 'Salesforce', 'hardware_label': 'A40 48GB', 'pricing_tier': 'supported', 'access': 'open', 'num_parameters': 16000000000, 'release_date': '2022-03-25T00:00:00.000Z', 'show_in_playground': True, 'isFeaturedModel': False, 'context_length': 2048, 'config': {'stop': ['\\n\\n'], 'chat_template_name': 'gpt'}, 'pricing': {'input': 75, 'output': 75, 'hourly': 0}, 'created_at': '2023-06-23T20:22:44.453Z', 'update_at': '2023-06-23T20:22:44.453Z', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '649e1ccca073332e47742415', 'name': 'togethercomputer/replit-code-v1-3b', 'display_name': 'Replit-Code-v1 (3B)', 'display_type': 'code', 'description': 'replit-code-v1-3b is a 2.7B Causal Language Model focused on Code Completion. The model has been trained on a subset of the Stack Dedup v1.2 dataset.', 'license': '', 'link': '', 'creator_organization': 'Replit', 'hardware_label': 'A40 48GB', 'pricing_tier': 'featured', 'access': 'limited', 'num_parameters': 3000000000, 'release_date': '2023-04-26T00:00:00.000Z', 'show_in_playground': 'true', 'isFeaturedModel': False, 'pricing': {'input': 25, 'output': 25, 'hourly': 0}, 'created_at': '2023-06-30T00:07:40.594Z', 'update_at': '2023-07-07T20:09:09.965Z', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64aceada227f790586239d11', 'name': 'togethercomputer/mpt-7b', 'display_name': 'MPT (7B)', 'display_type': 'language', 'description': 'Decoder-style transformer pretrained from scratch on 1T tokens of English text and code.', 'license': '', 'link': '', 'creator_organization': 'Mosaic ML', 'hardware_label': 'A40 48GB', 'pricing_tier': 'supported', 'access': 'open', 'num_parameters': 7000000000, 'show_in_playground': True, 'isFeaturedModel': False, 'config': {'stop': ['<|endoftext|>'], 'chat_template_name': 'default', 'add_generation_prompt': True}, 'pricing': {'input': 50, 'output': 50, 'hourly': 0}, 'created_at': '2023-07-11T05:38:34.852Z', 'update_at': '2023-07-15T03:06:20.780Z', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64aceb0e227f790586239d12', 'name': 'togethercomputer/mpt-30b-chat', 'display_name': 'MPT-Chat (30B)', 'display_type': 'chat', 'description': 'Chat model for dialogue generation finetuned on ShareGPT-Vicuna, Camel-AI, GPTeacher, Guanaco, Baize and some generated datasets.', 'license': '', 'link': '', 'creator_organization': 'Mosaic ML', 'hardware_label': 'A100 80GB', 'pricing_tier': 'supported', 'access': 'open', 'num_parameters': 30000000000, 'show_in_playground': True, 'isFeaturedModel': False, 'context_length': 2048, 'config': {'stop': ['<|im_end|>'], 'prompt_format': '<|im_start|>user\\n{prompt}<|im_end|>\\n<|im_start|>assistant', 'chat_template_name': 'default', 'add_generation_prompt': True}, 'pricing': {'input': 200, 'output': 200, 'hourly': 0}, 'created_at': '2023-07-11T05:39:26.078Z', 'update_at': '2023-07-11T05:39:26.078Z', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '6495ff1212907e072b8aecc5', 'name': 'google/flan-t5-xxl', 'display_name': 'Flan T5 XXL (11B)', 'display_type': 'language', 'description': 'Flan T5 XXL (11B parameters) is T5 fine-tuned on 1.8K tasks ([paper](https://arxiv.org/pdf/2210.11416.pdf)).', 'creator_organization': 'Google', 'hardware_label': 'A40 48GB', 'access': 'open', 'show_in_playground': True, 'isFeaturedModel': False, 'config': {'chat_template_name': 'default'}, 'pricing': {'input': 25, 'output': 25, 'hourly': 0}, 'created_at': '2023-06-23T20:22:42.261Z', 'update_at': '2023-09-01T14:35:00.161Z', 'license': '', 'link': '', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64ace6df227f790586239cfc', 'name': 'google/flan-t5-xl', 'display_name': 'Flan T5 XL (3B)', 'display_type': 'language', 'description': 'T5 fine-tuned on more than 1000 additional tasks covering also more languages, making it better than T5 at majority of tasks. ', 'license': '', 'link': '', 'creator_organization': 'Google', 'hardware_label': 'A40 48GB', 'pricing_tier': 'featured', 'access': 'open', 'num_parameters': 3000000000, 'show_in_playground': True, 'isFeaturedModel': False, 'config': {'chat_template_name': 'default'}, 'pricing': {'input': 25, 'output': 25, 'hourly': 0}, 'created_at': '2023-06-23T20:22:42.261Z', 'update_at': '2023-06-23T20:22:42.261Z', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64aceb6f227f790586239d15', 'name': 'togethercomputer/mpt-7b-instruct', 'display_name': 'MPT-Instruct (7B)', 'display_type': 'language', 'description': 'Designed for short-form instruction following, finetuned on Dolly and Anthropic HH-RLHF and other datasets', 'license': '', 'link': '', 'creator_organization': 'Mosaic ML', 'hardware_label': 'A40 48GB', 'pricing_tier': 'supported', 'access': 'open', 'num_parameters': 7000000000, 'show_in_playground': True, 'isFeaturedModel': False, 'config': {'stop': ['<|endoftext|>'], 'chat_template_name': 'default', 'add_generation_prompt': True}, 'pricing': {'input': 50, 'output': 50, 'hourly': 0}, 'created_at': '2023-07-11T05:41:03.757Z', 'update_at': '2023-07-11T05:41:03.757Z', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64acebe0227f790586239d17', 'name': 'NumbersStation/nsql-6B', 'display_name': 'NSQL (6B)', 'display_type': 'language', 'description': 'Foundation model designed specifically for SQL generation tasks. Pre-trained for 3 epochs and fine-tuned for 10 epochs.', 'license': '', 'creator_organization': 'Numbers Station', 'hardware_label': 'A40 48GB', 'pricing_tier': 'supported', 'access': 'open', 'num_parameters': 6000000000, 'show_in_playground': True, 'isFeaturedModel': False, 'config': {'stop': ['<|endoftext|>'], 'chat_template_name': 'default'}, 'pricing': {'input': 50, 'output': 50, 'hourly': 0}, 'created_at': '2023-07-11T05:42:56.540Z', 'update_at': '2023-07-11T05:42:56.540Z', 'link': '', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64ace9ca227f790586239d09', 'name': 'togethercomputer/Koala-7B', 'display_name': 'Koala (7B)', 'display_type': 'chat', 'description': 'Chatbot trained by fine-tuning LLaMA on dialogue data gathered from the web.', 'license': '', 'link': '', 'creator_organization': 'LM Sys', 'hardware_label': 'A40 48GB', 'pricing_tier': 'featured', 'access': 'open', 'num_parameters': 7000000000, 'show_in_playground': True, 'isFeaturedModel': False, 'config': {'stop': ['</s>'], 'prompt_format': 'USER: {prompt} GPT:', 'chat_template': \"{% for message in messages %}{% if message['role'] == 'user' %}{{ 'USER: ' + message['content'] + ' ' }}{% else %}{{ 'GPT: ' + message['content'] + '\\n' }}{% endif %}{% endfor %}{{ 'GPT:' }}\"}, 'pricing': {'input': 50, 'output': 50, 'hourly': 0}, 'created_at': '2023-07-11T05:34:02.521Z', 'update_at': '2023-07-11T05:34:02.521Z', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '6495ff1212907e072b8aecc0', 'name': 'EleutherAI/pythia-6.9b', 'display_name': 'Pythia (6.9B)', 'display_type': 'language', 'description': 'The Pythia Scaling Suite is a collection of models developed to facilitate interpretability research.', 'license': '', 'creator_organization': 'EleutherAI', 'hardware_label': 'A40 48GB', 'pricing_tier': 'featured', 'num_parameters': 6900000000, 'show_in_playground': True, 'isFeaturedModel': False, 'context_length': 2048, 'config': {'stop': ['<|endoftext|>'], 'chat_template_name': 'gpt'}, 'pricing': {'input': 50, 'output': 50, 'hourly': 0}, 'created_at': '2023-06-23T20:22:42.044Z', 'update_at': '2023-06-23T20:22:42.044Z', 'access': '', 'link': '', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '6495ff1112907e072b8aecb8', 'name': 'databricks/dolly-v2-12b', 'display_name': 'Dolly v2 (12B)', 'display_type': 'chat', 'description': 'An instruction-following LLM based on pythia-12b, and trained on ~15k instruction/response fine tuning records generated by Databricks employees.', 'license': '', 'link': '', 'creator_organization': 'Databricks', 'hardware_label': 'A40 48GB', 'pricing_tier': 'supported', 'num_parameters': 12000000000, 'show_in_playground': True, 'isFeaturedModel': False, 'context_length': 2048, 'config': {'stop': ['### End'], 'prompt_format': '### Instruction:\\n{prompt}\\n### Response:', 'chat_template': \"{% for message in messages %}{% if message['role'] == 'user' %}{{ '### Instruction:\\n' + message['content'] + '\\n' }}{% else %}{{ '### Response:\\n' + message['content'] + '\\n' }}{% endif %}{% endfor %}{{ '### Response:' }}\"}, 'pricing': {'input': 75, 'output': 75, 'hourly': 0}, 'created_at': '2023-06-23T20:22:41.607Z', 'update_at': '2023-06-23T20:22:41.607Z', 'access': '', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '6495ff1112907e072b8aecb6', 'name': 'databricks/dolly-v2-3b', 'display_name': 'Dolly v2 (3B)', 'display_type': 'chat', 'description': 'An instruction-following LLM based on pythia-3b, and trained on ~15k instruction/response fine tuning records generated by Databricks employees.', 'license': '', 'link': '', 'creator_organization': 'Databricks', 'hardware_label': 'A40 48GB', 'pricing_tier': 'supported', 'num_parameters': 3000000000, 'show_in_playground': True, 'isFeaturedModel': False, 'context_length': 2048, 'config': {'stop': ['### End'], 'prompt_format': '### Instruction:\\n{prompt}\\n### Response:', 'chat_template': \"{% for message in messages %}{% if message['role'] == 'user' %}{{ '### Instruction:\\n' + message['content'] + '\\n' }}{% else %}{{ '### Response:\\n' + message['content'] + '\\n' }}{% endif %}{% endfor %}{{ '### Response:' }}\"}, 'pricing': {'input': 25, 'output': 25, 'hourly': 0}, 'created_at': '2023-06-23T20:22:41.524Z', 'update_at': '2023-06-23T20:22:41.524Z', 'access': '', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '6495ff1212907e072b8aecc2', 'name': 'EleutherAI/gpt-neox-20b', 'display_name': 'GPT-NeoX (20B)', 'display_type': 'language', 'description': 'Autoregressive language model trained on the Pile. Its architecture intentionally resembles that of GPT-3, and is almost identical to that of GPT-J 6B.', 'license': '', 'link': '', 'creator_organization': 'EleutherAI', 'hardware_label': 'A40 48GB', 'pricing_tier': 'supported', 'num_parameters': 20000000000, 'show_in_playground': True, 'isFeaturedModel': False, 'config': {'chat_template_name': 'gpt'}, 'pricing': {'input': 75, 'output': 75, 'hourly': 0}, 'created_at': '2023-06-23T20:22:42.132Z', 'update_at': '2023-06-23T20:22:42.132Z', 'access': '', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '6495ff1112907e072b8aecbf', 'name': 'EleutherAI/pythia-2.8b-v0', 'display_name': 'Pythia (2.8B)', 'display_type': 'language', 'description': 'The Pythia Scaling Suite is a collection of models developed to facilitate interpretability research.', 'license': '', 'creator_organization': 'EleutherAI', 'hardware_label': 'A40 48GB', 'num_parameters': 2800000000, 'show_in_playground': True, 'isFeaturedModel': False, 'context_length': 2048, 'config': {'stop': ['<|endoftext|>'], 'chat_template_name': 'gpt'}, 'pricing': {'input': 25, 'output': 25, 'hourly': 0}, 'created_at': '2023-06-23T20:22:41.975Z', 'update_at': '2023-06-23T20:22:41.975Z', 'access': '', 'link': '', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64acebb2227f790586239d16', 'name': 'NousResearch/Nous-Hermes-13b', 'display_name': 'Nous Hermes (13B)', 'display_type': 'language', 'description': 'LLaMA 13B fine-tuned on over 300,000 instructions. Designed for long responses, low hallucination rate, and absence of censorship mechanisms.', 'license': '', 'link': '', 'creator_organization': 'Nous Research', 'hardware_label': 'A40 48GB', 'pricing_tier': 'supported', 'access': 'open', 'num_parameters': 13000000000, 'show_in_playground': True, 'isFeaturedModel': False, 'context_length': 2048, 'config': {'chat_template_name': 'llama', 'chat_template': \"{% for message in messages %}{% if message['role'] == 'user' %}{{ '### Instruction:\\n' + message['content'] + '\\n' }}{% else %}{{ '### Response:\\n' + message['content'] + '\\n' }}{% endif %}{% endfor %}{{ '### Response:\\n' }}\"}, 'pricing': {'input': 75, 'output': 75, 'hourly': 0}, 'created_at': '2023-07-11T05:42:10.444Z', 'update_at': '2023-07-11T05:42:10.444Z', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64ace8d1227f790586239d03', 'name': 'togethercomputer/guanaco-65b', 'display_name': 'Guanaco (65B) ', 'display_type': 'chat', 'description': 'Instruction-following language model built on LLaMA. Expanding upon the initial 52K dataset from the Alpaca model, an additional 534,530 focused on multi-lingual tasks.', 'license': '', 'link': '', 'creator_organization': 'Tim Dettmers', 'hardware_label': '2X A100 80GB', 'pricing_tier': 'Supported', 'access': 'open', 'num_parameters': 65000000000, 'show_in_playground': True, 'isFeaturedModel': False, 'context_length': 2048, 'config': {'stop': ['###'], 'prompt_format': '### Human: {prompt} ### Assistant:', 'chat_template': \"{% for message in messages %}{% if message['role'] == 'user' %}{{ '### Human: ' + message['content'] + ' ' }}{% else %}{{ '### Assistant: ' + message['content'] + '\\n' }}{% endif %}{% endfor %}{{ '### Assistant:' }}\"}, 'pricing': {'input': 225, 'output': 225, 'hourly': 0}, 'created_at': '2023-07-11T05:29:53.740Z', 'update_at': '2023-07-11T05:29:53.740Z', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64acec99227f790586239d1c', 'name': 'OpenAssistant/oasst-sft-6-llama-30b-xor', 'display_name': 'Open-Assistant LLaMA SFT-6 (30B)', 'display_type': 'chat', 'description': 'Chat-based and open-source assistant. The vision of the project is to make a large language model that can run on a single high-end consumer GPU. ', 'license': '', 'link': '', 'creator_organization': 'LAION', 'hardware_label': 'A100 80GB', 'pricing_tier': 'supported', 'show_in_playground': True, 'isFeaturedModel': False, 'config': {'stop': ['<|endoftext|>'], 'prompt_format': '<|prompter|>{prompt}<|endoftext|><|assistant|>', 'chat_template': \"{% for message in messages %}{% if message['role'] == 'user' %}{{ '<|prompter|>' + message['content'] + '<|endoftext|>' }}{% else %}{{ '<|assistant|>' + message['content'] + '<|endoftext|>\\n' }}{% endif %}{% endfor %}{{ '<|assistant|>' }}\"}, 'pricing': {'input': 25, 'output': 25, 'hourly': 0}, 'created_at': '2023-06-23T20:22:42.469Z', 'update_at': '2023-06-23T20:22:42.469Z', 'access': '', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64ace955227f790586239d06', 'name': 'Salesforce/instructcodet5p-16b', 'display_name': 'InstructCodeT5 (16B)', 'display_type': 'chat', 'description': 'Code large language model that can flexibly operate in different modes to support a wide range of code understanding and generation tasks. ', 'license': '', 'link': '', 'creator_organization': 'Salesforce', 'hardware_label': 'A40 48GB', 'pricing_tier': 'supported', 'access': 'open', 'num_parameters': 33000000000, 'show_in_playground': True, 'isFeaturedModel': False, 'config': {'chat_template_name': 'default'}, 'pricing': {'input': 200, 'output': 200, 'hourly': 0}, 'created_at': '2023-07-11T05:32:05.369Z', 'update_at': '2023-07-11T05:32:05.369Z', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64acf031227f790586239d44', 'name': 'lmsys/fastchat-t5-3b-v1.0', 'display_name': 'Vicuna-FastChat-T5 (3B)', 'display_type': 'chat', 'description': 'Chatbot trained by fine-tuning Flan-t5-xl on user-shared conversations collected from ShareGPT.', 'license': '', 'link': '', 'creator_organization': 'LM Sys', 'hardware_label': 'A40 48GB', 'pricing_tier': 'featured', 'num_parameters': 3000000000, 'show_in_playground': True, 'isFeaturedModel': False, 'context_length': 512, 'config': {'stop': ['###', '</s>'], 'prompt_format': '### Human: {prompt}\\n### Assistant:', 'chat_template': \"{% for message in messages %}{% if message['role'] == 'user' %}{{ '### Human: ' + message['content'] + '\\n' }}{% else %}{{ '### Assistant: ' + message['content'] + '\\n' }}{% endif %}{% endfor %}{{ '### Assistant:' }}\"}, 'pricing': {'input': 25, 'output': 25, 'hourly': 0}, 'created_at': '2023-07-11T06:01:21.713Z', 'update_at': '2023-07-11T06:01:21.713Z', 'access': '', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64acea6e227f790586239d0e', 'name': 'huggyllama/llama-7b', 'display_name': 'LLaMA (7B)', 'display_type': 'language', 'description': 'An auto-regressive language model, based on the transformer architecture. The model comes in different sizes: 7B, 13B, 33B and 65B parameters.', 'license': '', 'link': '', 'creator_organization': 'Meta', 'hardware_label': 'A100 80GB', 'pricing_tier': 'supported', 'access': 'open', 'num_parameters': 7000000000, 'show_in_playground': True, 'isFeaturedModel': False, 'context_length': 2048, 'config': {'chat_template_name': 'llama'}, 'pricing': {'input': 50, 'output': 50, 'hourly': 0}, 'created_at': '2023-07-11T05:36:46.255Z', 'update_at': '2023-07-11T05:36:46.255Z', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '6495ff1212907e072b8aecc9', 'name': 'OpenAssistant/stablelm-7b-sft-v7-epoch-3', 'display_name': 'Open-Assistant StableLM SFT-7 (7B)', 'display_type': 'chat', 'description': 'Chat-based and open-source assistant. The vision of the project is to make a large language model that can run on a single high-end consumer GPU. ', 'license': '', 'link': '', 'creator_organization': 'LAION', 'hardware_label': 'A40 48GB', 'pricing_tier': 'supported', 'num_parameters': 7000000000, 'show_in_playground': True, 'isFeaturedModel': False, 'context_length': 4096, 'config': {'stop': ['<|endoftext|>'], 'prompt_format': '<|prompter|>{prompt}<|endoftext|><|assistant|>', 'chat_template': \"{% for message in messages %}{% if message['role'] == 'user' %}{{ '<|prompter|>' + message['content'] + '<|endoftext|>' }}{% else %}{{ '<|assistant|>' + message['content'] + '<|endoftext|>\\n' }}{% endif %}{% endfor %}{{ '<|assistant|>' }}\"}, 'pricing': {'input': 50, 'output': 50, 'hourly': 0}, 'created_at': '2023-06-23T20:22:42.425Z', 'update_at': '2023-06-23T20:22:42.425Z', 'access': '', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '6495ff1212907e072b8aecc1', 'name': 'EleutherAI/pythia-12b-v0', 'display_name': 'Pythia (12B)', 'display_type': 'language', 'description': 'The Pythia Scaling Suite is a collection of models developed to facilitate interpretability research.', 'license': '', 'link': '', 'creator_organization': 'EleutherAI', 'hardware_label': 'A40 48GB', 'pricing_tier': 'supported', 'num_parameters': 12000000000, 'show_in_playground': True, 'isFeaturedModel': False, 'context_length': 2048, 'config': {'stop': ['<|endoftext|>'], 'chat_template_name': 'gpt'}, 'pricing': {'input': 75, 'output': 75, 'hourly': 0}, 'created_at': '2023-06-23T20:22:42.091Z', 'update_at': '2023-06-23T20:22:42.091Z', 'access': '', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64aceb28227f790586239d13', 'name': 'togethercomputer/mpt-7b-chat', 'display_name': 'MPT-Chat (7B)', 'display_type': 'chat', 'description': 'Chat model for dialogue generation finetuned on ShareGPT-Vicuna, Camel-AI, GPTeacher, Guanaco, Baize and some generated datasets.', 'license': '', 'link': '', 'creator_organization': 'Mosaic ML', 'hardware_label': 'A40 48GB', 'pricing_tier': 'supported', 'access': 'open', 'num_parameters': 7000000000, 'show_in_playground': True, 'isFeaturedModel': False, 'context_length': 2048, 'config': {'stop': ['<|im_end|>'], 'prompt_format': '<|im_start|>user\\n{prompt}<|im_end|>\\n<|im_start|>assistant', 'chat_template_name': 'default', 'add_generation_prompt': True}, 'pricing': {'input': 50, 'output': 50, 'hourly': 0}, 'created_at': '2023-07-11T05:39:52.024Z', 'update_at': '2023-07-11T05:39:52.024Z', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '6495ff1212907e072b8aecc8', 'name': 'OpenAssistant/oasst-sft-4-pythia-12b-epoch-3.5', 'display_name': 'Open-Assistant Pythia SFT-4 (12B)', 'display_type': 'chat', 'description': 'Chat-based and open-source assistant. The vision of the project is to make a large language model that can run on a single high-end consumer GPU. ', 'license': '', 'link': '', 'creator_organization': 'LAION', 'hardware_label': 'A40 48GB', 'pricing_tier': 'supported', 'num_parameters': 12000000000, 'show_in_playground': True, 'isFeaturedModel': False, 'context_length': 2048, 'config': {'stop': ['<|endoftext|>'], 'prompt_format': '<|prompter|>{prompt}<|endoftext|><|assistant|>', 'chat_template': \"{% for message in messages %}{% if message['role'] == 'user' %}{{ '<|prompter|>' + message['content'] + '<|endoftext|>' }}{% else %}{{ '<|assistant|>' + message['content'] + '<|endoftext|>\\n' }}{% endif %}{% endfor %}{{ '<|assistant|>' }}\"}, 'pricing': {'input': 75, 'output': 75, 'hourly': 0}, 'created_at': '2023-06-23T20:22:42.383Z', 'update_at': '2023-06-23T20:22:42.383Z', 'access': '', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '6495ff1112907e072b8aecbc', 'name': 'EleutherAI/gpt-j-6b', 'display_name': 'GPT-J (6B)', 'display_type': 'language', 'description': \"Transformer model trained using Ben Wang's Mesh Transformer JAX. \", 'license': '', 'link': '', 'creator_organization': 'EleutherAI', 'hardware_label': 'A40 48GB', 'pricing_tier': 'supported', 'access': 'open', 'num_parameters': 6000000000, 'release_date': '2021-06-04T00:00:00.000Z', 'show_in_playground': True, 'isFeaturedModel': False, 'config': {'chat_template_name': 'gpt'}, 'pricing': {'input': 50, 'output': 50, 'hourly': 0}, 'created_at': '2023-06-23T20:22:41.831Z', 'update_at': '2023-06-23T20:22:41.831Z', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64acf013227f790586239d43', 'name': 'lmsys/vicuna-7b-v1.3', 'display_name': 'Vicuna v1.3 (7B)', 'display_type': 'chat', 'description': 'Chatbot trained by fine-tuning LLaMA on user-shared conversations collected from ShareGPT. Auto-regressive model, based on the transformer architecture.', 'license': '', 'link': '', 'creator_organization': 'LM Sys', 'hardware_label': 'A40 48GB', 'pricing_tier': 'supported', 'access': 'open', 'num_parameters': 7000000000, 'show_in_playground': True, 'isFeaturedModel': False, 'context_length': 2048, 'config': {'stop': ['</s>'], 'prompt_format': 'USER: {prompt}\\nASSISTANT:', 'chat_template': \"{% for message in messages %}{{message['role'].toLocaleUpperCase() + ': ' + message['content'] + '\\n'}}{% endfor %}{{ 'ASSISTANT:' }}\"}, 'pricing': {'input': 50, 'output': 50, 'hourly': 0}, 'created_at': '2023-07-11T06:00:51.553Z', 'update_at': '2023-07-11T06:00:51.553Z', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64ace476227f790586239cef', 'name': 'togethercomputer/codegen2-7B', 'display_name': 'CodeGen2 (7B)', 'display_type': 'code', 'description': 'An autoregressive language models for program synthesis.', 'license': '', 'link': '', 'creator_organization': 'Salesforce', 'hardware_label': 'A40 48GB', 'pricing_tier': 'supported', 'access': 'open', 'num_parameters': 7000000000, 'release_date': '2022-03-25T00:00:00.000Z', 'show_in_playground': True, 'isFeaturedModel': False, 'context_length': 2048, 'config': {'stop': ['\\n\\n'], 'chat_template_name': 'gpt'}, 'pricing': {'input': 50, 'output': 50, 'hourly': 0}, 'created_at': '2023-07-11T05:11:18.328Z', 'update_at': '2023-07-11T05:11:18.328Z', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64f0de22caa9e2eb543b373b', 'name': 'togethercomputer/guanaco-13b', 'display_name': 'Guanaco (13B) ', 'display_type': 'chat', 'description': 'Instruction-following language model built on LLaMA. Expanding upon the initial 52K dataset from the Alpaca model, an additional 534,530 focused on multi-lingual tasks.', 'license': '', 'link': '', 'creator_organization': 'Tim Dettmers', 'hardware_label': 'A40 48GB', 'pricing_tier': 'Supported', 'access': 'open', 'num_parameters': 13000000000, 'show_in_playground': True, 'isFeaturedModel': False, 'context_length': 2048, 'config': {'stop': ['###'], 'prompt_format': '### Human: {prompt} ### Assistant:', 'chat_template': \"{% for message in messages %}{% if message['role'] == 'user' %}{{ '### Human: ' + message['content'] + ' ' }}{% else %}{{ '### Assistant: ' + message['content'] + '\\n' }}{% endif %}{% endfor %}{{ '### Assistant:' }}\"}, 'pricing': {'input': 75, 'output': 75, 'hourly': 0}, 'created_at': '2023-07-11T05:29:07.717Z', 'update_at': '2023-07-11T05:29:07.717Z', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64acefe5227f790586239d41', 'name': 'lmsys/vicuna-13b-v1.3', 'display_name': 'Vicuna v1.3 (13B)', 'display_type': 'chat', 'description': 'Chatbot trained by fine-tuning LLaMA on user-shared conversations collected from ShareGPT. Auto-regressive model, based on the transformer architecture.', 'license': '', 'link': '', 'creator_organization': 'LM Sys', 'hardware_label': 'A40 48GB', 'pricing_tier': 'supported', 'access': 'open', 'num_parameters': 13000000000, 'show_in_playground': True, 'isFeaturedModel': False, 'context_length': 2048, 'config': {'stop': ['</s>'], 'prompt_format': 'USER: {prompt}\\nASSISTANT:', 'chat_template': \"{% for message in messages %}{{message['role'].toLocaleUpperCase() + ': ' + message['content'] + '\\n'}}{% endfor %}{{ 'ASSISTANT:' }}\"}, 'pricing': {'input': 75, 'output': 75, 'hourly': 0}, 'created_at': '2023-07-11T06:00:05.166Z', 'update_at': '2023-07-15T03:08:44.173Z', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64acea0b227f790586239d0b', 'name': 'huggyllama/llama-13b', 'display_name': 'LLaMA (13B)', 'display_type': 'language', 'description': 'An auto-regressive language model, based on the transformer architecture. The model comes in different sizes: 7B, 13B, 33B and 65B parameters.', 'license': '', 'link': '', 'creator_organization': 'Meta', 'hardware_label': 'A100 80GB', 'pricing_tier': 'supported', 'access': 'open', 'num_parameters': 13000000000, 'show_in_playground': True, 'isFeaturedModel': False, 'context_length': 2048, 'config': {'chat_template_name': 'llama'}, 'pricing': {'input': 75, 'output': 75, 'hourly': 0}, 'created_at': '2023-07-11T05:35:07.955Z', 'update_at': '2023-07-11T05:35:07.955Z', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64acefbe227f790586239d40', 'name': 'HuggingFaceH4/starchat-alpha', 'display_name': 'StarCoderChat Alpha (16B)', 'display_type': 'chat', 'description': 'Fine-tuned from StarCoder to act as a helpful coding assistant. As an alpha release is only intended for educational or research purpopses.', 'license': '', 'link': '', 'creator_organization': 'HuggingFaceH4', 'hardware_label': 'A40 48GB', 'pricing_tier': 'supported', 'num_parameters': 16000000000, 'show_in_playground': True, 'isFeaturedModel': False, 'context_length': 8192, 'config': {'stop': ['<|endoftext|>', '<|end|>'], 'prompt_format': '<|system|>\\n<|end|>\\n<|user|>\\n{prompt}<|end|>\\n<|assistant|>', 'chat_template_name': 'default'}, 'pricing': {'input': 75, 'output': 75, 'hourly': 0}, 'created_at': '2023-07-11T05:59:26.298Z', 'update_at': '2023-07-11T05:59:26.298Z', 'access': '', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64acea35227f790586239d0c', 'name': 'huggyllama/llama-30b', 'display_name': 'LLaMA (30B)', 'display_type': 'language', 'description': 'An auto-regressive language model, based on the transformer architecture. The model comes in different sizes: 7B, 13B, 33B and 65B parameters.', 'license': '', 'link': '', 'creator_organization': 'Meta', 'hardware_label': 'A100 80GB', 'access': 'open', 'num_parameters': 33000000000, 'show_in_playground': True, 'isFeaturedModel': False, 'context_length': 2048, 'config': {'chat_template_name': 'llama'}, 'pricing': {'input': 200, 'output': 200, 'hourly': 0}, 'created_at': '2023-07-11T05:35:49.870Z', 'update_at': '2023-07-11T05:35:49.870Z', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '6495ff1512907e072b8aecf5', 'name': 'stabilityai/stablelm-base-alpha-7b', 'display_name': 'StableLM-Base-Alpha (7B)', 'display_type': 'language', 'description': 'Decoder-only language model pre-trained on a diverse collection of English and Code datasets with a sequence length of 4096.', 'license': '', 'link': '', 'creator_organization': 'Stability AI', 'hardware_label': 'A40 48GB', 'pricing_tier': 'supported', 'num_parameters': 7000000000, 'show_in_playground': True, 'isFeaturedModel': False, 'config': {'chat_template_name': 'gpt'}, 'pricing': {'input': 50, 'output': 50, 'hourly': 0}, 'created_at': '2023-06-23T20:22:45.249Z', 'update_at': '2023-06-23T20:22:45.249Z', 'access': '', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '6495ff1412907e072b8aecf4', 'name': 'stabilityai/stablelm-base-alpha-3b', 'display_name': 'StableLM-Base-Alpha (3B)', 'display_type': 'language', 'description': 'Decoder-only language model pre-trained on a diverse collection of English and Code datasets with a sequence length of 4096.', 'license': '', 'link': '', 'creator_organization': 'Stability AI', 'hardware_label': 'A40 48GB', 'pricing_tier': 'supported', 'num_parameters': 3000000000, 'show_in_playground': True, 'isFeaturedModel': False, 'config': {'chat_template_name': 'gpt'}, 'pricing': {'input': 25, 'output': 25, 'hourly': 0}, 'created_at': '2023-06-23T20:22:44.907Z', 'update_at': '2023-06-23T20:22:44.907Z', 'access': '', 'descriptionLink': ''}, {'modelInstanceConfig': {'appearsIn': [], 'order': 0}, '_id': '64f67987bc372ce719b97f07', 'name': 'defog/sqlcoder', 'display_name': 'Sqlcoder (15B)', 'display_type': 'language', 'description': \"Defog's SQLCoder is a state-of-the-art LLM for converting natural language questions to SQL queries, fine-tuned from Bigcode's Starcoder 15B model.\", 'license': '', 'creator_organization': 'Defog', 'hardware_label': 'A40 48GB', 'pricing_tier': 'supported', 'access': 'open', 'num_parameters': 15000000000, 'show_in_playground': True, 'isFeaturedModel': False, 'context_length': 8192, 'config': {'stop': ['<|endoftext|>'], 'prompt_format': '### Instructions:\\n\\n{prompt}\\n\\n### Response:\\n'}, 'pricing': {'input': 75, 'output': 75, 'hourly': 0}, 'created_at': '2023-09-05T00:42:47.496Z', 'update_at': '2023-09-05T00:42:47.496Z', 'link': '', 'descriptionLink': ''}]\n",
      "117 models available\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import json\n",
    "import together\n",
    "from apikey import TOG_KEY\n",
    "\n",
    "OLD_HAN_PATH = './trainingdata/hansolo/old-han-data.jsonl'\n",
    "# PROTECTED_PATH = './trainingdata/hansolo/young-han-protective-new.jsonl'\n",
    "\n",
    "together.api_key = TOG_KEY\n",
    "\n",
    "model_list = together.Models.list()\n",
    "print(model_list[:-5])\n",
    "\n",
    "print(f\"{len(model_list)} models available\")\n",
    "\n",
    "# print the first 10 models on the menu\n",
    "# model_names = [model_dict['name'] for model_dict in model_list]\n",
    "# print(model_names[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading ./trainingdata/hansolo/old-han-data.jsonl: 100%|| 2.79M/2.79M [00:00<00:00, 3.09MB/s]\n"
     ]
    }
   ],
   "source": [
    "resp = together.Files.upload(file=OLD_HAN_PATH)\n",
    "file_id = resp[\"id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'filename': 'young-han-data-new.jsonl',\n",
       "  'bytes': 948468,\n",
       "  'created_at': 1700686846,\n",
       "  'id': 'file-10d2233d-0f67-4457-9baa-59ef5c874dac',\n",
       "  'purpose': 'fine-tune',\n",
       "  'object': 'file',\n",
       "  'LineCount': 0,\n",
       "  'Processed': True},\n",
       " {'filename': 'han-data.jsonl',\n",
       "  'bytes': 2208884,\n",
       "  'created_at': 1700805318,\n",
       "  'id': 'file-5350fa6b-2ad1-4a4d-8717-fcb1522be037',\n",
       "  'purpose': 'fine-tune',\n",
       "  'object': 'file',\n",
       "  'LineCount': 0,\n",
       "  'Processed': True},\n",
       " {'filename': 'old-han-data.jsonl',\n",
       "  'bytes': 2920963,\n",
       "  'created_at': 1700949437,\n",
       "  'id': 'file-04c71832-ca56-45de-81af-483b42b70b7b',\n",
       "  'purpose': 'fine-tune',\n",
       "  'object': 'file',\n",
       "  'LineCount': 0,\n",
       "  'Processed': True}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files_list = together.Files.list()\n",
    "files_list['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'file-bb280f38-2b64-42a9-9349-6e7eb2ad2d05',\n",
       " 'object': 'file',\n",
       " 'deleted': 'true'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "together.Files.delete('file-bb280f38-2b64-42a9-9349-6e7eb2ad2d05')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'training_file': 'file-5350fa6b-2ad1-4a4d-8717-fcb1522be037', 'validation_file': '', 'model_output_name': 'mifu67@stanford.edu/llama-2-7b-chat-middle-han-second-10--1e-05-2023-11-29-06-01-02', 'model_output_path': 's3://together-dev/finetune/6552b4a556bb2d3952ed7a14/mifu67@stanford.edu/llama-2-7b-chat-middle-han-second-10--1e-05-2023-11-29-06-01-02/ft-1c17315c-eebb-47a8-bdd9-f76272bb05ce', 'Suffix': 'middle-han-second-10--1e-05', 'model': 'togethercomputer/llama-2-7b-chat', 'n_epochs': 10, 'n_checkpoints': 1, 'batch_size': 4, 'learning_rate': 1e-05, 'user_id': '6552b4a556bb2d3952ed7a14', 'lora': False, 'lora_r': 8, 'lora_alpha': 8, 'lora_dropout': 0, 'staring_epoch': 0, 'training_offset': 0, 'checkspoint_path': '', 'random_seed': '', 'created_at': '2023-11-29T06:01:02.988Z', 'updated_at': '2023-11-29T06:01:02.988Z', 'status': 'pending', 'owner_address': '0xebd597774b313d8e8d22af4629b75ec7d567f678', 'id': 'ft-1c17315c-eebb-47a8-bdd9-f76272bb05ce', 'job_id': '', 'token_count': 0, 'param_count': 0, 'total_price': 0, 'epochs_completed': 0, 'events': [{'object': 'fine-tune-event', 'created_at': '2023-11-29T06:01:02.988Z', 'level': '', 'message': 'Fine tune request created', 'type': 'JOB_PENDING', 'param_count': 0, 'token_count': 0, 'wandb_url': '', 'checkpoint_path': '', 'model_path': '', 'training_offset': 0, 'hash': ''}], 'queue_depth': 0, 'wandb_key': '', 'wandb_project_name': '', 'wandb_url': '', 'enable_checkpoints': False, 'internal_flags': ''}\n"
     ]
    }
   ],
   "source": [
    "n_ep = 10\n",
    "lr = 1e-5\n",
    "\n",
    "resp = together.Finetune.create(\n",
    "  training_file = 'file-5350fa6b-2ad1-4a4d-8717-fcb1522be037',\n",
    "  model = 'togethercomputer/llama-2-7b-chat',\n",
    "  n_epochs = n_ep,\n",
    "  n_checkpoints = 1,\n",
    "  batch_size = 4,\n",
    "  learning_rate = lr,\n",
    "  suffix = f'middle-han-second-{n_ep}--{lr}',\n",
    ")\n",
    "\n",
    "fine_tune_id = resp['id']\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'training_file': 'file-5350fa6b-2ad1-4a4d-8717-fcb1522be037',\n",
       " 'validation_file': '',\n",
       " 'model_output_name': 'mifu67@stanford.edu/llama-2-7b-chat-middle-han-second-10--1e-05-2023-11-29-06-01-02',\n",
       " 'model_output_path': 's3://together-dev/finetune/6552b4a556bb2d3952ed7a14/mifu67@stanford.edu/llama-2-7b-chat-middle-han-second-10--1e-05-2023-11-29-06-01-02/ft-1c17315c-eebb-47a8-bdd9-f76272bb05ce-2023-11-29-09-18-55',\n",
       " 'Suffix': 'middle-han-second-10--1e-05',\n",
       " 'model': 'togethercomputer/llama-2-7b-chat',\n",
       " 'n_epochs': 10,\n",
       " 'n_checkpoints': 1,\n",
       " 'batch_size': 4,\n",
       " 'learning_rate': 1e-05,\n",
       " 'user_id': '6552b4a556bb2d3952ed7a14',\n",
       " 'lora': False,\n",
       " 'lora_r': 8,\n",
       " 'lora_alpha': 8,\n",
       " 'lora_dropout': 0,\n",
       " 'staring_epoch': 0,\n",
       " 'training_offset': 0,\n",
       " 'checkspoint_path': '',\n",
       " 'random_seed': '',\n",
       " 'created_at': '2023-11-29T06:01:02.988Z',\n",
       " 'updated_at': '2023-11-29T17:22:57.957Z',\n",
       " 'status': 'completed',\n",
       " 'owner_address': '0xebd597774b313d8e8d22af4629b75ec7d567f678',\n",
       " 'id': 'ft-1c17315c-eebb-47a8-bdd9-f76272bb05ce',\n",
       " 'job_id': '7049',\n",
       " 'token_count': 688510,\n",
       " 'param_count': 6738415616,\n",
       " 'total_price': 5000000000,\n",
       " 'epochs_completed': 10,\n",
       " 'events': [{'object': 'fine-tune-event',\n",
       "   'created_at': '2023-11-29T06:01:02.988Z',\n",
       "   'level': '',\n",
       "   'message': 'Fine tune request created',\n",
       "   'type': 'JOB_PENDING',\n",
       "   'param_count': 0,\n",
       "   'token_count': 0,\n",
       "   'wandb_url': '',\n",
       "   'checkpoint_path': '',\n",
       "   'model_path': '',\n",
       "   'training_offset': 0,\n",
       "   'hash': ''},\n",
       "  {'object': 'fine-tune-event',\n",
       "   'created_at': '2023-11-29T17:00:54.578Z',\n",
       "   'level': 'info',\n",
       "   'message': 'Job started at Wed Nov 29 09:00:53 PST 2023',\n",
       "   'type': 'JOB_START',\n",
       "   'param_count': 0,\n",
       "   'token_count': 0,\n",
       "   'wandb_url': '',\n",
       "   'checkpoint_path': '',\n",
       "   'model_path': '',\n",
       "   'training_offset': 0,\n",
       "   'hash': '8497730042872359476'},\n",
       "  {'object': 'fine-tune-event',\n",
       "   'created_at': '2023-11-29T17:02:13.287Z',\n",
       "   'level': 'info',\n",
       "   'message': 'Model data downloaded for togethercomputer/llama-2-7b-chat at Wed Nov 29 09:02:12 PST 2023',\n",
       "   'type': 'MODEL_DOWNLOAD_COMPLETE',\n",
       "   'param_count': 0,\n",
       "   'token_count': 0,\n",
       "   'wandb_url': '',\n",
       "   'checkpoint_path': '',\n",
       "   'model_path': '',\n",
       "   'training_offset': 0,\n",
       "   'hash': '-2941435665401099257'},\n",
       "  {'object': 'fine-tune-event',\n",
       "   'created_at': '2023-11-29T17:02:15.56Z',\n",
       "   'level': 'info',\n",
       "   'message': 'Training data downloaded for togethercomputer/llama-2-7b-chat at Wed Nov 29 09:02:14 PST 2023',\n",
       "   'type': 'TRAINING_DATA_DOWNLOAD_COMPLETE',\n",
       "   'param_count': 0,\n",
       "   'token_count': 0,\n",
       "   'wandb_url': '',\n",
       "   'checkpoint_path': '',\n",
       "   'model_path': '',\n",
       "   'training_offset': 0,\n",
       "   'hash': '4324118787525346890'},\n",
       "  {'object': 'fine-tune-event',\n",
       "   'created_at': '2023-11-29T17:02:50.141Z',\n",
       "   'level': 'info',\n",
       "   'message': 'Training started for model /work/job-ft-1c17315c-eebb-47a8-bdd9-f76272bb05ce/model',\n",
       "   'type': 'TRAINING_START',\n",
       "   'param_count': 6738415616,\n",
       "   'token_count': 688510,\n",
       "   'wandb_url': '',\n",
       "   'checkpoint_path': '',\n",
       "   'model_path': '',\n",
       "   'training_offset': 0,\n",
       "   'hash': '-5968746771653984898'},\n",
       "  {'object': 'fine-tune-event',\n",
       "   'created_at': '2023-11-29T17:04:28.68Z',\n",
       "   'level': 'info',\n",
       "   'message': 'Epoch completed, at step 43',\n",
       "   'type': 'EPOCH_COMPLETE',\n",
       "   'param_count': 0,\n",
       "   'token_count': 0,\n",
       "   'wandb_url': '',\n",
       "   'checkpoint_path': '',\n",
       "   'model_path': '',\n",
       "   'training_offset': 0,\n",
       "   'hash': '5679148464011540741'},\n",
       "  {'object': 'fine-tune-event',\n",
       "   'created_at': '2023-11-29T17:05:56.613Z',\n",
       "   'level': 'info',\n",
       "   'message': 'Epoch completed, at step 86',\n",
       "   'type': 'EPOCH_COMPLETE',\n",
       "   'param_count': 0,\n",
       "   'token_count': 0,\n",
       "   'wandb_url': '',\n",
       "   'checkpoint_path': '',\n",
       "   'model_path': '',\n",
       "   'training_offset': 0,\n",
       "   'hash': '-2207390798290669768'},\n",
       "  {'object': 'fine-tune-event',\n",
       "   'created_at': '2023-11-29T17:07:24.541Z',\n",
       "   'level': 'info',\n",
       "   'message': 'Epoch completed, at step 129',\n",
       "   'type': 'EPOCH_COMPLETE',\n",
       "   'param_count': 0,\n",
       "   'token_count': 0,\n",
       "   'wandb_url': '',\n",
       "   'checkpoint_path': '',\n",
       "   'model_path': '',\n",
       "   'training_offset': 0,\n",
       "   'hash': '-6984951409631680009'},\n",
       "  {'object': 'fine-tune-event',\n",
       "   'created_at': '2023-11-29T17:08:52.168Z',\n",
       "   'level': 'info',\n",
       "   'message': 'Epoch completed, at step 172',\n",
       "   'type': 'EPOCH_COMPLETE',\n",
       "   'param_count': 0,\n",
       "   'token_count': 0,\n",
       "   'wandb_url': '',\n",
       "   'checkpoint_path': '',\n",
       "   'model_path': '',\n",
       "   'training_offset': 0,\n",
       "   'hash': '3879409174283895094'},\n",
       "  {'object': 'fine-tune-event',\n",
       "   'created_at': '2023-11-29T17:10:20.11Z',\n",
       "   'level': 'info',\n",
       "   'message': 'Epoch completed, at step 215',\n",
       "   'type': 'EPOCH_COMPLETE',\n",
       "   'param_count': 0,\n",
       "   'token_count': 0,\n",
       "   'wandb_url': '',\n",
       "   'checkpoint_path': '',\n",
       "   'model_path': '',\n",
       "   'training_offset': 0,\n",
       "   'hash': '634904574388157497'},\n",
       "  {'object': 'fine-tune-event',\n",
       "   'created_at': '2023-11-29T17:11:47.603Z',\n",
       "   'level': 'info',\n",
       "   'message': 'Epoch completed, at step 258',\n",
       "   'type': 'EPOCH_COMPLETE',\n",
       "   'param_count': 0,\n",
       "   'token_count': 0,\n",
       "   'wandb_url': '',\n",
       "   'checkpoint_path': '',\n",
       "   'model_path': '',\n",
       "   'training_offset': 0,\n",
       "   'hash': '-6813106032989739045'},\n",
       "  {'object': 'fine-tune-event',\n",
       "   'created_at': '2023-11-29T17:13:15.526Z',\n",
       "   'level': 'info',\n",
       "   'message': 'Epoch completed, at step 301',\n",
       "   'type': 'EPOCH_COMPLETE',\n",
       "   'param_count': 0,\n",
       "   'token_count': 0,\n",
       "   'wandb_url': '',\n",
       "   'checkpoint_path': '',\n",
       "   'model_path': '',\n",
       "   'training_offset': 0,\n",
       "   'hash': '-1028324577062069189'},\n",
       "  {'object': 'fine-tune-event',\n",
       "   'created_at': '2023-11-29T17:14:43.1Z',\n",
       "   'level': 'info',\n",
       "   'message': 'Epoch completed, at step 344',\n",
       "   'type': 'EPOCH_COMPLETE',\n",
       "   'param_count': 0,\n",
       "   'token_count': 0,\n",
       "   'wandb_url': '',\n",
       "   'checkpoint_path': '',\n",
       "   'model_path': '',\n",
       "   'training_offset': 0,\n",
       "   'hash': '1332303618885735484'},\n",
       "  {'object': 'fine-tune-event',\n",
       "   'created_at': '2023-11-29T17:16:10.629Z',\n",
       "   'level': 'info',\n",
       "   'message': 'Epoch completed, at step 387',\n",
       "   'type': 'EPOCH_COMPLETE',\n",
       "   'param_count': 0,\n",
       "   'token_count': 0,\n",
       "   'wandb_url': '',\n",
       "   'checkpoint_path': '',\n",
       "   'model_path': '',\n",
       "   'training_offset': 0,\n",
       "   'hash': '-5699581631650221294'},\n",
       "  {'object': 'fine-tune-event',\n",
       "   'created_at': '2023-11-29T17:17:37.969Z',\n",
       "   'level': 'info',\n",
       "   'message': 'Epoch completed, at step 430',\n",
       "   'type': 'EPOCH_COMPLETE',\n",
       "   'param_count': 0,\n",
       "   'token_count': 0,\n",
       "   'wandb_url': '',\n",
       "   'checkpoint_path': '',\n",
       "   'model_path': '',\n",
       "   'training_offset': 0,\n",
       "   'hash': '-2702287032144578512'},\n",
       "  {'object': 'fine-tune-event',\n",
       "   'created_at': '2023-11-29T17:17:58.203Z',\n",
       "   'level': 'info',\n",
       "   'message': 'Training completed for togethercomputer/llama-2-7b-chat at Wed Nov 29 09:17:57 PST 2023',\n",
       "   'type': 'TRAINING_COMPLETE',\n",
       "   'param_count': 0,\n",
       "   'token_count': 0,\n",
       "   'wandb_url': '',\n",
       "   'checkpoint_path': '',\n",
       "   'model_path': '',\n",
       "   'training_offset': 0,\n",
       "   'hash': '-3602026626559728903'},\n",
       "  {'object': 'fine-tune-event',\n",
       "   'created_at': '2023-11-29T17:18:40.037Z',\n",
       "   'level': 'info',\n",
       "   'message': 'Compressing output model',\n",
       "   'type': 'COMPRESSING_MODEL',\n",
       "   'param_count': 0,\n",
       "   'token_count': 0,\n",
       "   'wandb_url': '',\n",
       "   'checkpoint_path': '',\n",
       "   'model_path': '',\n",
       "   'training_offset': 0,\n",
       "   'hash': '8749100413630211268'},\n",
       "  {'object': 'fine-tune-event',\n",
       "   'created_at': '2023-11-29T17:18:56.175Z',\n",
       "   'level': 'info',\n",
       "   'message': 'Model compression complete',\n",
       "   'type': 'MODEL_COMPRESSION_COMPLETE',\n",
       "   'param_count': 0,\n",
       "   'token_count': 0,\n",
       "   'wandb_url': '',\n",
       "   'checkpoint_path': '',\n",
       "   'model_path': '',\n",
       "   'training_offset': 0,\n",
       "   'hash': '-8489537390716392921'},\n",
       "  {'object': 'fine-tune-event',\n",
       "   'created_at': '2023-11-29T17:18:57.759Z',\n",
       "   'level': 'info',\n",
       "   'message': 'Uploading output model',\n",
       "   'type': 'MODEL_UPLOADING',\n",
       "   'param_count': 0,\n",
       "   'token_count': 0,\n",
       "   'wandb_url': '',\n",
       "   'checkpoint_path': '',\n",
       "   'model_path': '',\n",
       "   'training_offset': 0,\n",
       "   'hash': '445466684731091030'},\n",
       "  {'object': 'fine-tune-event',\n",
       "   'created_at': '2023-11-29T17:22:57.243Z',\n",
       "   'level': 'info',\n",
       "   'message': 'Model upload complete',\n",
       "   'type': 'MODEL_UPLOAD_COMPLETE',\n",
       "   'param_count': 0,\n",
       "   'token_count': 0,\n",
       "   'wandb_url': '',\n",
       "   'checkpoint_path': '',\n",
       "   'model_path': '',\n",
       "   'training_offset': 0,\n",
       "   'hash': '890781417987216056'},\n",
       "  {'object': 'fine-tune-event',\n",
       "   'created_at': '2023-11-29T17:22:57.957Z',\n",
       "   'level': 'info',\n",
       "   'message': 'Job finished at Wed Nov 29 09:22:57 PST 2023',\n",
       "   'type': 'JOB_COMPLETE',\n",
       "   'param_count': 0,\n",
       "   'token_count': 0,\n",
       "   'wandb_url': '',\n",
       "   'checkpoint_path': '',\n",
       "   'model_path': 's3://together-dev/finetune/6552b4a556bb2d3952ed7a14/mifu67@stanford.edu/llama-2-7b-chat-middle-han-second-10--1e-05-2023-11-29-06-01-02/ft-1c17315c-eebb-47a8-bdd9-f76272bb05ce-2023-11-29-09-18-55',\n",
       "   'training_offset': 0,\n",
       "   'hash': '9127685939625564436'}],\n",
       " 'queue_depth': 0,\n",
       " 'wandb_key': '',\n",
       " 'wandb_project_name': '',\n",
       " 'wandb_url': '',\n",
       " 'enable_checkpoints': False,\n",
       " 'internal_flags': ''}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp = together.Finetune.list()\n",
    "resp['data'][-1]#['status']\n",
    "# print(len(resp['data']))\n",
    "# print(resp['data'][3]['id'])\n",
    "# resp['data'][4]['status'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'success': True,\n",
       " 'value': '6db8a40646607efa35a0b83d7a98a01ec35dad85e3486d0d77a444bf446d295f-54b07198e280046e0c36ba65da4fef6276f6f71376aed6009c1b6b0bd1dcf953'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "together.Models.start('mifu67@stanford.edu/llama-2-7b-chat-middle-han-second-10--1e-05-2023-11-29-06-01-02')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'success': True}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "together.Models.stop('mifu67@stanford.edu/llama-2-7b-chat-middle-han-second-10--1e-05-2023-11-29-06-01-02')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "404 Client Error: Not Found for url: https://api.together.xyz/api/inference",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/adamzhao/Desktop/characterbot/finetune.ipynb Cell 10\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/adamzhao/Desktop/characterbot/finetune.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m output \u001b[39m=\u001b[39m together\u001b[39m.\u001b[39;49mComplete\u001b[39m.\u001b[39;49mcreate(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/adamzhao/Desktop/characterbot/finetune.ipynb#X12sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m   prompt \u001b[39m=\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mWhat are your thoughts on Count Dooku?\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m\\n\u001b[39;49;00m\u001b[39m1. \u001b[39;49m\u001b[39m\"\u001b[39;49m, \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/adamzhao/Desktop/characterbot/finetune.ipynb#X12sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m   model \u001b[39m=\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39mmifu67@stanford.edu/llama-2-7b-chat-middle-han-second-10--1e-05-2023-11-29-06-01-02\u001b[39;49m\u001b[39m'\u001b[39;49m, \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/adamzhao/Desktop/characterbot/finetune.ipynb#X12sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/together/complete.py:41\u001b[0m, in \u001b[0;36mComplete.create\u001b[0;34m(self, prompt, model, max_tokens, stop, temperature, top_p, top_k, repetition_penalty, logprobs)\u001b[0m\n\u001b[1;32m     28\u001b[0m parameter_payload \u001b[39m=\u001b[39m {\n\u001b[1;32m     29\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m\"\u001b[39m: model,\n\u001b[1;32m     30\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mprompt\u001b[39m\u001b[39m\"\u001b[39m: prompt,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mlogprobs\u001b[39m\u001b[39m\"\u001b[39m: logprobs,\n\u001b[1;32m     38\u001b[0m }\n\u001b[1;32m     40\u001b[0m \u001b[39m# send request\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m response \u001b[39m=\u001b[39m create_post_request(\n\u001b[1;32m     42\u001b[0m     url\u001b[39m=\u001b[39;49mtogether\u001b[39m.\u001b[39;49mapi_base_complete, json\u001b[39m=\u001b[39;49mparameter_payload\n\u001b[1;32m     43\u001b[0m )\n\u001b[1;32m     45\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     46\u001b[0m     response_json \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(response\u001b[39m.\u001b[39mjson())\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/together/utils.py:109\u001b[0m, in \u001b[0;36mcreate_post_request\u001b[0;34m(url, headers, json, stream, check_auth)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[39melif\u001b[39;00m response\u001b[39m.\u001b[39mstatus_code \u001b[39m==\u001b[39m \u001b[39m401\u001b[39m:\n\u001b[1;32m    108\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mAPI Key not supplied\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 109\u001b[0m response\u001b[39m.\u001b[39;49mraise_for_status()\n\u001b[1;32m    111\u001b[0m \u001b[39mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/requests/models.py:1021\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1016\u001b[0m     http_error_msg \u001b[39m=\u001b[39m (\n\u001b[1;32m   1017\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstatus_code\u001b[39m}\u001b[39;00m\u001b[39m Server Error: \u001b[39m\u001b[39m{\u001b[39;00mreason\u001b[39m}\u001b[39;00m\u001b[39m for url: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39murl\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1018\u001b[0m     )\n\u001b[1;32m   1020\u001b[0m \u001b[39mif\u001b[39;00m http_error_msg:\n\u001b[0;32m-> 1021\u001b[0m     \u001b[39mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m)\n",
      "\u001b[0;31mHTTPError\u001b[0m: 404 Client Error: Not Found for url: https://api.together.xyz/api/inference"
     ]
    }
   ],
   "source": [
    "output = together.Complete.create(\n",
    "  prompt = \"What are your thoughts on Count Dooku?\\n\\n1. \", \n",
    "  model = 'mifu67@stanford.edu/llama-2-7b-chat-middle-han-second-10--1e-05-2023-11-29-06-01-02', \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'training_file': 'file-5350fa6b-2ad1-4a4d-8717-fcb1522be037',\n",
       " 'validation_file': '',\n",
       " 'model_output_name': 'mifu67@stanford.edu/llama-2-7b-chat-middle-han-10--1e-05-2023-11-29-03-08-42',\n",
       " 'model_output_path': 's3://together-dev/finetune/6552b4a556bb2d3952ed7a14/mifu67@stanford.edu/llama-2-7b-chat-middle-han-10--1e-05-2023-11-29-03-08-42/ft-33d67b6b-7bb0-4840-8bce-27ebd5169593',\n",
       " 'Suffix': 'middle-han-10--1e-05',\n",
       " 'model': 'togethercomputer/llama-2-7b-chat',\n",
       " 'n_epochs': 10,\n",
       " 'n_checkpoints': 1,\n",
       " 'batch_size': 4,\n",
       " 'learning_rate': 1e-05,\n",
       " 'user_id': '6552b4a556bb2d3952ed7a14',\n",
       " 'lora': False,\n",
       " 'lora_r': 8,\n",
       " 'lora_alpha': 8,\n",
       " 'lora_dropout': 0,\n",
       " 'staring_epoch': 0,\n",
       " 'training_offset': 0,\n",
       " 'checkspoint_path': '',\n",
       " 'random_seed': '',\n",
       " 'created_at': '2023-11-29T03:08:42.709Z',\n",
       " 'updated_at': '2023-11-29T05:57:55.914Z',\n",
       " 'status': 'cancel_requested',\n",
       " 'owner_address': '0xebd597774b313d8e8d22af4629b75ec7d567f678',\n",
       " 'id': 'ft-33d67b6b-7bb0-4840-8bce-27ebd5169593',\n",
       " 'job_id': '',\n",
       " 'token_count': 0,\n",
       " 'param_count': 0,\n",
       " 'total_price': 0,\n",
       " 'epochs_completed': 0,\n",
       " 'events': [{'object': 'fine-tune-event',\n",
       "   'created_at': '2023-11-29T03:08:42.709Z',\n",
       "   'level': '',\n",
       "   'message': 'Fine tune request created',\n",
       "   'type': 'JOB_PENDING',\n",
       "   'param_count': 0,\n",
       "   'token_count': 0,\n",
       "   'wandb_url': '',\n",
       "   'checkpoint_path': '',\n",
       "   'model_path': '',\n",
       "   'training_offset': 0,\n",
       "   'hash': ''}],\n",
       " 'queue_depth': 0,\n",
       " 'wandb_key': '',\n",
       " 'wandb_project_name': '',\n",
       " 'wandb_url': '',\n",
       " 'enable_checkpoints': False,\n",
       " 'internal_flags': ''}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "together.Finetune.cancel('ft-33d67b6b-7bb0-4840-8bce-27ebd5169593')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
